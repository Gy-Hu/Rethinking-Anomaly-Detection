Using device: cuda
Namespace(dataset='tfinance', train_ratio=0.4, hid_dim=128, num_layers=3, epoch=100, run=3, knn_reconstruct_graph=True, knn_reconstruct_graph_approximate=False, alpha=0.5, top_k=5, save_model=False, model_path='./model', device=device(type='cuda', index=0), choose_model='GCN', hyperparameter_tuning=False)
Graph(num_nodes=39357, num_edges=298512,
      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'feature': Scheme(shape=(10,), dtype=torch.float32)}
      edata_schemes={})
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 60.6509, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 450.1737, val mf1: 0.0438, (best 0.4883)
Epoch 2, loss: 22.3025, val mf1: 0.3912, (best 0.4883)
Epoch 3, loss: 31.8481, val mf1: 0.5925, (best 0.5925)
Epoch 4, loss: 48.6161, val mf1: 0.5580, (best 0.5925)
Epoch 5, loss: 50.2093, val mf1: 0.8498, (best 0.8498)
Epoch 6, loss: 52.8657, val mf1: 0.8071, (best 0.8498)
Epoch 7, loss: 53.9561, val mf1: 0.7465, (best 0.8498)
Epoch 8, loss: 53.8716, val mf1: 0.7061, (best 0.8498)
Epoch 9, loss: 52.8172, val mf1: 0.6752, (best 0.8498)
Epoch 10, loss: 50.7972, val mf1: 0.6535, (best 0.8498)
Epoch 11, loss: 47.8585, val mf1: 0.6435, (best 0.8498)
Epoch 12, loss: 44.0286, val mf1: 0.6391, (best 0.8498)
Epoch 13, loss: 39.3279, val mf1: 0.6395, (best 0.8498)
Epoch 14, loss: 34.0120, val mf1: 0.6447, (best 0.8498)
Epoch 15, loss: 28.3370, val mf1: 0.6548, (best 0.8498)
Epoch 16, loss: 22.5937, val mf1: 0.6776, (best 0.8498)
Epoch 17, loss: 17.1339, val mf1: 0.7136, (best 0.8498)
Epoch 18, loss: 12.0757, val mf1: 0.7074, (best 0.8498)
Epoch 19, loss: 9.2488, val mf1: 0.5902, (best 0.8498)
Epoch 20, loss: 13.8749, val mf1: 0.4868, (best 0.8498)
Epoch 21, loss: 14.4450, val mf1: 0.4711, (best 0.8498)
Epoch 22, loss: 9.7465, val mf1: 0.5225, (best 0.8498)
Epoch 23, loss: 7.1040, val mf1: 0.6546, (best 0.8498)
Epoch 24, loss: 6.7904, val mf1: 0.7034, (best 0.8498)
Epoch 25, loss: 7.0560, val mf1: 0.6553, (best 0.8498)
Epoch 26, loss: 7.6086, val mf1: 0.6107, (best 0.8498)
Epoch 27, loss: 7.8737, val mf1: 0.5870, (best 0.8498)
Epoch 28, loss: 7.5890, val mf1: 0.5870, (best 0.8498)
Epoch 29, loss: 6.7848, val mf1: 0.6098, (best 0.8498)
Epoch 30, loss: 5.6877, val mf1: 0.6511, (best 0.8498)
Epoch 31, loss: 4.5077, val mf1: 0.7080, (best 0.8498)
Epoch 32, loss: 3.3523, val mf1: 0.7332, (best 0.8498)
Epoch 33, loss: 2.4610, val mf1: 0.6588, (best 0.8498)
Epoch 34, loss: 2.8703, val mf1: 0.5503, (best 0.8498)
Epoch 35, loss: 2.8098, val mf1: 0.5560, (best 0.8498)
Epoch 36, loss: 2.5583, val mf1: 0.7732, (best 0.8498)
Epoch 37, loss: 3.0106, val mf1: 0.7756, (best 0.8498)
Epoch 38, loss: 2.5640, val mf1: 0.6889, (best 0.8498)
Epoch 39, loss: 2.6636, val mf1: 0.5352, (best 0.8498)
Epoch 40, loss: 1.8240, val mf1: 0.6870, (best 0.8498)
Epoch 41, loss: 1.6163, val mf1: 0.8053, (best 0.8498)
Epoch 42, loss: 1.1330, val mf1: 0.7535, (best 0.8498)
Epoch 43, loss: 2.2438, val mf1: 0.4968, (best 0.8498)
Epoch 44, loss: 1.9799, val mf1: 0.7350, (best 0.8498)
Epoch 45, loss: 2.9498, val mf1: 0.8074, (best 0.8498)
Epoch 46, loss: 3.3605, val mf1: 0.8195, (best 0.8498)
Epoch 47, loss: 3.1146, val mf1: 0.8030, (best 0.8498)
Epoch 48, loss: 2.5986, val mf1: 0.6867, (best 0.8498)
Epoch 49, loss: 2.3277, val mf1: 0.5868, (best 0.8498)
Epoch 50, loss: 2.0397, val mf1: 0.5370, (best 0.8498)
Epoch 51, loss: 1.7784, val mf1: 0.5116, (best 0.8498)
Epoch 52, loss: 1.4908, val mf1: 0.8348, (best 0.8498)
Epoch 53, loss: 2.1411, val mf1: 0.8152, (best 0.8498)
Epoch 54, loss: 1.8926, val mf1: 0.6795, (best 0.8498)
Epoch 55, loss: 3.1884, val mf1: 0.5364, (best 0.8498)
Epoch 56, loss: 2.5630, val mf1: 0.8375, (best 0.8498)
Epoch 57, loss: 3.2420, val mf1: 0.8506, (best 0.8506)
Epoch 58, loss: 3.1291, val mf1: 0.8481, (best 0.8506)
Epoch 59, loss: 2.7637, val mf1: 0.7260, (best 0.8506)
Epoch 60, loss: 3.4212, val mf1: 0.5405, (best 0.8506)
Epoch 61, loss: 3.8374, val mf1: 0.5025, (best 0.8506)
Epoch 62, loss: 3.2137, val mf1: 0.5314, (best 0.8506)
Epoch 63, loss: 2.2491, val mf1: 0.7135, (best 0.8506)
Epoch 64, loss: 2.1182, val mf1: 0.8253, (best 0.8506)
Epoch 65, loss: 1.8787, val mf1: 0.7213, (best 0.8506)
Epoch 66, loss: 1.8682, val mf1: 0.6440, (best 0.8506)
Epoch 67, loss: 1.2976, val mf1: 0.8213, (best 0.8506)
Epoch 68, loss: 1.5122, val mf1: 0.5979, (best 0.8506)
Epoch 69, loss: 1.5037, val mf1: 0.6252, (best 0.8506)
Epoch 70, loss: 1.5178, val mf1: 0.7040, (best 0.8506)
Epoch 71, loss: 1.5358, val mf1: 0.7175, (best 0.8506)
Epoch 72, loss: 1.4530, val mf1: 0.6754, (best 0.8506)
Epoch 73, loss: 1.5155, val mf1: 0.6152, (best 0.8506)
Epoch 74, loss: 1.5044, val mf1: 0.6215, (best 0.8506)
Epoch 75, loss: 1.4013, val mf1: 0.6866, (best 0.8506)
Epoch 76, loss: 1.3333, val mf1: 0.7499, (best 0.8506)
Epoch 77, loss: 1.1493, val mf1: 0.7611, (best 0.8506)
Epoch 78, loss: 1.1659, val mf1: 0.6335, (best 0.8506)
Epoch 79, loss: 1.1245, val mf1: 0.8272, (best 0.8506)
Epoch 80, loss: 1.0745, val mf1: 0.8366, (best 0.8506)
Epoch 81, loss: 0.7202, val mf1: 0.7061, (best 0.8506)
Epoch 82, loss: 0.5976, val mf1: 0.7571, (best 0.8506)
Epoch 83, loss: 0.7627, val mf1: 0.6224, (best 0.8506)
Epoch 84, loss: 0.8676, val mf1: 0.8033, (best 0.8506)
Epoch 85, loss: 0.9878, val mf1: 0.7848, (best 0.8506)
Epoch 86, loss: 0.8252, val mf1: 0.6516, (best 0.8506)
Epoch 87, loss: 0.9005, val mf1: 0.5796, (best 0.8506)
Epoch 88, loss: 0.6862, val mf1: 0.8169, (best 0.8506)
Epoch 89, loss: 0.6077, val mf1: 0.8090, (best 0.8506)
Epoch 90, loss: 1.9634, val mf1: 0.5355, (best 0.8506)
Epoch 91, loss: 1.9332, val mf1: 0.8440, (best 0.8506)
Epoch 92, loss: 2.9825, val mf1: 0.8449, (best 0.8506)
Epoch 93, loss: 3.0926, val mf1: 0.8557, (best 0.8557)
Epoch 94, loss: 2.6437, val mf1: 0.7567, (best 0.8557)
Epoch 95, loss: 2.6235, val mf1: 0.6175, (best 0.8557)
Epoch 96, loss: 2.7758, val mf1: 0.5533, (best 0.8557)
Epoch 97, loss: 2.6414, val mf1: 0.5261, (best 0.8557)
Epoch 98, loss: 1.8825, val mf1: 0.5519, (best 0.8557)
Epoch 99, loss: 0.9161, val mf1: 0.6896, (best 0.8557)
time cost:  30.414222478866577 s
Test: REC 62.76 PRE 87.16 MF1 85.93 AUC 91.22
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 240.7608, val mf1: 0.0438, (best 0.0438)
Epoch 1, loss: 70.4518, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 101.0720, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 108.5561, val mf1: 0.4883, (best 0.4883)
Epoch 4, loss: 104.7110, val mf1: 0.4994, (best 0.4994)
Epoch 5, loss: 95.1894, val mf1: 0.8391, (best 0.8391)
Epoch 6, loss: 90.9638, val mf1: 0.8091, (best 0.8391)
Epoch 7, loss: 87.2450, val mf1: 0.7495, (best 0.8391)
Epoch 8, loss: 83.6455, val mf1: 0.7110, (best 0.8391)
Epoch 9, loss: 80.0165, val mf1: 0.6731, (best 0.8391)
Epoch 10, loss: 76.2078, val mf1: 0.6490, (best 0.8391)
Epoch 11, loss: 72.1429, val mf1: 0.6320, (best 0.8391)
Epoch 12, loss: 67.7189, val mf1: 0.6183, (best 0.8391)
Epoch 13, loss: 62.7903, val mf1: 0.6074, (best 0.8391)
Epoch 14, loss: 57.2979, val mf1: 0.6010, (best 0.8391)
Epoch 15, loss: 51.3298, val mf1: 0.5996, (best 0.8391)
Epoch 16, loss: 44.9967, val mf1: 0.6015, (best 0.8391)
Epoch 17, loss: 38.4062, val mf1: 0.6059, (best 0.8391)
Epoch 18, loss: 31.7218, val mf1: 0.6189, (best 0.8391)
Epoch 19, loss: 25.1051, val mf1: 0.6421, (best 0.8391)
Epoch 20, loss: 18.8729, val mf1: 0.6804, (best 0.8391)
Epoch 21, loss: 13.1971, val mf1: 0.7514, (best 0.8391)
Epoch 22, loss: 8.3750, val mf1: 0.8322, (best 0.8391)
Epoch 23, loss: 11.6771, val mf1: 0.5329, (best 0.8391)
Epoch 24, loss: 14.4558, val mf1: 0.4976, (best 0.8391)
Epoch 25, loss: 8.9515, val mf1: 0.4964, (best 0.8391)
Epoch 26, loss: 5.1674, val mf1: 0.6033, (best 0.8391)
Epoch 27, loss: 5.4331, val mf1: 0.6625, (best 0.8391)
Epoch 28, loss: 5.9806, val mf1: 0.6257, (best 0.8391)
Epoch 29, loss: 6.8362, val mf1: 0.5772, (best 0.8391)
Epoch 30, loss: 7.2836, val mf1: 0.5694, (best 0.8391)
Epoch 31, loss: 7.2055, val mf1: 0.5803, (best 0.8391)
Epoch 32, loss: 6.7393, val mf1: 0.6173, (best 0.8391)
Epoch 33, loss: 6.1941, val mf1: 0.7284, (best 0.8391)
Epoch 34, loss: 5.8189, val mf1: 0.8180, (best 0.8391)
Epoch 35, loss: 5.2896, val mf1: 0.8200, (best 0.8391)
Epoch 36, loss: 4.5757, val mf1: 0.7853, (best 0.8391)
Epoch 37, loss: 3.7568, val mf1: 0.7042, (best 0.8391)
Epoch 38, loss: 3.0393, val mf1: 0.6135, (best 0.8391)
Epoch 39, loss: 2.5572, val mf1: 0.5407, (best 0.8391)
Epoch 40, loss: 2.0159, val mf1: 0.5159, (best 0.8391)
Epoch 41, loss: 1.6043, val mf1: 0.5573, (best 0.8391)
Epoch 42, loss: 1.5702, val mf1: 0.5902, (best 0.8391)
Epoch 43, loss: 1.6059, val mf1: 0.7418, (best 0.8391)
Epoch 44, loss: 1.7192, val mf1: 0.8352, (best 0.8391)
Epoch 45, loss: 1.4988, val mf1: 0.8248, (best 0.8391)
Epoch 46, loss: 1.7583, val mf1: 0.6304, (best 0.8391)
Epoch 47, loss: 1.4017, val mf1: 0.7264, (best 0.8391)
Epoch 48, loss: 1.6064, val mf1: 0.6665, (best 0.8391)
Epoch 49, loss: 1.6116, val mf1: 0.6370, (best 0.8391)
Epoch 50, loss: 1.3958, val mf1: 0.6291, (best 0.8391)
Epoch 51, loss: 1.1385, val mf1: 0.6194, (best 0.8391)
Epoch 52, loss: 0.8722, val mf1: 0.6962, (best 0.8391)
Epoch 53, loss: 0.8451, val mf1: 0.7644, (best 0.8391)
Epoch 54, loss: 0.9116, val mf1: 0.7081, (best 0.8391)
Epoch 55, loss: 0.9683, val mf1: 0.6623, (best 0.8391)
Epoch 56, loss: 0.9263, val mf1: 0.7007, (best 0.8391)
Epoch 57, loss: 0.8028, val mf1: 0.6948, (best 0.8391)
Epoch 58, loss: 0.6855, val mf1: 0.6598, (best 0.8391)
Epoch 59, loss: 0.6924, val mf1: 0.6575, (best 0.8391)
Epoch 60, loss: 0.7044, val mf1: 0.6848, (best 0.8391)
Epoch 61, loss: 0.7080, val mf1: 0.7094, (best 0.8391)
Epoch 62, loss: 0.6475, val mf1: 0.7463, (best 0.8391)
Epoch 63, loss: 0.5839, val mf1: 0.7267, (best 0.8391)
Epoch 64, loss: 0.8083, val mf1: 0.6153, (best 0.8391)
Epoch 65, loss: 0.9642, val mf1: 0.8571, (best 0.8571)
Epoch 66, loss: 1.1939, val mf1: 0.8567, (best 0.8571)
Epoch 67, loss: 1.1432, val mf1: 0.7959, (best 0.8571)
Epoch 68, loss: 1.1008, val mf1: 0.6553, (best 0.8571)
Epoch 69, loss: 1.0287, val mf1: 0.6027, (best 0.8571)
Epoch 70, loss: 0.6916, val mf1: 0.6594, (best 0.8571)
Epoch 71, loss: 0.8063, val mf1: 0.6177, (best 0.8571)
Epoch 72, loss: 1.1599, val mf1: 0.8313, (best 0.8571)
Epoch 73, loss: 1.5315, val mf1: 0.8340, (best 0.8571)
Epoch 74, loss: 1.4378, val mf1: 0.8481, (best 0.8571)
Epoch 75, loss: 0.9904, val mf1: 0.8567, (best 0.8571)
Epoch 76, loss: 0.5214, val mf1: 0.7429, (best 0.8571)
Epoch 77, loss: 2.9240, val mf1: 0.4728, (best 0.8571)
Epoch 78, loss: 1.3337, val mf1: 0.7430, (best 0.8571)
Epoch 79, loss: 2.3676, val mf1: 0.8254, (best 0.8571)
Epoch 80, loss: 3.1501, val mf1: 0.8418, (best 0.8571)
Epoch 81, loss: 3.5897, val mf1: 0.8398, (best 0.8571)
Epoch 82, loss: 3.7344, val mf1: 0.8146, (best 0.8571)
Epoch 83, loss: 3.6962, val mf1: 0.7520, (best 0.8571)
Epoch 84, loss: 3.5592, val mf1: 0.6996, (best 0.8571)
Epoch 85, loss: 3.3077, val mf1: 0.6669, (best 0.8571)
Epoch 86, loss: 2.9226, val mf1: 0.6464, (best 0.8571)
Epoch 87, loss: 2.3761, val mf1: 0.6630, (best 0.8571)
Epoch 88, loss: 1.7037, val mf1: 0.7259, (best 0.8571)
Epoch 89, loss: 1.1474, val mf1: 0.7349, (best 0.8571)
Epoch 90, loss: 1.0471, val mf1: 0.5863, (best 0.8571)
Epoch 91, loss: 2.2541, val mf1: 0.4492, (best 0.8571)
Epoch 92, loss: 1.1960, val mf1: 0.6363, (best 0.8571)
Epoch 93, loss: 1.6670, val mf1: 0.8150, (best 0.8571)
Epoch 94, loss: 1.8555, val mf1: 0.8301, (best 0.8571)
Epoch 95, loss: 1.6968, val mf1: 0.8451, (best 0.8571)
Epoch 96, loss: 1.2938, val mf1: 0.8502, (best 0.8571)
Epoch 97, loss: 0.8065, val mf1: 0.8238, (best 0.8571)
Epoch 98, loss: 0.9633, val mf1: 0.6099, (best 0.8571)
Epoch 99, loss: 1.4233, val mf1: 0.5155, (best 0.8571)
time cost:  26.34505844116211 s
Test: REC 59.86 PRE 86.63 MF1 84.81 AUC 91.36
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 37.1661, val mf1: 0.4619, (best 0.4619)
Epoch 1, loss: 47.6397, val mf1: 0.7261, (best 0.7261)
Epoch 2, loss: 57.0088, val mf1: 0.6610, (best 0.7261)
Epoch 3, loss: 62.4483, val mf1: 0.6076, (best 0.7261)
Epoch 4, loss: 61.3755, val mf1: 0.5822, (best 0.7261)
Epoch 5, loss: 54.7057, val mf1: 0.5738, (best 0.7261)
Epoch 6, loss: 44.4782, val mf1: 0.5734, (best 0.7261)
Epoch 7, loss: 32.7324, val mf1: 0.5785, (best 0.7261)
Epoch 8, loss: 20.5982, val mf1: 0.5897, (best 0.7261)
Epoch 9, loss: 39.3561, val mf1: 0.4731, (best 0.7261)
Epoch 10, loss: 16.8540, val mf1: 0.6501, (best 0.7261)
Epoch 11, loss: 26.9996, val mf1: 0.6252, (best 0.7261)
Epoch 12, loss: 33.3550, val mf1: 0.5720, (best 0.7261)
Epoch 13, loss: 30.1542, val mf1: 0.6935, (best 0.7261)
Epoch 14, loss: 23.7445, val mf1: 0.8534, (best 0.8534)
Epoch 15, loss: 17.7502, val mf1: 0.7853, (best 0.8534)
Epoch 16, loss: 12.8203, val mf1: 0.6670, (best 0.8534)
Epoch 17, loss: 13.0282, val mf1: 0.4808, (best 0.8534)
Epoch 18, loss: 22.7449, val mf1: 0.3365, (best 0.8534)
Epoch 19, loss: 12.7341, val mf1: 0.4668, (best 0.8534)
Epoch 20, loss: 11.0551, val mf1: 0.6064, (best 0.8534)
Epoch 21, loss: 12.0085, val mf1: 0.6952, (best 0.8534)
Epoch 22, loss: 12.8402, val mf1: 0.7603, (best 0.8534)
Epoch 23, loss: 12.9506, val mf1: 0.8056, (best 0.8534)
Epoch 24, loss: 11.8270, val mf1: 0.8184, (best 0.8534)
Epoch 25, loss: 9.5459, val mf1: 0.8179, (best 0.8534)
Epoch 26, loss: 6.2941, val mf1: 0.7925, (best 0.8534)
Epoch 27, loss: 4.5935, val mf1: 0.5738, (best 0.8534)
Epoch 28, loss: 10.1249, val mf1: 0.4519, (best 0.8534)
Epoch 29, loss: 3.4389, val mf1: 0.8059, (best 0.8534)
Epoch 30, loss: 5.9409, val mf1: 0.8465, (best 0.8534)
Epoch 31, loss: 6.9088, val mf1: 0.8520, (best 0.8534)
Epoch 32, loss: 6.4485, val mf1: 0.8465, (best 0.8534)
Epoch 33, loss: 4.8876, val mf1: 0.7956, (best 0.8534)
Epoch 34, loss: 3.2661, val mf1: 0.6341, (best 0.8534)
Epoch 35, loss: 6.1814, val mf1: 0.3758, (best 0.8534)
Epoch 36, loss: 2.9087, val mf1: 0.5595, (best 0.8534)
Epoch 37, loss: 3.0575, val mf1: 0.7902, (best 0.8534)
Epoch 38, loss: 3.7307, val mf1: 0.8345, (best 0.8534)
Epoch 39, loss: 3.3150, val mf1: 0.8490, (best 0.8534)
Epoch 40, loss: 2.6474, val mf1: 0.6388, (best 0.8534)
Epoch 41, loss: 4.8199, val mf1: 0.5518, (best 0.8534)
Epoch 42, loss: 3.0700, val mf1: 0.8476, (best 0.8534)
Epoch 43, loss: 4.0769, val mf1: 0.8476, (best 0.8534)
Epoch 44, loss: 3.9509, val mf1: 0.8057, (best 0.8534)
Epoch 45, loss: 3.0834, val mf1: 0.7451, (best 0.8534)
Epoch 46, loss: 2.1566, val mf1: 0.6256, (best 0.8534)
Epoch 47, loss: 4.3801, val mf1: 0.3917, (best 0.8534)
Epoch 48, loss: 1.9235, val mf1: 0.6232, (best 0.8534)
Epoch 49, loss: 2.4770, val mf1: 0.7569, (best 0.8534)
Epoch 50, loss: 2.9742, val mf1: 0.7858, (best 0.8534)
Epoch 51, loss: 2.0535, val mf1: 0.7826, (best 0.8534)
Epoch 52, loss: 1.5467, val mf1: 0.5629, (best 0.8534)
Epoch 53, loss: 2.2076, val mf1: 0.5176, (best 0.8534)
Epoch 54, loss: 1.9621, val mf1: 0.7916, (best 0.8534)
Epoch 55, loss: 2.9161, val mf1: 0.8310, (best 0.8534)
Epoch 56, loss: 2.8788, val mf1: 0.8237, (best 0.8534)
Epoch 57, loss: 2.0398, val mf1: 0.7654, (best 0.8534)
Epoch 58, loss: 1.1349, val mf1: 0.6180, (best 0.8534)
Epoch 59, loss: 5.0192, val mf1: 0.4101, (best 0.8534)
Epoch 60, loss: 5.8585, val mf1: 0.8600, (best 0.8600)
Epoch 61, loss: 11.5751, val mf1: 0.8221, (best 0.8600)
Epoch 62, loss: 14.4706, val mf1: 0.8465, (best 0.8600)
Epoch 63, loss: 15.7343, val mf1: 0.8590, (best 0.8600)
Epoch 64, loss: 16.2023, val mf1: 0.8446, (best 0.8600)
Epoch 65, loss: 15.8800, val mf1: 0.8225, (best 0.8600)
Epoch 66, loss: 14.9822, val mf1: 0.7797, (best 0.8600)
Epoch 67, loss: 13.8571, val mf1: 0.7242, (best 0.8600)
Epoch 68, loss: 12.7865, val mf1: 0.6562, (best 0.8600)
Epoch 69, loss: 11.9226, val mf1: 0.5981, (best 0.8600)
Epoch 70, loss: 11.2838, val mf1: 0.5514, (best 0.8600)
Epoch 71, loss: 10.6831, val mf1: 0.5166, (best 0.8600)
Epoch 72, loss: 9.7752, val mf1: 0.4939, (best 0.8600)
Epoch 73, loss: 8.4037, val mf1: 0.4793, (best 0.8600)
Epoch 74, loss: 6.6334, val mf1: 0.4715, (best 0.8600)
Epoch 75, loss: 4.7542, val mf1: 0.4905, (best 0.8600)
Epoch 76, loss: 3.2457, val mf1: 0.5704, (best 0.8600)
Epoch 77, loss: 2.8565, val mf1: 0.6661, (best 0.8600)
Epoch 78, loss: 3.3406, val mf1: 0.7230, (best 0.8600)
Epoch 79, loss: 3.9036, val mf1: 0.7496, (best 0.8600)
Epoch 80, loss: 4.2921, val mf1: 0.7122, (best 0.8600)
Epoch 81, loss: 4.5992, val mf1: 0.6474, (best 0.8600)
Epoch 82, loss: 4.5983, val mf1: 0.6996, (best 0.8600)
Epoch 83, loss: 4.4913, val mf1: 0.7482, (best 0.8600)
Epoch 84, loss: 4.1346, val mf1: 0.6853, (best 0.8600)
Epoch 85, loss: 3.7346, val mf1: 0.6461, (best 0.8600)
Epoch 86, loss: 3.1865, val mf1: 0.7731, (best 0.8600)
Epoch 87, loss: 2.6097, val mf1: 0.7823, (best 0.8600)
Epoch 88, loss: 2.0401, val mf1: 0.6697, (best 0.8600)
Epoch 89, loss: 1.7269, val mf1: 0.6393, (best 0.8600)
Epoch 90, loss: 1.5354, val mf1: 0.6710, (best 0.8600)
Epoch 91, loss: 1.7287, val mf1: 0.6697, (best 0.8600)
Epoch 92, loss: 1.9210, val mf1: 0.6370, (best 0.8600)
Epoch 93, loss: 1.8198, val mf1: 0.6468, (best 0.8600)
Epoch 94, loss: 1.6325, val mf1: 0.6955, (best 0.8600)
Epoch 95, loss: 1.4575, val mf1: 0.7454, (best 0.8600)
Epoch 96, loss: 1.2825, val mf1: 0.7840, (best 0.8600)
Epoch 97, loss: 1.2919, val mf1: 0.6092, (best 0.8600)
Epoch 98, loss: 1.3665, val mf1: 0.5805, (best 0.8600)
Epoch 99, loss: 1.1952, val mf1: 0.8015, (best 0.8600)
time cost:  25.990503787994385 s
Test: REC 64.69 PRE 85.43 MF1 86.26 AUC 91.50
MF1-mean: 85.67, MF1-std: 0.62, AUC-mean: 91.36, AUC-std: 0.11
