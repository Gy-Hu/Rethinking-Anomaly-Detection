Using device: cuda
Namespace(dataset='tfinance', train_ratio=0.4, hid_dim=128, num_layers=3, epoch=100, run=3, knn_reconstruct_graph=True, knn_reconstruct_graph_approximate=False, alpha=0.7, top_k=3, save_model=False, model_path='./model', device=device(type='cuda', index=0), choose_model='GCN', hyperparameter_tuning=False)
Graph(num_nodes=39357, num_edges=199778,
      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'feature': Scheme(shape=(10,), dtype=torch.float32)}
      edata_schemes={})
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 51.6714, val mf1: 0.4911, (best 0.4911)
Epoch 1, loss: 371.3055, val mf1: 0.0440, (best 0.4911)
Epoch 2, loss: 10.7247, val mf1: 0.7107, (best 0.7107)
Epoch 3, loss: 29.6169, val mf1: 0.8542, (best 0.8542)
Epoch 4, loss: 42.1273, val mf1: 0.8486, (best 0.8542)
Epoch 5, loss: 49.0593, val mf1: 0.8505, (best 0.8542)
Epoch 6, loss: 52.4587, val mf1: 0.8237, (best 0.8542)
Epoch 7, loss: 53.6097, val mf1: 0.7860, (best 0.8542)
Epoch 8, loss: 53.4294, val mf1: 0.7474, (best 0.8542)
Epoch 9, loss: 52.2914, val mf1: 0.7194, (best 0.8542)
Epoch 10, loss: 50.3839, val mf1: 0.6975, (best 0.8542)
Epoch 11, loss: 47.8385, val mf1: 0.6748, (best 0.8542)
Epoch 12, loss: 44.6988, val mf1: 0.6574, (best 0.8542)
Epoch 13, loss: 41.0315, val mf1: 0.6512, (best 0.8542)
Epoch 14, loss: 36.8722, val mf1: 0.6506, (best 0.8542)
Epoch 15, loss: 32.3540, val mf1: 0.6547, (best 0.8542)
Epoch 16, loss: 27.6690, val mf1: 0.6828, (best 0.8542)
Epoch 17, loss: 23.0519, val mf1: 0.7200, (best 0.8542)
Epoch 18, loss: 18.7476, val mf1: 0.7483, (best 0.8542)
Epoch 19, loss: 14.7374, val mf1: 0.7200, (best 0.8542)
Epoch 20, loss: 10.9935, val mf1: 0.6257, (best 0.8542)
Epoch 21, loss: 8.6110, val mf1: 0.5347, (best 0.8542)
Epoch 22, loss: 12.6514, val mf1: 0.4253, (best 0.8542)
Epoch 23, loss: 11.0249, val mf1: 0.4331, (best 0.8542)
Epoch 24, loss: 7.2608, val mf1: 0.4993, (best 0.8542)
Epoch 25, loss: 6.1329, val mf1: 0.5746, (best 0.8542)
Epoch 26, loss: 6.0086, val mf1: 0.6215, (best 0.8542)
Epoch 27, loss: 6.0748, val mf1: 0.6517, (best 0.8542)
Epoch 28, loss: 5.9902, val mf1: 0.6710, (best 0.8542)
Epoch 29, loss: 5.4827, val mf1: 0.6890, (best 0.8542)
Epoch 30, loss: 4.6147, val mf1: 0.7163, (best 0.8542)
Epoch 31, loss: 3.5007, val mf1: 0.7039, (best 0.8542)
Epoch 32, loss: 2.6819, val mf1: 0.5933, (best 0.8542)
Epoch 33, loss: 3.5181, val mf1: 0.5211, (best 0.8542)
Epoch 34, loss: 2.1046, val mf1: 0.5919, (best 0.8542)
Epoch 35, loss: 2.3695, val mf1: 0.8361, (best 0.8542)
Epoch 36, loss: 2.5973, val mf1: 0.6869, (best 0.8542)
Epoch 37, loss: 2.6331, val mf1: 0.6191, (best 0.8542)
Epoch 38, loss: 1.9193, val mf1: 0.6411, (best 0.8542)
Epoch 39, loss: 1.1976, val mf1: 0.7190, (best 0.8542)
Epoch 40, loss: 6.6040, val mf1: 0.4220, (best 0.8542)
Epoch 41, loss: 2.0721, val mf1: 0.7526, (best 0.8542)
Epoch 42, loss: 2.8807, val mf1: 0.7916, (best 0.8542)
Epoch 43, loss: 3.9157, val mf1: 0.6393, (best 0.8542)
Epoch 44, loss: 4.5411, val mf1: 0.6336, (best 0.8542)
Epoch 45, loss: 4.6042, val mf1: 0.6542, (best 0.8542)
Epoch 46, loss: 4.2676, val mf1: 0.6853, (best 0.8542)
Epoch 47, loss: 3.7930, val mf1: 0.7837, (best 0.8542)
Epoch 48, loss: 3.1391, val mf1: 0.8057, (best 0.8542)
Epoch 49, loss: 2.1935, val mf1: 0.7217, (best 0.8542)
Epoch 50, loss: 1.9257, val mf1: 0.5633, (best 0.8542)
Epoch 51, loss: 2.9790, val mf1: 0.4572, (best 0.8542)
Epoch 52, loss: 1.5548, val mf1: 0.5882, (best 0.8542)
Epoch 53, loss: 1.9901, val mf1: 0.7746, (best 0.8542)
Epoch 54, loss: 1.7288, val mf1: 0.8427, (best 0.8542)
Epoch 55, loss: 1.2638, val mf1: 0.7854, (best 0.8542)
Epoch 56, loss: 1.4939, val mf1: 0.5931, (best 0.8542)
Epoch 57, loss: 1.8594, val mf1: 0.5716, (best 0.8542)
Epoch 58, loss: 1.4896, val mf1: 0.6722, (best 0.8542)
Epoch 59, loss: 1.6582, val mf1: 0.7234, (best 0.8542)
Epoch 60, loss: 1.6460, val mf1: 0.7572, (best 0.8542)
Epoch 61, loss: 1.3848, val mf1: 0.7840, (best 0.8542)
Epoch 62, loss: 1.3135, val mf1: 0.6438, (best 0.8542)
Epoch 63, loss: 1.3633, val mf1: 0.6159, (best 0.8542)
Epoch 64, loss: 1.1247, val mf1: 0.7988, (best 0.8542)
Epoch 65, loss: 1.1706, val mf1: 0.7541, (best 0.8542)
Epoch 66, loss: 1.0665, val mf1: 0.6642, (best 0.8542)
Epoch 67, loss: 1.0637, val mf1: 0.5910, (best 0.8542)
Epoch 68, loss: 1.0373, val mf1: 0.5617, (best 0.8542)
Epoch 69, loss: 0.9601, val mf1: 0.7031, (best 0.8542)
Epoch 70, loss: 1.1170, val mf1: 0.7535, (best 0.8542)
Epoch 71, loss: 0.8048, val mf1: 0.7233, (best 0.8542)
Epoch 72, loss: 1.6094, val mf1: 0.5530, (best 0.8542)
Epoch 73, loss: 1.6325, val mf1: 0.8013, (best 0.8542)
Epoch 74, loss: 2.6839, val mf1: 0.7720, (best 0.8542)
Epoch 75, loss: 3.3769, val mf1: 0.7319, (best 0.8542)
Epoch 76, loss: 3.7476, val mf1: 0.7115, (best 0.8542)
Epoch 77, loss: 3.8113, val mf1: 0.7047, (best 0.8542)
Epoch 78, loss: 3.5805, val mf1: 0.7217, (best 0.8542)
Epoch 79, loss: 3.1381, val mf1: 0.7914, (best 0.8542)
Epoch 80, loss: 2.6167, val mf1: 0.8000, (best 0.8542)
Epoch 81, loss: 2.1388, val mf1: 0.6298, (best 0.8542)
Epoch 82, loss: 1.9894, val mf1: 0.5250, (best 0.8542)
Epoch 83, loss: 1.8761, val mf1: 0.4942, (best 0.8542)
Epoch 84, loss: 1.5639, val mf1: 0.5224, (best 0.8542)
Epoch 85, loss: 1.1452, val mf1: 0.6596, (best 0.8542)
Epoch 86, loss: 1.0600, val mf1: 0.8197, (best 0.8542)
Epoch 87, loss: 1.0272, val mf1: 0.7090, (best 0.8542)
Epoch 88, loss: 1.1486, val mf1: 0.6747, (best 0.8542)
Epoch 89, loss: 1.2761, val mf1: 0.7191, (best 0.8542)
Epoch 90, loss: 1.4020, val mf1: 0.6982, (best 0.8542)
Epoch 91, loss: 1.4453, val mf1: 0.6564, (best 0.8542)
Epoch 92, loss: 1.3421, val mf1: 0.7050, (best 0.8542)
Epoch 93, loss: 1.2607, val mf1: 0.7472, (best 0.8542)
Epoch 94, loss: 1.1912, val mf1: 0.7019, (best 0.8542)
Epoch 95, loss: 1.1166, val mf1: 0.7995, (best 0.8542)
Epoch 96, loss: 0.9185, val mf1: 0.7843, (best 0.8542)
Epoch 97, loss: 1.0251, val mf1: 0.6484, (best 0.8542)
Epoch 98, loss: 1.3041, val mf1: 0.8219, (best 0.8542)
Epoch 99, loss: 1.6882, val mf1: 0.8131, (best 0.8542)
time cost:  22.79398488998413 s
Test: REC 61.79 PRE 85.33 MF1 85.26 AUC 90.71
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 33.6320, val mf1: 0.6067, (best 0.6067)
Epoch 1, loss: 237.5887, val mf1: 0.1941, (best 0.6067)
Epoch 2, loss: 43.7297, val mf1: 0.4994, (best 0.6067)
Epoch 3, loss: 58.5802, val mf1: 0.5126, (best 0.6067)
Epoch 4, loss: 59.9377, val mf1: 0.8547, (best 0.8547)
Epoch 5, loss: 64.8166, val mf1: 0.7524, (best 0.8547)
Epoch 6, loss: 67.0425, val mf1: 0.6886, (best 0.8547)
Epoch 7, loss: 67.2994, val mf1: 0.6374, (best 0.8547)
Epoch 8, loss: 65.7016, val mf1: 0.6063, (best 0.8547)
Epoch 9, loss: 62.1166, val mf1: 0.5882, (best 0.8547)
Epoch 10, loss: 56.7060, val mf1: 0.5815, (best 0.8547)
Epoch 11, loss: 49.7491, val mf1: 0.5782, (best 0.8547)
Epoch 12, loss: 41.6426, val mf1: 0.5808, (best 0.8547)
Epoch 13, loss: 32.8679, val mf1: 0.5889, (best 0.8547)
Epoch 14, loss: 23.7663, val mf1: 0.6019, (best 0.8547)
Epoch 15, loss: 14.8872, val mf1: 0.5963, (best 0.8547)
Epoch 16, loss: 22.8295, val mf1: 0.5092, (best 0.8547)
Epoch 17, loss: 15.4264, val mf1: 0.5943, (best 0.8547)
Epoch 18, loss: 16.8644, val mf1: 0.7217, (best 0.8547)
Epoch 19, loss: 21.0354, val mf1: 0.6091, (best 0.8547)
Epoch 20, loss: 18.3780, val mf1: 0.6895, (best 0.8547)
Epoch 21, loss: 12.7067, val mf1: 0.8591, (best 0.8591)
Epoch 22, loss: 7.7752, val mf1: 0.7244, (best 0.8591)
Epoch 23, loss: 8.3101, val mf1: 0.5249, (best 0.8591)
Epoch 24, loss: 12.4992, val mf1: 0.4106, (best 0.8591)
Epoch 25, loss: 8.9349, val mf1: 0.4602, (best 0.8591)
Epoch 26, loss: 6.8785, val mf1: 0.6083, (best 0.8591)
Epoch 27, loss: 8.2330, val mf1: 0.7230, (best 0.8591)
Epoch 28, loss: 9.1124, val mf1: 0.7514, (best 0.8591)
Epoch 29, loss: 8.8379, val mf1: 0.7658, (best 0.8591)
Epoch 30, loss: 7.5081, val mf1: 0.7639, (best 0.8591)
Epoch 31, loss: 5.5458, val mf1: 0.7432, (best 0.8591)
Epoch 32, loss: 4.2231, val mf1: 0.5832, (best 0.8591)
Epoch 33, loss: 7.1700, val mf1: 0.4143, (best 0.8591)
Epoch 34, loss: 2.7856, val mf1: 0.6488, (best 0.8591)
Epoch 35, loss: 3.9395, val mf1: 0.8216, (best 0.8591)
Epoch 36, loss: 4.4895, val mf1: 0.8393, (best 0.8591)
Epoch 37, loss: 3.7427, val mf1: 0.7892, (best 0.8591)
Epoch 38, loss: 3.7999, val mf1: 0.6107, (best 0.8591)
Epoch 39, loss: 3.5758, val mf1: 0.6092, (best 0.8591)
Epoch 40, loss: 3.0079, val mf1: 0.7956, (best 0.8591)
Epoch 41, loss: 3.0522, val mf1: 0.8170, (best 0.8591)
Epoch 42, loss: 2.0916, val mf1: 0.7541, (best 0.8591)
Epoch 43, loss: 3.1047, val mf1: 0.5094, (best 0.8591)
Epoch 44, loss: 2.0572, val mf1: 0.6789, (best 0.8591)
Epoch 45, loss: 2.5252, val mf1: 0.7362, (best 0.8591)
Epoch 46, loss: 2.3458, val mf1: 0.7334, (best 0.8591)
Epoch 47, loss: 1.5795, val mf1: 0.6648, (best 0.8591)
Epoch 48, loss: 2.8100, val mf1: 0.5031, (best 0.8591)
Epoch 49, loss: 2.7393, val mf1: 0.8079, (best 0.8591)
Epoch 50, loss: 4.3091, val mf1: 0.8439, (best 0.8591)
Epoch 51, loss: 4.5111, val mf1: 0.8558, (best 0.8591)
Epoch 52, loss: 3.3518, val mf1: 0.8519, (best 0.8591)
Epoch 53, loss: 1.4961, val mf1: 0.6786, (best 0.8591)
Epoch 54, loss: 7.3277, val mf1: 0.4773, (best 0.8591)
Epoch 55, loss: 4.5088, val mf1: 0.8440, (best 0.8591)
Epoch 56, loss: 8.1400, val mf1: 0.8573, (best 0.8591)
Epoch 57, loss: 10.2149, val mf1: 0.8582, (best 0.8591)
Epoch 58, loss: 10.8890, val mf1: 0.8436, (best 0.8591)
Epoch 59, loss: 10.5015, val mf1: 0.7924, (best 0.8591)
Epoch 60, loss: 9.9428, val mf1: 0.6332, (best 0.8591)
Epoch 61, loss: 9.9740, val mf1: 0.5322, (best 0.8591)
Epoch 62, loss: 10.0293, val mf1: 0.4790, (best 0.8591)
Epoch 63, loss: 9.0815, val mf1: 0.4629, (best 0.8591)
Epoch 64, loss: 6.8366, val mf1: 0.4803, (best 0.8591)
Epoch 65, loss: 4.5417, val mf1: 0.7553, (best 0.8591)
Epoch 66, loss: 3.7556, val mf1: 0.8372, (best 0.8591)
Epoch 67, loss: 2.2870, val mf1: 0.6483, (best 0.8591)
Epoch 68, loss: 5.8042, val mf1: 0.3984, (best 0.8591)
Epoch 69, loss: 2.8676, val mf1: 0.5873, (best 0.8591)
Epoch 70, loss: 3.8738, val mf1: 0.7725, (best 0.8591)
Epoch 71, loss: 3.3766, val mf1: 0.8384, (best 0.8591)
Epoch 72, loss: 2.1655, val mf1: 0.8254, (best 0.8591)
Epoch 73, loss: 1.9246, val mf1: 0.5784, (best 0.8591)
Epoch 74, loss: 2.6953, val mf1: 0.5181, (best 0.8591)
Epoch 75, loss: 1.8166, val mf1: 0.7209, (best 0.8591)
Epoch 76, loss: 2.6498, val mf1: 0.7321, (best 0.8591)
Epoch 77, loss: 2.8535, val mf1: 0.7248, (best 0.8591)
Epoch 78, loss: 2.4634, val mf1: 0.7048, (best 0.8591)
Epoch 79, loss: 1.8951, val mf1: 0.6481, (best 0.8591)
Epoch 80, loss: 3.4503, val mf1: 0.4829, (best 0.8591)
Epoch 81, loss: 3.4386, val mf1: 0.7731, (best 0.8591)
Epoch 82, loss: 5.7401, val mf1: 0.8165, (best 0.8591)
Epoch 83, loss: 7.0570, val mf1: 0.8333, (best 0.8591)
Epoch 84, loss: 7.3163, val mf1: 0.8380, (best 0.8591)
Epoch 85, loss: 6.5967, val mf1: 0.8352, (best 0.8591)
Epoch 86, loss: 5.0521, val mf1: 0.8185, (best 0.8591)
Epoch 87, loss: 2.9298, val mf1: 0.7808, (best 0.8591)
Epoch 88, loss: 5.7002, val mf1: 0.5186, (best 0.8591)
Epoch 89, loss: 3.0567, val mf1: 0.5668, (best 0.8591)
Epoch 90, loss: 2.8043, val mf1: 0.7179, (best 0.8591)
Epoch 91, loss: 3.5619, val mf1: 0.7584, (best 0.8591)
Epoch 92, loss: 3.7344, val mf1: 0.7605, (best 0.8591)
Epoch 93, loss: 3.3328, val mf1: 0.7406, (best 0.8591)
Epoch 94, loss: 2.6970, val mf1: 0.6560, (best 0.8591)
Epoch 95, loss: 2.6101, val mf1: 0.5350, (best 0.8591)
Epoch 96, loss: 2.3487, val mf1: 0.5306, (best 0.8591)
Epoch 97, loss: 1.6087, val mf1: 0.6882, (best 0.8591)
Epoch 98, loss: 1.8617, val mf1: 0.7973, (best 0.8591)
Epoch 99, loss: 1.7496, val mf1: 0.7363, (best 0.8591)
time cost:  25.928385496139526 s
Test: REC 61.93 PRE 86.51 MF1 85.52 AUC 92.13
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 31.4570, val mf1: 0.4619, (best 0.4619)
Epoch 1, loss: 75.5259, val mf1: 0.3594, (best 0.4619)
Epoch 2, loss: 59.2521, val mf1: 0.5761, (best 0.5761)
Epoch 3, loss: 80.0181, val mf1: 0.8264, (best 0.8264)
Epoch 4, loss: 90.8779, val mf1: 0.7549, (best 0.8264)
Epoch 5, loss: 93.0475, val mf1: 0.7112, (best 0.8264)
Epoch 6, loss: 89.6505, val mf1: 0.6716, (best 0.8264)
Epoch 7, loss: 82.5310, val mf1: 0.6437, (best 0.8264)
Epoch 8, loss: 72.7259, val mf1: 0.6292, (best 0.8264)
Epoch 9, loss: 61.2595, val mf1: 0.6168, (best 0.8264)
Epoch 10, loss: 49.0879, val mf1: 0.6102, (best 0.8264)
Epoch 11, loss: 36.5893, val mf1: 0.6062, (best 0.8264)
Epoch 12, loss: 24.4123, val mf1: 0.6003, (best 0.8264)
Epoch 13, loss: 13.4675, val mf1: 0.5765, (best 0.8264)
Epoch 14, loss: 20.5960, val mf1: 0.4430, (best 0.8264)
Epoch 15, loss: 16.2920, val mf1: 0.5042, (best 0.8264)
Epoch 16, loss: 11.3681, val mf1: 0.6679, (best 0.8264)
Epoch 17, loss: 16.5170, val mf1: 0.6063, (best 0.8264)
Epoch 18, loss: 16.2091, val mf1: 0.6607, (best 0.8264)
Epoch 19, loss: 12.3070, val mf1: 0.8516, (best 0.8516)
Epoch 20, loss: 8.9087, val mf1: 0.8221, (best 0.8516)
Epoch 21, loss: 6.3650, val mf1: 0.6082, (best 0.8516)
Epoch 22, loss: 7.7083, val mf1: 0.4352, (best 0.8516)
Epoch 23, loss: 10.5888, val mf1: 0.3116, (best 0.8516)
Epoch 24, loss: 5.7743, val mf1: 0.4422, (best 0.8516)
Epoch 25, loss: 3.4036, val mf1: 0.6703, (best 0.8516)
Epoch 26, loss: 4.3113, val mf1: 0.7774, (best 0.8516)
Epoch 27, loss: 4.5187, val mf1: 0.8098, (best 0.8516)
Epoch 28, loss: 3.6637, val mf1: 0.8070, (best 0.8516)
Epoch 29, loss: 14.2036, val mf1: 0.5071, (best 0.8516)
Epoch 30, loss: 9.6362, val mf1: 0.8492, (best 0.8516)
Epoch 31, loss: 15.8096, val mf1: 0.8564, (best 0.8564)
Epoch 32, loss: 20.3599, val mf1: 0.8577, (best 0.8577)
Epoch 33, loss: 23.3813, val mf1: 0.8564, (best 0.8577)
Epoch 34, loss: 25.0284, val mf1: 0.8542, (best 0.8577)
Epoch 35, loss: 25.4959, val mf1: 0.8467, (best 0.8577)
Epoch 36, loss: 24.9586, val mf1: 0.8329, (best 0.8577)
Epoch 37, loss: 23.6523, val mf1: 0.8122, (best 0.8577)
Epoch 38, loss: 21.8221, val mf1: 0.7888, (best 0.8577)
Epoch 39, loss: 19.6602, val mf1: 0.7508, (best 0.8577)
Epoch 40, loss: 17.3042, val mf1: 0.7192, (best 0.8577)
Epoch 41, loss: 14.8716, val mf1: 0.6790, (best 0.8577)
Epoch 42, loss: 12.4033, val mf1: 0.6401, (best 0.8577)
Epoch 43, loss: 10.1358, val mf1: 0.5825, (best 0.8577)
Epoch 44, loss: 8.4623, val mf1: 0.5208, (best 0.8577)
Epoch 45, loss: 8.4510, val mf1: 0.4500, (best 0.8577)
Epoch 46, loss: 11.6406, val mf1: 0.3888, (best 0.8577)
Epoch 47, loss: 8.0668, val mf1: 0.4422, (best 0.8577)
Epoch 48, loss: 5.1117, val mf1: 0.5391, (best 0.8577)
Epoch 49, loss: 5.1913, val mf1: 0.6624, (best 0.8577)
Epoch 50, loss: 6.3337, val mf1: 0.8018, (best 0.8577)
Epoch 51, loss: 6.9216, val mf1: 0.8386, (best 0.8577)
Epoch 52, loss: 6.7003, val mf1: 0.8318, (best 0.8577)
Epoch 53, loss: 5.8680, val mf1: 0.7960, (best 0.8577)
Epoch 54, loss: 4.7626, val mf1: 0.6976, (best 0.8577)
Epoch 55, loss: 3.9674, val mf1: 0.6066, (best 0.8577)
Epoch 56, loss: 4.1413, val mf1: 0.5441, (best 0.8577)
Epoch 57, loss: 4.5814, val mf1: 0.5161, (best 0.8577)
Epoch 58, loss: 3.9464, val mf1: 0.5266, (best 0.8577)
Epoch 59, loss: 3.0305, val mf1: 0.5714, (best 0.8577)
Epoch 60, loss: 2.8859, val mf1: 0.6544, (best 0.8577)
Epoch 61, loss: 3.0805, val mf1: 0.7635, (best 0.8577)
Epoch 62, loss: 2.9926, val mf1: 0.7715, (best 0.8577)
Epoch 63, loss: 2.5633, val mf1: 0.7296, (best 0.8577)
Epoch 64, loss: 2.1218, val mf1: 0.6382, (best 0.8577)
Epoch 65, loss: 2.1655, val mf1: 0.5593, (best 0.8577)
Epoch 66, loss: 2.3140, val mf1: 0.5298, (best 0.8577)
Epoch 67, loss: 1.6890, val mf1: 0.5926, (best 0.8577)
Epoch 68, loss: 1.5506, val mf1: 0.7181, (best 0.8577)
Epoch 69, loss: 1.6484, val mf1: 0.7499, (best 0.8577)
Epoch 70, loss: 1.4891, val mf1: 0.7678, (best 0.8577)
Epoch 71, loss: 1.0846, val mf1: 0.7537, (best 0.8577)
Epoch 72, loss: 2.3533, val mf1: 0.5471, (best 0.8577)
Epoch 73, loss: 1.4305, val mf1: 0.8079, (best 0.8577)
Epoch 74, loss: 2.0146, val mf1: 0.8317, (best 0.8577)
Epoch 75, loss: 2.1533, val mf1: 0.8311, (best 0.8577)
Epoch 76, loss: 1.9162, val mf1: 0.7974, (best 0.8577)
Epoch 77, loss: 1.5792, val mf1: 0.6674, (best 0.8577)
Epoch 78, loss: 1.4695, val mf1: 0.5397, (best 0.8577)
Epoch 79, loss: 1.7472, val mf1: 0.4785, (best 0.8577)
Epoch 80, loss: 1.0314, val mf1: 0.7408, (best 0.8577)
Epoch 81, loss: 1.5103, val mf1: 0.8407, (best 0.8577)
Epoch 82, loss: 1.6207, val mf1: 0.8410, (best 0.8577)
Epoch 83, loss: 1.2896, val mf1: 0.8296, (best 0.8577)
Epoch 84, loss: 1.6089, val mf1: 0.5899, (best 0.8577)
Epoch 85, loss: 1.4534, val mf1: 0.8553, (best 0.8577)
Epoch 86, loss: 1.8738, val mf1: 0.8467, (best 0.8577)
Epoch 87, loss: 1.9336, val mf1: 0.7600, (best 0.8577)
Epoch 88, loss: 1.7658, val mf1: 0.6811, (best 0.8577)
Epoch 89, loss: 1.4286, val mf1: 0.6179, (best 0.8577)
Epoch 90, loss: 1.0103, val mf1: 0.5828, (best 0.8577)
Epoch 91, loss: 3.1814, val mf1: 0.4132, (best 0.8577)
Epoch 92, loss: 2.1822, val mf1: 0.7768, (best 0.8577)
Epoch 93, loss: 4.1184, val mf1: 0.8571, (best 0.8577)
Epoch 94, loss: 5.5498, val mf1: 0.8582, (best 0.8582)
Epoch 95, loss: 6.4282, val mf1: 0.8584, (best 0.8584)
Epoch 96, loss: 6.7808, val mf1: 0.8580, (best 0.8584)
Epoch 97, loss: 6.6635, val mf1: 0.8590, (best 0.8590)
Epoch 98, loss: 6.1591, val mf1: 0.8514, (best 0.8590)
Epoch 99, loss: 5.3409, val mf1: 0.8323, (best 0.8590)
time cost:  26.057142972946167 s
Test: REC 65.10 PRE 83.25 MF1 85.96 AUC 90.71
MF1-mean: 85.58, MF1-std: 0.29, AUC-mean: 91.18, AUC-std: 0.67
