Using device: cuda
Namespace(dataset='tfinance', train_ratio=0.4, hid_dim=128, num_layers=3, epoch=100, run=3, knn_reconstruct_graph=True, knn_reconstruct_graph_approximate=False, alpha=0.6, top_k=5, save_model=False, model_path='./model', device=device(type='cuda', index=0), choose_model='GCN', hyperparameter_tuning=False)
Graph(num_nodes=39357, num_edges=298512,
      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'feature': Scheme(shape=(10,), dtype=torch.float32)}
      edata_schemes={})
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 16.8197, val mf1: 0.4821, (best 0.4821)
Epoch 1, loss: 44.3953, val mf1: 0.7191, (best 0.7191)
Epoch 2, loss: 54.2218, val mf1: 0.6176, (best 0.7191)
Epoch 3, loss: 53.4669, val mf1: 0.5798, (best 0.7191)
Epoch 4, loss: 45.3928, val mf1: 0.5562, (best 0.7191)
Epoch 5, loss: 33.5321, val mf1: 0.5254, (best 0.7191)
Epoch 6, loss: 20.9120, val mf1: 0.5306, (best 0.7191)
Epoch 7, loss: 19.7768, val mf1: 0.6966, (best 0.7191)
Epoch 8, loss: 7.8941, val mf1: 0.5547, (best 0.7191)
Epoch 9, loss: 5.8757, val mf1: 0.8391, (best 0.8391)
Epoch 10, loss: 16.9452, val mf1: 0.4546, (best 0.8391)
Epoch 11, loss: 14.3804, val mf1: 0.8560, (best 0.8560)
Epoch 12, loss: 23.2605, val mf1: 0.8480, (best 0.8560)
Epoch 13, loss: 26.8453, val mf1: 0.8570, (best 0.8570)
Epoch 14, loss: 26.6115, val mf1: 0.8329, (best 0.8570)
Epoch 15, loss: 23.8636, val mf1: 0.7765, (best 0.8570)
Epoch 16, loss: 20.5234, val mf1: 0.6686, (best 0.8570)
Epoch 17, loss: 18.6490, val mf1: 0.5654, (best 0.8570)
Epoch 18, loss: 18.6461, val mf1: 0.5012, (best 0.8570)
Epoch 19, loss: 19.7075, val mf1: 0.4432, (best 0.8570)
Epoch 20, loss: 18.2420, val mf1: 0.4304, (best 0.8570)
Epoch 21, loss: 11.6766, val mf1: 0.5136, (best 0.8570)
Epoch 22, loss: 9.5775, val mf1: 0.6647, (best 0.8570)
Epoch 23, loss: 10.5622, val mf1: 0.8089, (best 0.8570)
Epoch 24, loss: 10.3647, val mf1: 0.8415, (best 0.8570)
Epoch 25, loss: 8.1313, val mf1: 0.8507, (best 0.8570)
Epoch 26, loss: 15.4864, val mf1: 0.5548, (best 0.8570)
Epoch 27, loss: 8.1222, val mf1: 0.6146, (best 0.8570)
Epoch 28, loss: 12.0280, val mf1: 0.8191, (best 0.8570)
Epoch 29, loss: 13.4746, val mf1: 0.8454, (best 0.8570)
Epoch 30, loss: 12.6926, val mf1: 0.8588, (best 0.8588)
Epoch 31, loss: 10.3825, val mf1: 0.8375, (best 0.8588)
Epoch 32, loss: 7.0006, val mf1: 0.7866, (best 0.8588)
Epoch 33, loss: 3.6947, val mf1: 0.6487, (best 0.8588)
Epoch 34, loss: 19.7674, val mf1: 0.3204, (best 0.8588)
Epoch 35, loss: 4.9889, val mf1: 0.6157, (best 0.8588)
Epoch 36, loss: 8.0735, val mf1: 0.7116, (best 0.8588)
Epoch 37, loss: 10.3993, val mf1: 0.7381, (best 0.8588)
Epoch 38, loss: 11.5625, val mf1: 0.7536, (best 0.8588)
Epoch 39, loss: 11.5706, val mf1: 0.7551, (best 0.8588)
Epoch 40, loss: 10.5463, val mf1: 0.7489, (best 0.8588)
Epoch 41, loss: 8.6645, val mf1: 0.7306, (best 0.8588)
Epoch 42, loss: 6.2550, val mf1: 0.6755, (best 0.8588)
Epoch 43, loss: 5.2073, val mf1: 0.4938, (best 0.8588)
Epoch 44, loss: 7.6913, val mf1: 0.2861, (best 0.8588)
Epoch 45, loss: 3.3302, val mf1: 0.4685, (best 0.8588)
Epoch 46, loss: 3.2926, val mf1: 0.8113, (best 0.8588)
Epoch 47, loss: 4.5236, val mf1: 0.8493, (best 0.8588)
Epoch 48, loss: 4.4992, val mf1: 0.8506, (best 0.8588)
Epoch 49, loss: 3.2372, val mf1: 0.7954, (best 0.8588)
Epoch 50, loss: 8.1965, val mf1: 0.4666, (best 0.8588)
Epoch 51, loss: 5.4241, val mf1: 0.8326, (best 0.8588)
Epoch 52, loss: 8.3469, val mf1: 0.8410, (best 0.8588)
Epoch 53, loss: 9.5838, val mf1: 0.8455, (best 0.8588)
Epoch 54, loss: 9.4343, val mf1: 0.8517, (best 0.8588)
Epoch 55, loss: 8.2007, val mf1: 0.8566, (best 0.8588)
Epoch 56, loss: 6.0966, val mf1: 0.8444, (best 0.8588)
Epoch 57, loss: 3.3848, val mf1: 0.7957, (best 0.8588)
Epoch 58, loss: 3.1280, val mf1: 0.4558, (best 0.8588)
Epoch 59, loss: 5.3820, val mf1: 0.3716, (best 0.8588)
Epoch 60, loss: 3.5765, val mf1: 0.7144, (best 0.8588)
Epoch 61, loss: 5.9460, val mf1: 0.7581, (best 0.8588)
Epoch 62, loss: 7.4637, val mf1: 0.7855, (best 0.8588)
Epoch 63, loss: 8.0588, val mf1: 0.7931, (best 0.8588)
Epoch 64, loss: 7.8026, val mf1: 0.7892, (best 0.8588)
Epoch 65, loss: 6.8178, val mf1: 0.7633, (best 0.8588)
Epoch 66, loss: 5.2988, val mf1: 0.7228, (best 0.8588)
Epoch 67, loss: 3.6275, val mf1: 0.6291, (best 0.8588)
Epoch 68, loss: 3.3222, val mf1: 0.4412, (best 0.8588)
Epoch 69, loss: 5.7579, val mf1: 0.2444, (best 0.8588)
Epoch 70, loss: 1.9033, val mf1: 0.7614, (best 0.8588)
Epoch 71, loss: 3.4079, val mf1: 0.8446, (best 0.8588)
Epoch 72, loss: 4.1893, val mf1: 0.8570, (best 0.8588)
Epoch 73, loss: 4.0621, val mf1: 0.8544, (best 0.8588)
Epoch 74, loss: 3.0841, val mf1: 0.8434, (best 0.8588)
Epoch 75, loss: 1.4753, val mf1: 0.7076, (best 0.8588)
Epoch 76, loss: 10.0607, val mf1: 0.4356, (best 0.8588)
Epoch 77, loss: 3.6105, val mf1: 0.8503, (best 0.8588)
Epoch 78, loss: 6.5822, val mf1: 0.8522, (best 0.8588)
Epoch 79, loss: 8.4190, val mf1: 0.8551, (best 0.8588)
Epoch 80, loss: 9.2447, val mf1: 0.8578, (best 0.8588)
Epoch 81, loss: 9.2001, val mf1: 0.8601, (best 0.8601)
Epoch 82, loss: 8.4305, val mf1: 0.8538, (best 0.8601)
Epoch 83, loss: 7.1392, val mf1: 0.8055, (best 0.8601)
Epoch 84, loss: 5.6913, val mf1: 0.7110, (best 0.8601)
Epoch 85, loss: 4.3649, val mf1: 0.6224, (best 0.8601)
Epoch 86, loss: 3.6682, val mf1: 0.5258, (best 0.8601)
Epoch 87, loss: 5.7997, val mf1: 0.3796, (best 0.8601)
Epoch 88, loss: 5.7288, val mf1: 0.3724, (best 0.8601)
Epoch 89, loss: 2.6569, val mf1: 0.5441, (best 0.8601)
Epoch 90, loss: 2.9306, val mf1: 0.6797, (best 0.8601)
Epoch 91, loss: 3.5477, val mf1: 0.7784, (best 0.8601)
Epoch 92, loss: 3.8436, val mf1: 0.8345, (best 0.8601)
Epoch 93, loss: 3.6146, val mf1: 0.8481, (best 0.8601)
Epoch 94, loss: 2.8211, val mf1: 0.8508, (best 0.8601)
Epoch 95, loss: 1.5410, val mf1: 0.8131, (best 0.8601)
Epoch 96, loss: 4.2474, val mf1: 0.4956, (best 0.8601)
Epoch 97, loss: 1.3317, val mf1: 0.7981, (best 0.8601)
Epoch 98, loss: 2.1224, val mf1: 0.8435, (best 0.8601)
Epoch 99, loss: 2.2864, val mf1: 0.8504, (best 0.8601)
time cost:  27.928210973739624 s
Test: REC 63.31 PRE 84.84 MF1 85.68 AUC 91.07
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 9.0300, val mf1: 0.6035, (best 0.6035)
Epoch 1, loss: 843.0772, val mf1: 0.0438, (best 0.6035)
Epoch 2, loss: 234.4157, val mf1: 0.0446, (best 0.6035)
Epoch 3, loss: 25.8292, val mf1: 0.7155, (best 0.7155)
Epoch 4, loss: 53.5271, val mf1: 0.7500, (best 0.7500)
Epoch 5, loss: 75.5151, val mf1: 0.5651, (best 0.7500)
Epoch 6, loss: 87.0909, val mf1: 0.5722, (best 0.7500)
Epoch 7, loss: 90.8647, val mf1: 0.7222, (best 0.7500)
Epoch 8, loss: 92.1663, val mf1: 0.8512, (best 0.8512)
Epoch 9, loss: 92.5514, val mf1: 0.8155, (best 0.8512)
Epoch 10, loss: 91.6766, val mf1: 0.7756, (best 0.8512)
Epoch 11, loss: 90.0040, val mf1: 0.7443, (best 0.8512)
Epoch 12, loss: 87.6335, val mf1: 0.7137, (best 0.8512)
Epoch 13, loss: 84.7584, val mf1: 0.6820, (best 0.8512)
Epoch 14, loss: 81.4706, val mf1: 0.6651, (best 0.8512)
Epoch 15, loss: 77.6854, val mf1: 0.6453, (best 0.8512)
Epoch 16, loss: 73.4228, val mf1: 0.6299, (best 0.8512)
Epoch 17, loss: 68.5898, val mf1: 0.6178, (best 0.8512)
Epoch 18, loss: 63.3636, val mf1: 0.6108, (best 0.8512)
Epoch 19, loss: 57.8061, val mf1: 0.6047, (best 0.8512)
Epoch 20, loss: 51.9867, val mf1: 0.5993, (best 0.8512)
Epoch 21, loss: 45.9634, val mf1: 0.5956, (best 0.8512)
Epoch 22, loss: 39.8082, val mf1: 0.5942, (best 0.8512)
Epoch 23, loss: 33.5674, val mf1: 0.5924, (best 0.8512)
Epoch 24, loss: 27.3589, val mf1: 0.5886, (best 0.8512)
Epoch 25, loss: 21.2383, val mf1: 0.5843, (best 0.8512)
Epoch 26, loss: 15.3477, val mf1: 0.5967, (best 0.8512)
Epoch 27, loss: 10.0962, val mf1: 0.6048, (best 0.8512)
Epoch 28, loss: 6.9270, val mf1: 0.5242, (best 0.8512)
Epoch 29, loss: 8.4880, val mf1: 0.4283, (best 0.8512)
Epoch 30, loss: 12.0882, val mf1: 0.3975, (best 0.8512)
Epoch 31, loss: 9.6570, val mf1: 0.4936, (best 0.8512)
Epoch 32, loss: 11.3650, val mf1: 0.5610, (best 0.8512)
Epoch 33, loss: 10.2850, val mf1: 0.6327, (best 0.8512)
Epoch 34, loss: 7.2499, val mf1: 0.7805, (best 0.8512)
Epoch 35, loss: 4.9343, val mf1: 0.7385, (best 0.8512)
Epoch 36, loss: 3.7202, val mf1: 0.5557, (best 0.8512)
Epoch 37, loss: 5.9963, val mf1: 0.4482, (best 0.8512)
Epoch 38, loss: 3.4292, val mf1: 0.5467, (best 0.8512)
Epoch 39, loss: 3.6440, val mf1: 0.6747, (best 0.8512)
Epoch 40, loss: 4.5164, val mf1: 0.7675, (best 0.8512)
Epoch 41, loss: 4.9571, val mf1: 0.7537, (best 0.8512)
Epoch 42, loss: 4.8810, val mf1: 0.7316, (best 0.8512)
Epoch 43, loss: 4.4723, val mf1: 0.6874, (best 0.8512)
Epoch 44, loss: 4.2112, val mf1: 0.5732, (best 0.8512)
Epoch 45, loss: 4.2210, val mf1: 0.5035, (best 0.8512)
Epoch 46, loss: 3.7295, val mf1: 0.5058, (best 0.8512)
Epoch 47, loss: 2.7472, val mf1: 0.5960, (best 0.8512)
Epoch 48, loss: 2.2954, val mf1: 0.7303, (best 0.8512)
Epoch 49, loss: 1.9730, val mf1: 0.7629, (best 0.8512)
Epoch 50, loss: 2.4449, val mf1: 0.5888, (best 0.8512)
Epoch 51, loss: 2.6438, val mf1: 0.8025, (best 0.8512)
Epoch 52, loss: 3.3361, val mf1: 0.8126, (best 0.8512)
Epoch 53, loss: 3.3541, val mf1: 0.8165, (best 0.8512)
Epoch 54, loss: 2.7465, val mf1: 0.8180, (best 0.8512)
Epoch 55, loss: 4.8147, val mf1: 0.5587, (best 0.8512)
Epoch 56, loss: 4.1795, val mf1: 0.8276, (best 0.8512)
Epoch 57, loss: 5.9835, val mf1: 0.8332, (best 0.8512)
Epoch 58, loss: 7.0409, val mf1: 0.8368, (best 0.8512)
Epoch 59, loss: 7.4294, val mf1: 0.8380, (best 0.8512)
Epoch 60, loss: 7.2335, val mf1: 0.8336, (best 0.8512)
Epoch 61, loss: 6.5261, val mf1: 0.8296, (best 0.8512)
Epoch 62, loss: 5.3860, val mf1: 0.8228, (best 0.8512)
Epoch 63, loss: 3.9171, val mf1: 0.7928, (best 0.8512)
Epoch 64, loss: 2.5201, val mf1: 0.6885, (best 0.8512)
Epoch 65, loss: 5.3104, val mf1: 0.4321, (best 0.8512)
Epoch 66, loss: 3.8385, val mf1: 0.4522, (best 0.8512)
Epoch 67, loss: 2.7775, val mf1: 0.5872, (best 0.8512)
Epoch 68, loss: 3.1468, val mf1: 0.7338, (best 0.8512)
Epoch 69, loss: 3.6358, val mf1: 0.7849, (best 0.8512)
Epoch 70, loss: 3.8081, val mf1: 0.8099, (best 0.8512)
Epoch 71, loss: 3.5831, val mf1: 0.8199, (best 0.8512)
Epoch 72, loss: 2.9773, val mf1: 0.8160, (best 0.8512)
Epoch 73, loss: 2.2336, val mf1: 0.7169, (best 0.8512)
Epoch 74, loss: 2.2692, val mf1: 0.5404, (best 0.8512)
Epoch 75, loss: 2.7726, val mf1: 0.4818, (best 0.8512)
Epoch 76, loss: 2.1660, val mf1: 0.5318, (best 0.8512)
Epoch 77, loss: 1.7648, val mf1: 0.6574, (best 0.8512)
Epoch 78, loss: 2.0800, val mf1: 0.8324, (best 0.8512)
Epoch 79, loss: 2.2151, val mf1: 0.8408, (best 0.8512)
Epoch 80, loss: 1.9033, val mf1: 0.8318, (best 0.8512)
Epoch 81, loss: 1.5314, val mf1: 0.6485, (best 0.8512)
Epoch 82, loss: 1.8898, val mf1: 0.5639, (best 0.8512)
Epoch 83, loss: 1.3106, val mf1: 0.6409, (best 0.8512)
Epoch 84, loss: 1.3682, val mf1: 0.8288, (best 0.8512)
Epoch 85, loss: 1.3747, val mf1: 0.8242, (best 0.8512)
Epoch 86, loss: 1.0470, val mf1: 0.7872, (best 0.8512)
Epoch 87, loss: 1.0683, val mf1: 0.5988, (best 0.8512)
Epoch 88, loss: 0.9330, val mf1: 0.6334, (best 0.8512)
Epoch 89, loss: 0.9147, val mf1: 0.7645, (best 0.8512)
Epoch 90, loss: 0.9614, val mf1: 0.7970, (best 0.8512)
Epoch 91, loss: 0.7563, val mf1: 0.7929, (best 0.8512)
Epoch 92, loss: 1.0058, val mf1: 0.5988, (best 0.8512)
Epoch 93, loss: 0.9970, val mf1: 0.8185, (best 0.8512)
Epoch 94, loss: 1.3154, val mf1: 0.8332, (best 0.8512)
Epoch 95, loss: 1.2135, val mf1: 0.8288, (best 0.8512)
Epoch 96, loss: 0.7655, val mf1: 0.8065, (best 0.8512)
Epoch 97, loss: 2.8524, val mf1: 0.4909, (best 0.8512)
Epoch 98, loss: 2.6526, val mf1: 0.8504, (best 0.8512)
Epoch 99, loss: 4.7751, val mf1: 0.8561, (best 0.8561)
time cost:  26.566741943359375 s
Test: REC 61.66 PRE 85.63 MF1 85.27 AUC 90.82
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 14.3454, val mf1: 0.5074, (best 0.5074)
Epoch 1, loss: 794.3279, val mf1: 0.0438, (best 0.5074)
Epoch 2, loss: 224.6413, val mf1: 0.0445, (best 0.5074)
Epoch 3, loss: 22.0585, val mf1: 0.7343, (best 0.7343)
Epoch 4, loss: 47.2121, val mf1: 0.8419, (best 0.8419)
Epoch 5, loss: 69.8569, val mf1: 0.5606, (best 0.8419)
Epoch 6, loss: 80.1310, val mf1: 0.5766, (best 0.8419)
Epoch 7, loss: 83.2628, val mf1: 0.8425, (best 0.8425)
Epoch 8, loss: 86.2175, val mf1: 0.8449, (best 0.8449)
Epoch 9, loss: 87.3159, val mf1: 0.8185, (best 0.8449)
Epoch 10, loss: 86.9987, val mf1: 0.7887, (best 0.8449)
Epoch 11, loss: 85.6215, val mf1: 0.7579, (best 0.8449)
Epoch 12, loss: 83.3367, val mf1: 0.7349, (best 0.8449)
Epoch 13, loss: 80.2742, val mf1: 0.7162, (best 0.8449)
Epoch 14, loss: 76.4535, val mf1: 0.6908, (best 0.8449)
Epoch 15, loss: 71.9399, val mf1: 0.6654, (best 0.8449)
Epoch 16, loss: 66.7886, val mf1: 0.6455, (best 0.8449)
Epoch 17, loss: 60.8765, val mf1: 0.6279, (best 0.8449)
Epoch 18, loss: 54.1219, val mf1: 0.6015, (best 0.8449)
Epoch 19, loss: 46.8030, val mf1: 0.5839, (best 0.8449)
Epoch 20, loss: 38.6943, val mf1: 0.5687, (best 0.8449)
Epoch 21, loss: 30.2119, val mf1: 0.5447, (best 0.8449)
Epoch 22, loss: 22.6562, val mf1: 0.4920, (best 0.8449)
Epoch 23, loss: 18.0964, val mf1: 0.4340, (best 0.8449)
Epoch 24, loss: 18.7103, val mf1: 0.4053, (best 0.8449)
Epoch 25, loss: 13.2972, val mf1: 0.4790, (best 0.8449)
Epoch 26, loss: 9.0751, val mf1: 0.5842, (best 0.8449)
Epoch 27, loss: 13.6689, val mf1: 0.6227, (best 0.8449)
Epoch 28, loss: 15.7785, val mf1: 0.6047, (best 0.8449)
Epoch 29, loss: 14.2412, val mf1: 0.6793, (best 0.8449)
Epoch 30, loss: 10.3851, val mf1: 0.8308, (best 0.8449)
Epoch 31, loss: 6.8668, val mf1: 0.8353, (best 0.8449)
Epoch 32, loss: 11.6787, val mf1: 0.5368, (best 0.8449)
Epoch 33, loss: 5.0302, val mf1: 0.6185, (best 0.8449)
Epoch 34, loss: 5.9374, val mf1: 0.7944, (best 0.8449)
Epoch 35, loss: 6.9682, val mf1: 0.7590, (best 0.8449)
Epoch 36, loss: 7.2034, val mf1: 0.7324, (best 0.8449)
Epoch 37, loss: 6.7826, val mf1: 0.7130, (best 0.8449)
Epoch 38, loss: 5.8010, val mf1: 0.6816, (best 0.8449)
Epoch 39, loss: 4.9196, val mf1: 0.5893, (best 0.8449)
Epoch 40, loss: 5.6461, val mf1: 0.4754, (best 0.8449)
Epoch 41, loss: 5.2709, val mf1: 0.4761, (best 0.8449)
Epoch 42, loss: 3.7328, val mf1: 0.6383, (best 0.8449)
Epoch 43, loss: 4.5443, val mf1: 0.7151, (best 0.8449)
Epoch 44, loss: 3.9839, val mf1: 0.7339, (best 0.8449)
Epoch 45, loss: 3.1523, val mf1: 0.7467, (best 0.8449)
Epoch 46, loss: 2.4752, val mf1: 0.6479, (best 0.8449)
Epoch 47, loss: 4.9682, val mf1: 0.4911, (best 0.8449)
Epoch 48, loss: 4.3137, val mf1: 0.8098, (best 0.8449)
Epoch 49, loss: 6.6289, val mf1: 0.8269, (best 0.8449)
Epoch 50, loss: 8.0837, val mf1: 0.8337, (best 0.8449)
Epoch 51, loss: 8.7718, val mf1: 0.8385, (best 0.8449)
Epoch 52, loss: 8.8037, val mf1: 0.8385, (best 0.8449)
Epoch 53, loss: 8.2599, val mf1: 0.8305, (best 0.8449)
Epoch 54, loss: 7.2420, val mf1: 0.8024, (best 0.8449)
Epoch 55, loss: 5.8837, val mf1: 0.7512, (best 0.8449)
Epoch 56, loss: 4.3893, val mf1: 0.6864, (best 0.8449)
Epoch 57, loss: 3.8577, val mf1: 0.5263, (best 0.8449)
Epoch 58, loss: 5.2185, val mf1: 0.3969, (best 0.8449)
Epoch 59, loss: 4.4164, val mf1: 0.4165, (best 0.8449)
Epoch 60, loss: 2.2482, val mf1: 0.5494, (best 0.8449)
Epoch 61, loss: 2.1218, val mf1: 0.7441, (best 0.8449)
Epoch 62, loss: 2.6611, val mf1: 0.8312, (best 0.8449)
Epoch 63, loss: 2.7578, val mf1: 0.8449, (best 0.8449)
Epoch 64, loss: 2.3697, val mf1: 0.7247, (best 0.8449)
Epoch 65, loss: 4.9197, val mf1: 0.5563, (best 0.8449)
Epoch 66, loss: 2.6968, val mf1: 0.8091, (best 0.8449)
Epoch 67, loss: 3.2023, val mf1: 0.8399, (best 0.8449)
Epoch 68, loss: 3.1157, val mf1: 0.8465, (best 0.8465)
Epoch 69, loss: 2.5184, val mf1: 0.8431, (best 0.8465)
Epoch 70, loss: 1.8010, val mf1: 0.6441, (best 0.8465)
Epoch 71, loss: 2.8922, val mf1: 0.5451, (best 0.8465)
Epoch 72, loss: 2.0730, val mf1: 0.7571, (best 0.8465)
Epoch 73, loss: 2.7704, val mf1: 0.7395, (best 0.8465)
Epoch 74, loss: 3.0550, val mf1: 0.7172, (best 0.8465)
Epoch 75, loss: 2.9995, val mf1: 0.6925, (best 0.8465)
Epoch 76, loss: 2.6776, val mf1: 0.6543, (best 0.8465)
Epoch 77, loss: 2.2458, val mf1: 0.6134, (best 0.8465)
Epoch 78, loss: 2.4944, val mf1: 0.5058, (best 0.8465)
Epoch 79, loss: 2.6442, val mf1: 0.4777, (best 0.8465)
Epoch 80, loss: 1.5969, val mf1: 0.6139, (best 0.8465)
Epoch 81, loss: 1.6168, val mf1: 0.7250, (best 0.8465)
Epoch 82, loss: 1.7017, val mf1: 0.7848, (best 0.8465)
Epoch 83, loss: 1.4928, val mf1: 0.8085, (best 0.8465)
Epoch 84, loss: 1.2359, val mf1: 0.6057, (best 0.8465)
Epoch 85, loss: 1.9407, val mf1: 0.5425, (best 0.8465)
Epoch 86, loss: 1.9364, val mf1: 0.8375, (best 0.8465)
Epoch 87, loss: 2.6446, val mf1: 0.8516, (best 0.8516)
Epoch 88, loss: 2.7847, val mf1: 0.8522, (best 0.8522)
Epoch 89, loss: 2.4266, val mf1: 0.8553, (best 0.8553)
Epoch 90, loss: 1.6802, val mf1: 0.8160, (best 0.8553)
Epoch 91, loss: 0.8901, val mf1: 0.6958, (best 0.8553)
Epoch 92, loss: 3.5684, val mf1: 0.4394, (best 0.8553)
Epoch 93, loss: 1.8417, val mf1: 0.7186, (best 0.8553)
Epoch 94, loss: 3.2865, val mf1: 0.7605, (best 0.8553)
Epoch 95, loss: 4.2876, val mf1: 0.7828, (best 0.8553)
Epoch 96, loss: 4.8270, val mf1: 0.7839, (best 0.8553)
Epoch 97, loss: 4.9472, val mf1: 0.7728, (best 0.8553)
Epoch 98, loss: 4.7134, val mf1: 0.7478, (best 0.8553)
Epoch 99, loss: 4.2012, val mf1: 0.7167, (best 0.8553)
time cost:  19.15469980239868 s
Test: REC 61.10 PRE 85.03 MF1 84.96 AUC 91.97
MF1-mean: 85.30, MF1-std: 0.30, AUC-mean: 91.29, AUC-std: 0.49
