Using device: cuda
Namespace(dataset='tfinance', train_ratio=0.4, hid_dim=128, num_layers=3, epoch=100, run=3, knn_reconstruct_graph=True, knn_reconstruct_graph_approximate=False, alpha=0.5, top_k=3, save_model=False, model_path='./model', device=device(type='cuda', index=0), choose_model='GCN', hyperparameter_tuning=False)
Graph(num_nodes=39357, num_edges=199778,
      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'feature': Scheme(shape=(10,), dtype=torch.float32)}
      edata_schemes={})
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 48.0334, val mf1: 0.1645, (best 0.1645)
Epoch 1, loss: 39.7459, val mf1: 0.6917, (best 0.6917)
Epoch 2, loss: 55.0361, val mf1: 0.7574, (best 0.7574)
Epoch 3, loss: 66.7224, val mf1: 0.7040, (best 0.7574)
Epoch 4, loss: 73.6161, val mf1: 0.6671, (best 0.7574)
Epoch 5, loss: 75.9926, val mf1: 0.6490, (best 0.7574)
Epoch 6, loss: 74.5350, val mf1: 0.6455, (best 0.7574)
Epoch 7, loss: 70.1024, val mf1: 0.6441, (best 0.7574)
Epoch 8, loss: 63.7575, val mf1: 0.6446, (best 0.7574)
Epoch 9, loss: 56.2209, val mf1: 0.6493, (best 0.7574)
Epoch 10, loss: 47.8836, val mf1: 0.6537, (best 0.7574)
Epoch 11, loss: 38.9596, val mf1: 0.6550, (best 0.7574)
Epoch 12, loss: 29.4860, val mf1: 0.6490, (best 0.7574)
Epoch 13, loss: 19.8418, val mf1: 0.6157, (best 0.7574)
Epoch 14, loss: 11.4490, val mf1: 0.5383, (best 0.7574)
Epoch 15, loss: 29.3254, val mf1: 0.4020, (best 0.7574)
Epoch 16, loss: 13.8420, val mf1: 0.4871, (best 0.7574)
Epoch 17, loss: 22.3821, val mf1: 0.5224, (best 0.7574)
Epoch 18, loss: 26.0023, val mf1: 0.5126, (best 0.7574)
Epoch 19, loss: 22.2477, val mf1: 0.5625, (best 0.7574)
Epoch 20, loss: 14.4848, val mf1: 0.8492, (best 0.8492)
Epoch 21, loss: 9.8037, val mf1: 0.8208, (best 0.8492)
Epoch 22, loss: 9.3396, val mf1: 0.5259, (best 0.8492)
Epoch 23, loss: 13.2229, val mf1: 0.4298, (best 0.8492)
Epoch 24, loss: 15.3012, val mf1: 0.3823, (best 0.8492)
Epoch 25, loss: 12.7821, val mf1: 0.4004, (best 0.8492)
Epoch 26, loss: 7.8654, val mf1: 0.4962, (best 0.8492)
Epoch 27, loss: 5.5458, val mf1: 0.7032, (best 0.8492)
Epoch 28, loss: 6.2250, val mf1: 0.8039, (best 0.8492)
Epoch 29, loss: 6.2280, val mf1: 0.8214, (best 0.8492)
Epoch 30, loss: 7.7195, val mf1: 0.6844, (best 0.8492)
Epoch 31, loss: 8.2197, val mf1: 0.8419, (best 0.8492)
Epoch 32, loss: 9.9765, val mf1: 0.8498, (best 0.8498)
Epoch 33, loss: 10.3066, val mf1: 0.8502, (best 0.8502)
Epoch 34, loss: 9.3729, val mf1: 0.8495, (best 0.8502)
Epoch 35, loss: 7.3651, val mf1: 0.8398, (best 0.8502)
Epoch 36, loss: 11.5817, val mf1: 0.5935, (best 0.8502)
Epoch 37, loss: 9.4461, val mf1: 0.6074, (best 0.8502)
Epoch 38, loss: 7.3731, val mf1: 0.8267, (best 0.8502)
Epoch 39, loss: 8.7044, val mf1: 0.8255, (best 0.8502)
Epoch 40, loss: 8.9049, val mf1: 0.8180, (best 0.8502)
Epoch 41, loss: 8.1883, val mf1: 0.8034, (best 0.8502)
Epoch 42, loss: 6.8937, val mf1: 0.7533, (best 0.8502)
Epoch 43, loss: 6.0672, val mf1: 0.6172, (best 0.8502)
Epoch 44, loss: 6.7198, val mf1: 0.5064, (best 0.8502)
Epoch 45, loss: 8.1265, val mf1: 0.4436, (best 0.8502)
Epoch 46, loss: 6.5590, val mf1: 0.4968, (best 0.8502)
Epoch 47, loss: 5.5934, val mf1: 0.5940, (best 0.8502)
Epoch 48, loss: 5.6304, val mf1: 0.6910, (best 0.8502)
Epoch 49, loss: 5.8180, val mf1: 0.7803, (best 0.8502)
Epoch 50, loss: 5.5097, val mf1: 0.8062, (best 0.8502)
Epoch 51, loss: 4.4710, val mf1: 0.8034, (best 0.8502)
Epoch 52, loss: 3.0841, val mf1: 0.6741, (best 0.8502)
Epoch 53, loss: 6.6745, val mf1: 0.4634, (best 0.8502)
Epoch 54, loss: 3.1516, val mf1: 0.8105, (best 0.8502)
Epoch 55, loss: 4.4233, val mf1: 0.8442, (best 0.8502)
Epoch 56, loss: 4.6828, val mf1: 0.8452, (best 0.8502)
Epoch 57, loss: 3.9977, val mf1: 0.8242, (best 0.8502)
Epoch 58, loss: 2.6968, val mf1: 0.7801, (best 0.8502)
Epoch 59, loss: 3.5066, val mf1: 0.4374, (best 0.8502)
Epoch 60, loss: 2.3649, val mf1: 0.5045, (best 0.8502)
Epoch 61, loss: 2.4363, val mf1: 0.8218, (best 0.8502)
Epoch 62, loss: 3.0094, val mf1: 0.8475, (best 0.8502)
Epoch 63, loss: 2.6801, val mf1: 0.8493, (best 0.8502)
Epoch 64, loss: 1.6525, val mf1: 0.7760, (best 0.8502)
Epoch 65, loss: 4.0721, val mf1: 0.3820, (best 0.8502)
Epoch 66, loss: 3.4168, val mf1: 0.8510, (best 0.8510)
Epoch 67, loss: 5.8463, val mf1: 0.8540, (best 0.8540)
Epoch 68, loss: 7.1163, val mf1: 0.8560, (best 0.8560)
Epoch 69, loss: 7.2711, val mf1: 0.8553, (best 0.8560)
Epoch 70, loss: 6.4655, val mf1: 0.8529, (best 0.8560)
Epoch 71, loss: 4.9478, val mf1: 0.8042, (best 0.8560)
Epoch 72, loss: 3.5740, val mf1: 0.6493, (best 0.8560)
Epoch 73, loss: 3.4801, val mf1: 0.4880, (best 0.8560)
Epoch 74, loss: 5.3218, val mf1: 0.2981, (best 0.8560)
Epoch 75, loss: 2.3189, val mf1: 0.6091, (best 0.8560)
Epoch 76, loss: 2.9267, val mf1: 0.7713, (best 0.8560)
Epoch 77, loss: 3.6478, val mf1: 0.8569, (best 0.8569)
Epoch 78, loss: 3.5875, val mf1: 0.8545, (best 0.8569)
Epoch 79, loss: 2.6259, val mf1: 0.8543, (best 0.8569)
Epoch 80, loss: 2.3624, val mf1: 0.6404, (best 0.8569)
Epoch 81, loss: 1.4531, val mf1: 0.8339, (best 0.8569)
Epoch 82, loss: 1.2225, val mf1: 0.8098, (best 0.8569)
Epoch 83, loss: 2.2519, val mf1: 0.5801, (best 0.8569)
Epoch 84, loss: 2.5729, val mf1: 0.8373, (best 0.8569)
Epoch 85, loss: 3.8790, val mf1: 0.8554, (best 0.8569)
Epoch 86, loss: 4.2725, val mf1: 0.8476, (best 0.8569)
Epoch 87, loss: 3.9248, val mf1: 0.7905, (best 0.8569)
Epoch 88, loss: 3.2760, val mf1: 0.6968, (best 0.8569)
Epoch 89, loss: 2.8239, val mf1: 0.5855, (best 0.8569)
Epoch 90, loss: 3.8986, val mf1: 0.4269, (best 0.8569)
Epoch 91, loss: 2.7877, val mf1: 0.5012, (best 0.8569)
Epoch 92, loss: 2.0368, val mf1: 0.6819, (best 0.8569)
Epoch 93, loss: 2.3041, val mf1: 0.8122, (best 0.8569)
Epoch 94, loss: 2.2164, val mf1: 0.8391, (best 0.8569)
Epoch 95, loss: 1.4345, val mf1: 0.8130, (best 0.8569)
Epoch 96, loss: 3.3062, val mf1: 0.4801, (best 0.8569)
Epoch 97, loss: 2.1922, val mf1: 0.8253, (best 0.8569)
Epoch 98, loss: 3.4000, val mf1: 0.8293, (best 0.8569)
Epoch 99, loss: 3.5750, val mf1: 0.8362, (best 0.8569)
time cost:  6.55628228187561 s
Test: REC 63.45 PRE 83.48 MF1 85.46 AUC 91.65
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 5.5313, val mf1: 0.6944, (best 0.6944)
Epoch 1, loss: 974.3351, val mf1: 0.0438, (best 0.6944)
Epoch 2, loss: 211.4597, val mf1: 0.3194, (best 0.6944)
Epoch 3, loss: 92.4092, val mf1: 0.4883, (best 0.6944)
Epoch 4, loss: 126.1459, val mf1: 0.4883, (best 0.6944)
Epoch 5, loss: 139.9080, val mf1: 0.4883, (best 0.6944)
Epoch 6, loss: 140.9404, val mf1: 0.4911, (best 0.6944)
Epoch 7, loss: 133.5186, val mf1: 0.5130, (best 0.6944)
Epoch 8, loss: 122.8867, val mf1: 0.8552, (best 0.8552)
Epoch 9, loss: 119.2980, val mf1: 0.7688, (best 0.8552)
Epoch 10, loss: 115.9425, val mf1: 0.7144, (best 0.8552)
Epoch 11, loss: 112.4210, val mf1: 0.6564, (best 0.8552)
Epoch 12, loss: 108.4721, val mf1: 0.6241, (best 0.8552)
Epoch 13, loss: 103.7480, val mf1: 0.5936, (best 0.8552)
Epoch 14, loss: 98.4249, val mf1: 0.5730, (best 0.8552)
Epoch 15, loss: 92.3352, val mf1: 0.5587, (best 0.8552)
Epoch 16, loss: 85.4835, val mf1: 0.5458, (best 0.8552)
Epoch 17, loss: 77.8644, val mf1: 0.5338, (best 0.8552)
Epoch 18, loss: 69.5368, val mf1: 0.5259, (best 0.8552)
Epoch 19, loss: 60.6702, val mf1: 0.5191, (best 0.8552)
Epoch 20, loss: 51.4430, val mf1: 0.5139, (best 0.8552)
Epoch 21, loss: 42.0410, val mf1: 0.5110, (best 0.8552)
Epoch 22, loss: 32.7542, val mf1: 0.5042, (best 0.8552)
Epoch 23, loss: 24.1865, val mf1: 0.4956, (best 0.8552)
Epoch 24, loss: 23.4288, val mf1: 0.4598, (best 0.8552)
Epoch 25, loss: 11.6574, val mf1: 0.6111, (best 0.8552)
Epoch 26, loss: 13.2678, val mf1: 0.7950, (best 0.8552)
Epoch 27, loss: 15.6584, val mf1: 0.8533, (best 0.8552)
Epoch 28, loss: 16.5058, val mf1: 0.7842, (best 0.8552)
Epoch 29, loss: 18.9917, val mf1: 0.5728, (best 0.8552)
Epoch 30, loss: 18.2083, val mf1: 0.5910, (best 0.8552)
Epoch 31, loss: 14.5058, val mf1: 0.8065, (best 0.8552)
Epoch 32, loss: 13.0108, val mf1: 0.8475, (best 0.8552)
Epoch 33, loss: 10.1621, val mf1: 0.8527, (best 0.8552)
Epoch 34, loss: 10.0594, val mf1: 0.6503, (best 0.8552)
Epoch 35, loss: 6.4582, val mf1: 0.7042, (best 0.8552)
Epoch 36, loss: 7.0193, val mf1: 0.7686, (best 0.8552)
Epoch 37, loss: 6.9815, val mf1: 0.7256, (best 0.8552)
Epoch 38, loss: 6.1742, val mf1: 0.6777, (best 0.8552)
Epoch 39, loss: 5.4309, val mf1: 0.5678, (best 0.8552)
Epoch 40, loss: 7.1849, val mf1: 0.4449, (best 0.8552)
Epoch 41, loss: 5.9588, val mf1: 0.4965, (best 0.8552)
Epoch 42, loss: 5.3411, val mf1: 0.5811, (best 0.8552)
Epoch 43, loss: 5.3431, val mf1: 0.6335, (best 0.8552)
Epoch 44, loss: 4.9477, val mf1: 0.6573, (best 0.8552)
Epoch 45, loss: 4.9019, val mf1: 0.6191, (best 0.8552)
Epoch 46, loss: 3.8487, val mf1: 0.6968, (best 0.8552)
Epoch 47, loss: 3.0806, val mf1: 0.7359, (best 0.8552)
Epoch 48, loss: 2.8667, val mf1: 0.5935, (best 0.8552)
Epoch 49, loss: 3.3252, val mf1: 0.7924, (best 0.8552)
Epoch 50, loss: 3.9685, val mf1: 0.8165, (best 0.8552)
Epoch 51, loss: 3.0361, val mf1: 0.8084, (best 0.8552)
Epoch 52, loss: 5.1592, val mf1: 0.5135, (best 0.8552)
Epoch 53, loss: 5.3909, val mf1: 0.8355, (best 0.8552)
Epoch 54, loss: 8.3145, val mf1: 0.8410, (best 0.8552)
Epoch 55, loss: 9.4521, val mf1: 0.8439, (best 0.8552)
Epoch 56, loss: 8.9560, val mf1: 0.8412, (best 0.8552)
Epoch 57, loss: 7.0265, val mf1: 0.8344, (best 0.8552)
Epoch 58, loss: 4.0959, val mf1: 0.7691, (best 0.8552)
Epoch 59, loss: 5.6166, val mf1: 0.3902, (best 0.8552)
Epoch 60, loss: 7.3637, val mf1: 0.3314, (best 0.8552)
Epoch 61, loss: 2.9854, val mf1: 0.6277, (best 0.8552)
Epoch 62, loss: 4.8960, val mf1: 0.8386, (best 0.8552)
Epoch 63, loss: 5.9523, val mf1: 0.8495, (best 0.8552)
Epoch 64, loss: 5.5462, val mf1: 0.8504, (best 0.8552)
Epoch 65, loss: 3.8103, val mf1: 0.8500, (best 0.8552)
Epoch 66, loss: 1.7475, val mf1: 0.6024, (best 0.8552)
Epoch 67, loss: 8.6851, val mf1: 0.4359, (best 0.8552)
Epoch 68, loss: 5.8888, val mf1: 0.8561, (best 0.8561)
Epoch 69, loss: 10.9021, val mf1: 0.8574, (best 0.8574)
Epoch 70, loss: 14.1571, val mf1: 0.8542, (best 0.8574)
Epoch 71, loss: 15.7847, val mf1: 0.8537, (best 0.8574)
Epoch 72, loss: 15.9279, val mf1: 0.8563, (best 0.8574)
Epoch 73, loss: 14.7961, val mf1: 0.8597, (best 0.8597)
Epoch 74, loss: 12.5916, val mf1: 0.8522, (best 0.8597)
Epoch 75, loss: 9.6640, val mf1: 0.7867, (best 0.8597)
Epoch 76, loss: 6.8028, val mf1: 0.6650, (best 0.8597)
Epoch 77, loss: 5.6691, val mf1: 0.4793, (best 0.8597)
Epoch 78, loss: 10.0734, val mf1: 0.2545, (best 0.8597)
Epoch 79, loss: 7.1778, val mf1: 0.3012, (best 0.8597)
Epoch 80, loss: 3.8710, val mf1: 0.5985, (best 0.8597)
Epoch 81, loss: 4.6414, val mf1: 0.7292, (best 0.8597)
Epoch 82, loss: 5.4439, val mf1: 0.8011, (best 0.8597)
Epoch 83, loss: 5.4960, val mf1: 0.8351, (best 0.8597)
Epoch 84, loss: 4.6004, val mf1: 0.8457, (best 0.8597)
Epoch 85, loss: 2.8063, val mf1: 0.8401, (best 0.8597)
Epoch 86, loss: 8.8992, val mf1: 0.5553, (best 0.8597)
Epoch 87, loss: 2.5530, val mf1: 0.7091, (best 0.8597)
Epoch 88, loss: 5.1963, val mf1: 0.8601, (best 0.8601)
Epoch 89, loss: 6.9359, val mf1: 0.8596, (best 0.8601)
Epoch 90, loss: 7.4759, val mf1: 0.8600, (best 0.8601)
Epoch 91, loss: 6.9642, val mf1: 0.8560, (best 0.8601)
Epoch 92, loss: 5.5460, val mf1: 0.8358, (best 0.8601)
Epoch 93, loss: 3.5422, val mf1: 0.7726, (best 0.8601)
Epoch 94, loss: 1.5462, val mf1: 0.6507, (best 0.8601)
Epoch 95, loss: 18.9772, val mf1: 0.2021, (best 0.8601)
Epoch 96, loss: 5.2684, val mf1: 0.7546, (best 0.8601)
Epoch 97, loss: 11.0119, val mf1: 0.8522, (best 0.8601)
Epoch 98, loss: 15.6576, val mf1: 0.8611, (best 0.8611)
Epoch 99, loss: 18.9857, val mf1: 0.8573, (best 0.8611)
time cost:  5.4232401847839355 s
Test: REC 65.38 PRE 82.87 MF1 85.97 AUC 90.99
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 134.7378, val mf1: 0.2414, (best 0.2414)
Epoch 1, loss: 48.8944, val mf1: 0.5764, (best 0.5764)
Epoch 2, loss: 64.7948, val mf1: 0.8043, (best 0.8043)
Epoch 3, loss: 73.6985, val mf1: 0.7276, (best 0.8043)
Epoch 4, loss: 76.8001, val mf1: 0.6852, (best 0.8043)
Epoch 5, loss: 75.4589, val mf1: 0.6541, (best 0.8043)
Epoch 6, loss: 70.5323, val mf1: 0.6339, (best 0.8043)
Epoch 7, loss: 62.8525, val mf1: 0.6245, (best 0.8043)
Epoch 8, loss: 53.0859, val mf1: 0.6208, (best 0.8043)
Epoch 9, loss: 41.9608, val mf1: 0.6178, (best 0.8043)
Epoch 10, loss: 30.0196, val mf1: 0.6144, (best 0.8043)
Epoch 11, loss: 17.4320, val mf1: 0.6083, (best 0.8043)
Epoch 12, loss: 8.9060, val mf1: 0.4382, (best 0.8043)
Epoch 13, loss: 4.2356, val mf1: 0.6576, (best 0.8043)
Epoch 14, loss: 7.0857, val mf1: 0.8173, (best 0.8173)
Epoch 15, loss: 11.8371, val mf1: 0.4927, (best 0.8173)
Epoch 16, loss: 13.5309, val mf1: 0.5628, (best 0.8173)
Epoch 17, loss: 9.5692, val mf1: 0.7060, (best 0.8173)
Epoch 18, loss: 10.7824, val mf1: 0.5885, (best 0.8173)
Epoch 19, loss: 7.2180, val mf1: 0.8235, (best 0.8235)
Epoch 20, loss: 8.0068, val mf1: 0.7914, (best 0.8235)
Epoch 21, loss: 7.5778, val mf1: 0.7403, (best 0.8235)
Epoch 22, loss: 7.3463, val mf1: 0.5787, (best 0.8235)
Epoch 23, loss: 9.8401, val mf1: 0.4693, (best 0.8235)
Epoch 24, loss: 10.2301, val mf1: 0.4702, (best 0.8235)
Epoch 25, loss: 8.2535, val mf1: 0.5601, (best 0.8235)
Epoch 26, loss: 8.1514, val mf1: 0.7071, (best 0.8235)
Epoch 27, loss: 8.3104, val mf1: 0.7474, (best 0.8235)
Epoch 28, loss: 7.4379, val mf1: 0.7656, (best 0.8235)
Epoch 29, loss: 7.4405, val mf1: 0.6033, (best 0.8235)
Epoch 30, loss: 6.6928, val mf1: 0.6637, (best 0.8235)
Epoch 31, loss: 6.9486, val mf1: 0.8066, (best 0.8235)
Epoch 32, loss: 6.4328, val mf1: 0.7704, (best 0.8235)
Epoch 33, loss: 6.4459, val mf1: 0.6049, (best 0.8235)
Epoch 34, loss: 5.8063, val mf1: 0.8135, (best 0.8235)
Epoch 35, loss: 5.2056, val mf1: 0.8066, (best 0.8235)
Epoch 36, loss: 4.4281, val mf1: 0.5877, (best 0.8235)
Epoch 37, loss: 4.3093, val mf1: 0.5490, (best 0.8235)
Epoch 38, loss: 3.6985, val mf1: 0.7730, (best 0.8235)
Epoch 39, loss: 3.4627, val mf1: 0.7875, (best 0.8235)
Epoch 40, loss: 2.8896, val mf1: 0.5828, (best 0.8235)
Epoch 41, loss: 2.9948, val mf1: 0.5113, (best 0.8235)
Epoch 42, loss: 2.7523, val mf1: 0.7491, (best 0.8235)
Epoch 43, loss: 2.7154, val mf1: 0.7432, (best 0.8235)
Epoch 44, loss: 2.2513, val mf1: 0.5755, (best 0.8235)
Epoch 45, loss: 2.6719, val mf1: 0.5007, (best 0.8235)
Epoch 46, loss: 4.7834, val mf1: 0.8479, (best 0.8479)
Epoch 47, loss: 6.6771, val mf1: 0.8555, (best 0.8555)
Epoch 48, loss: 6.6672, val mf1: 0.8545, (best 0.8555)
Epoch 49, loss: 5.0218, val mf1: 0.8461, (best 0.8555)
Epoch 50, loss: 2.3980, val mf1: 0.7125, (best 0.8555)
Epoch 51, loss: 11.6469, val mf1: 0.2334, (best 0.8555)
Epoch 52, loss: 5.1550, val mf1: 0.8081, (best 0.8555)
Epoch 53, loss: 9.8486, val mf1: 0.8536, (best 0.8555)
Epoch 54, loss: 12.8246, val mf1: 0.8577, (best 0.8577)
Epoch 55, loss: 14.0550, val mf1: 0.8577, (best 0.8577)
Epoch 56, loss: 13.7245, val mf1: 0.8530, (best 0.8577)
Epoch 57, loss: 12.1426, val mf1: 0.8150, (best 0.8577)
Epoch 58, loss: 10.0138, val mf1: 0.7075, (best 0.8577)
Epoch 59, loss: 8.3705, val mf1: 0.6007, (best 0.8577)
Epoch 60, loss: 7.4783, val mf1: 0.5134, (best 0.8577)
Epoch 61, loss: 7.1953, val mf1: 0.4299, (best 0.8577)
Epoch 62, loss: 6.8547, val mf1: 0.2957, (best 0.8577)
Epoch 63, loss: 2.7602, val mf1: 0.6190, (best 0.8577)
Epoch 64, loss: 3.8361, val mf1: 0.8414, (best 0.8577)
Epoch 65, loss: 4.8678, val mf1: 0.8501, (best 0.8577)
Epoch 66, loss: 4.6395, val mf1: 0.8354, (best 0.8577)
Epoch 67, loss: 4.9605, val mf1: 0.6186, (best 0.8577)
Epoch 68, loss: 4.3739, val mf1: 0.8015, (best 0.8577)
Epoch 69, loss: 4.1209, val mf1: 0.8136, (best 0.8577)
Epoch 70, loss: 3.5240, val mf1: 0.6259, (best 0.8577)
Epoch 71, loss: 3.8554, val mf1: 0.8473, (best 0.8577)
Epoch 72, loss: 3.8527, val mf1: 0.8555, (best 0.8577)
Epoch 73, loss: 2.9269, val mf1: 0.8074, (best 0.8577)
Epoch 74, loss: 1.6554, val mf1: 0.7174, (best 0.8577)
Epoch 75, loss: 6.1948, val mf1: 0.3238, (best 0.8577)
Epoch 76, loss: 3.7442, val mf1: 0.7100, (best 0.8577)
Epoch 77, loss: 6.4825, val mf1: 0.7650, (best 0.8577)
Epoch 78, loss: 8.3765, val mf1: 0.7913, (best 0.8577)
Epoch 79, loss: 9.2909, val mf1: 0.7975, (best 0.8577)
Epoch 80, loss: 9.2847, val mf1: 0.7917, (best 0.8577)
Epoch 81, loss: 8.4910, val mf1: 0.7686, (best 0.8577)
Epoch 82, loss: 7.1367, val mf1: 0.7302, (best 0.8577)
Epoch 83, loss: 5.5720, val mf1: 0.6616, (best 0.8577)
Epoch 84, loss: 4.6268, val mf1: 0.5258, (best 0.8577)
Epoch 85, loss: 5.6020, val mf1: 0.3523, (best 0.8577)
Epoch 86, loss: 3.7079, val mf1: 0.4184, (best 0.8577)
Epoch 87, loss: 1.9111, val mf1: 0.7536, (best 0.8577)
Epoch 88, loss: 2.5388, val mf1: 0.8424, (best 0.8577)
Epoch 89, loss: 2.5602, val mf1: 0.8055, (best 0.8577)
Epoch 90, loss: 3.0005, val mf1: 0.5473, (best 0.8577)
Epoch 91, loss: 3.0182, val mf1: 0.5685, (best 0.8577)
Epoch 92, loss: 3.5759, val mf1: 0.7828, (best 0.8577)
Epoch 93, loss: 3.6861, val mf1: 0.8008, (best 0.8577)
Epoch 94, loss: 2.8530, val mf1: 0.7640, (best 0.8577)
Epoch 95, loss: 5.6483, val mf1: 0.5270, (best 0.8577)
Epoch 96, loss: 3.9064, val mf1: 0.8447, (best 0.8577)
Epoch 97, loss: 5.3199, val mf1: 0.8599, (best 0.8599)
Epoch 98, loss: 5.7466, val mf1: 0.8577, (best 0.8599)
Epoch 99, loss: 5.3491, val mf1: 0.8302, (best 0.8599)
time cost:  6.107045888900757 s
Test: REC 61.10 PRE 86.52 MF1 85.24 AUC 91.81
MF1-mean: 85.56, MF1-std: 0.31, AUC-mean: 91.48, AUC-std: 0.36
