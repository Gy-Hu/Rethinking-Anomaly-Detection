Using device: cuda
Namespace(dataset='tfinance', train_ratio=0.4, hid_dim=128, num_layers=3, epoch=100, run=3, knn_reconstruct_graph=True, knn_reconstruct_graph_approximate=False, alpha=0.6, top_k=3, save_model=False, model_path='./model', device=device(type='cuda', index=0), choose_model='GCN', hyperparameter_tuning=False)
Graph(num_nodes=39357, num_edges=199778,
      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'feature': Scheme(shape=(10,), dtype=torch.float32)}
      edata_schemes={})
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 460.4802, val mf1: 0.0438, (best 0.0438)
Epoch 1, loss: 83.6950, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 116.5028, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 122.3388, val mf1: 0.4883, (best 0.4883)
Epoch 4, loss: 116.5269, val mf1: 0.4883, (best 0.4883)
Epoch 5, loss: 103.8727, val mf1: 0.4939, (best 0.4939)
Epoch 6, loss: 87.2104, val mf1: 0.8165, (best 0.8165)
Epoch 7, loss: 79.5295, val mf1: 0.8107, (best 0.8165)
Epoch 8, loss: 74.2752, val mf1: 0.7337, (best 0.8165)
Epoch 9, loss: 70.2740, val mf1: 0.6793, (best 0.8165)
Epoch 10, loss: 66.8302, val mf1: 0.6413, (best 0.8165)
Epoch 11, loss: 63.4538, val mf1: 0.6063, (best 0.8165)
Epoch 12, loss: 59.6425, val mf1: 0.5842, (best 0.8165)
Epoch 13, loss: 55.1622, val mf1: 0.5698, (best 0.8165)
Epoch 14, loss: 50.0262, val mf1: 0.5608, (best 0.8165)
Epoch 15, loss: 44.2715, val mf1: 0.5505, (best 0.8165)
Epoch 16, loss: 37.9897, val mf1: 0.5441, (best 0.8165)
Epoch 17, loss: 31.2873, val mf1: 0.5386, (best 0.8165)
Epoch 18, loss: 24.3555, val mf1: 0.5329, (best 0.8165)
Epoch 19, loss: 17.8262, val mf1: 0.5157, (best 0.8165)
Epoch 20, loss: 18.4971, val mf1: 0.4507, (best 0.8165)
Epoch 21, loss: 11.6651, val mf1: 0.5126, (best 0.8165)
Epoch 22, loss: 9.0422, val mf1: 0.7417, (best 0.8165)
Epoch 23, loss: 11.4035, val mf1: 0.8190, (best 0.8190)
Epoch 24, loss: 13.2168, val mf1: 0.8570, (best 0.8570)
Epoch 25, loss: 13.9519, val mf1: 0.8481, (best 0.8570)
Epoch 26, loss: 13.5275, val mf1: 0.8294, (best 0.8570)
Epoch 27, loss: 11.5348, val mf1: 0.8286, (best 0.8570)
Epoch 28, loss: 8.4812, val mf1: 0.8336, (best 0.8570)
Epoch 29, loss: 6.0002, val mf1: 0.5978, (best 0.8570)
Epoch 30, loss: 6.9639, val mf1: 0.5399, (best 0.8570)
Epoch 31, loss: 3.9945, val mf1: 0.7300, (best 0.8570)
Epoch 32, loss: 4.0372, val mf1: 0.8011, (best 0.8570)
Epoch 33, loss: 3.7056, val mf1: 0.7627, (best 0.8570)
Epoch 34, loss: 3.7021, val mf1: 0.6115, (best 0.8570)
Epoch 35, loss: 4.4848, val mf1: 0.5138, (best 0.8570)
Epoch 36, loss: 4.8219, val mf1: 0.4824, (best 0.8570)
Epoch 37, loss: 4.0317, val mf1: 0.5407, (best 0.8570)
Epoch 38, loss: 3.3211, val mf1: 0.6634, (best 0.8570)
Epoch 39, loss: 3.3025, val mf1: 0.7702, (best 0.8570)
Epoch 40, loss: 3.0043, val mf1: 0.7918, (best 0.8570)
Epoch 41, loss: 2.2756, val mf1: 0.7006, (best 0.8570)
Epoch 42, loss: 2.7557, val mf1: 0.5193, (best 0.8570)
Epoch 43, loss: 2.0789, val mf1: 0.5914, (best 0.8570)
Epoch 44, loss: 2.2203, val mf1: 0.8170, (best 0.8570)
Epoch 45, loss: 2.4353, val mf1: 0.8246, (best 0.8570)
Epoch 46, loss: 1.9973, val mf1: 0.8114, (best 0.8570)
Epoch 47, loss: 2.0465, val mf1: 0.5809, (best 0.8570)
Epoch 48, loss: 1.9853, val mf1: 0.8064, (best 0.8570)
Epoch 49, loss: 2.2768, val mf1: 0.8030, (best 0.8570)
Epoch 50, loss: 1.9719, val mf1: 0.7874, (best 0.8570)
Epoch 51, loss: 1.3165, val mf1: 0.6908, (best 0.8570)
Epoch 52, loss: 3.0947, val mf1: 0.5052, (best 0.8570)
Epoch 53, loss: 2.7499, val mf1: 0.7583, (best 0.8570)
Epoch 54, loss: 4.3996, val mf1: 0.7793, (best 0.8570)
Epoch 55, loss: 5.3873, val mf1: 0.8344, (best 0.8570)
Epoch 56, loss: 5.7236, val mf1: 0.8349, (best 0.8570)
Epoch 57, loss: 5.4516, val mf1: 0.7466, (best 0.8570)
Epoch 58, loss: 4.8112, val mf1: 0.6819, (best 0.8570)
Epoch 59, loss: 3.9473, val mf1: 0.6194, (best 0.8570)
Epoch 60, loss: 3.0953, val mf1: 0.5421, (best 0.8570)
Epoch 61, loss: 3.6428, val mf1: 0.3793, (best 0.8570)
Epoch 62, loss: 2.4885, val mf1: 0.4680, (best 0.8570)
Epoch 63, loss: 2.0284, val mf1: 0.5187, (best 0.8570)
Epoch 64, loss: 1.4803, val mf1: 0.5534, (best 0.8570)
Epoch 65, loss: 1.4393, val mf1: 0.5666, (best 0.8570)
Epoch 66, loss: 1.3168, val mf1: 0.6211, (best 0.8570)
Epoch 67, loss: 1.3560, val mf1: 0.7688, (best 0.8570)
Epoch 68, loss: 1.4778, val mf1: 0.7810, (best 0.8570)
Epoch 69, loss: 1.4741, val mf1: 0.6865, (best 0.8570)
Epoch 70, loss: 1.6359, val mf1: 0.6580, (best 0.8570)
Epoch 71, loss: 1.9835, val mf1: 0.7956, (best 0.8570)
Epoch 72, loss: 2.1937, val mf1: 0.7952, (best 0.8570)
Epoch 73, loss: 1.8958, val mf1: 0.7812, (best 0.8570)
Epoch 74, loss: 1.2286, val mf1: 0.7430, (best 0.8570)
Epoch 75, loss: 3.6026, val mf1: 0.5322, (best 0.8570)
Epoch 76, loss: 2.0765, val mf1: 0.7890, (best 0.8570)
Epoch 77, loss: 3.3748, val mf1: 0.8175, (best 0.8570)
Epoch 78, loss: 4.0475, val mf1: 0.8238, (best 0.8570)
Epoch 79, loss: 4.0992, val mf1: 0.8191, (best 0.8570)
Epoch 80, loss: 3.6572, val mf1: 0.7760, (best 0.8570)
Epoch 81, loss: 3.1103, val mf1: 0.6723, (best 0.8570)
Epoch 82, loss: 3.0076, val mf1: 0.5392, (best 0.8570)
Epoch 83, loss: 2.3287, val mf1: 0.5821, (best 0.8570)
Epoch 84, loss: 1.7778, val mf1: 0.8366, (best 0.8570)
Epoch 85, loss: 1.7304, val mf1: 0.8403, (best 0.8570)
Epoch 86, loss: 1.5252, val mf1: 0.6402, (best 0.8570)
Epoch 87, loss: 2.5232, val mf1: 0.5200, (best 0.8570)
Epoch 88, loss: 1.8063, val mf1: 0.6642, (best 0.8570)
Epoch 89, loss: 2.2161, val mf1: 0.8319, (best 0.8570)
Epoch 90, loss: 2.1714, val mf1: 0.8430, (best 0.8570)
Epoch 91, loss: 1.6103, val mf1: 0.7879, (best 0.8570)
Epoch 92, loss: 1.6168, val mf1: 0.5924, (best 0.8570)
Epoch 93, loss: 1.5443, val mf1: 0.5831, (best 0.8570)
Epoch 94, loss: 1.3111, val mf1: 0.7194, (best 0.8570)
Epoch 95, loss: 1.6248, val mf1: 0.6910, (best 0.8570)
Epoch 96, loss: 1.6274, val mf1: 0.6709, (best 0.8570)
Epoch 97, loss: 1.3318, val mf1: 0.6586, (best 0.8570)
Epoch 98, loss: 1.3376, val mf1: 0.5693, (best 0.8570)
Epoch 99, loss: 0.8988, val mf1: 0.7179, (best 0.8570)
time cost:  23.612550258636475 s
Test: REC 60.55 PRE 86.59 MF1 85.05 AUC 91.98
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 19.4671, val mf1: 0.4342, (best 0.4342)
Epoch 1, loss: 74.1947, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 130.9815, val mf1: 0.4348, (best 0.4883)
Epoch 3, loss: 47.0324, val mf1: 0.4911, (best 0.4911)
Epoch 4, loss: 45.8633, val mf1: 0.6931, (best 0.6931)
Epoch 5, loss: 46.4571, val mf1: 0.7822, (best 0.7822)
Epoch 6, loss: 48.6338, val mf1: 0.7024, (best 0.7822)
Epoch 7, loss: 49.8874, val mf1: 0.6421, (best 0.7822)
Epoch 8, loss: 49.6907, val mf1: 0.6064, (best 0.7822)
Epoch 9, loss: 47.8390, val mf1: 0.5787, (best 0.7822)
Epoch 10, loss: 44.2445, val mf1: 0.5580, (best 0.7822)
Epoch 11, loss: 39.0324, val mf1: 0.5404, (best 0.7822)
Epoch 12, loss: 32.7573, val mf1: 0.5189, (best 0.7822)
Epoch 13, loss: 25.7055, val mf1: 0.4894, (best 0.7822)
Epoch 14, loss: 25.5278, val mf1: 0.4092, (best 0.7822)
Epoch 15, loss: 13.0371, val mf1: 0.6002, (best 0.7822)
Epoch 16, loss: 12.3137, val mf1: 0.7025, (best 0.7822)
Epoch 17, loss: 12.3545, val mf1: 0.7775, (best 0.7822)
Epoch 18, loss: 11.9966, val mf1: 0.8374, (best 0.8374)
Epoch 19, loss: 9.6059, val mf1: 0.8565, (best 0.8565)
Epoch 20, loss: 10.8342, val mf1: 0.6057, (best 0.8565)
Epoch 21, loss: 7.5615, val mf1: 0.6245, (best 0.8565)
Epoch 22, loss: 7.8716, val mf1: 0.8345, (best 0.8565)
Epoch 23, loss: 7.9780, val mf1: 0.8481, (best 0.8565)
Epoch 24, loss: 5.8768, val mf1: 0.8536, (best 0.8565)
Epoch 25, loss: 4.7407, val mf1: 0.5531, (best 0.8565)
Epoch 26, loss: 5.4840, val mf1: 0.4762, (best 0.8565)
Epoch 27, loss: 4.2987, val mf1: 0.8020, (best 0.8565)
Epoch 28, loss: 5.4860, val mf1: 0.8091, (best 0.8565)
Epoch 29, loss: 4.9740, val mf1: 0.8003, (best 0.8565)
Epoch 30, loss: 3.3247, val mf1: 0.6874, (best 0.8565)
Epoch 31, loss: 5.3234, val mf1: 0.4460, (best 0.8565)
Epoch 32, loss: 4.3973, val mf1: 0.4926, (best 0.8565)
Epoch 33, loss: 3.8610, val mf1: 0.7740, (best 0.8565)
Epoch 34, loss: 4.9397, val mf1: 0.8258, (best 0.8565)
Epoch 35, loss: 4.4722, val mf1: 0.8266, (best 0.8565)
Epoch 36, loss: 3.3886, val mf1: 0.6108, (best 0.8565)
Epoch 37, loss: 4.7342, val mf1: 0.5033, (best 0.8565)
Epoch 38, loss: 3.1198, val mf1: 0.6989, (best 0.8565)
Epoch 39, loss: 3.9014, val mf1: 0.8378, (best 0.8565)
Epoch 40, loss: 3.3077, val mf1: 0.8309, (best 0.8565)
Epoch 41, loss: 2.8749, val mf1: 0.5520, (best 0.8565)
Epoch 42, loss: 2.4840, val mf1: 0.5628, (best 0.8565)
Epoch 43, loss: 2.7467, val mf1: 0.8074, (best 0.8565)
Epoch 44, loss: 2.6907, val mf1: 0.8063, (best 0.8565)
Epoch 45, loss: 1.4893, val mf1: 0.7129, (best 0.8565)
Epoch 46, loss: 6.9595, val mf1: 0.3431, (best 0.8565)
Epoch 47, loss: 7.0528, val mf1: 0.8573, (best 0.8573)
Epoch 48, loss: 13.1369, val mf1: 0.8495, (best 0.8573)
Epoch 49, loss: 17.0800, val mf1: 0.8386, (best 0.8573)
Epoch 50, loss: 18.7854, val mf1: 0.8404, (best 0.8573)
Epoch 51, loss: 18.4676, val mf1: 0.8487, (best 0.8573)
Epoch 52, loss: 16.5597, val mf1: 0.8593, (best 0.8593)
Epoch 53, loss: 13.3799, val mf1: 0.8330, (best 0.8593)
Epoch 54, loss: 9.5939, val mf1: 0.7070, (best 0.8593)
Epoch 55, loss: 7.6309, val mf1: 0.5041, (best 0.8593)
Epoch 56, loss: 12.8116, val mf1: 0.3240, (best 0.8593)
Epoch 57, loss: 8.2330, val mf1: 0.3834, (best 0.8593)
Epoch 58, loss: 5.1403, val mf1: 0.5893, (best 0.8593)
Epoch 59, loss: 5.3760, val mf1: 0.6887, (best 0.8593)
Epoch 60, loss: 5.4530, val mf1: 0.7583, (best 0.8593)
Epoch 61, loss: 4.7577, val mf1: 0.8045, (best 0.8593)
Epoch 62, loss: 3.1131, val mf1: 0.8043, (best 0.8593)
Epoch 63, loss: 6.7738, val mf1: 0.5330, (best 0.8593)
Epoch 64, loss: 3.0989, val mf1: 0.8474, (best 0.8593)
Epoch 65, loss: 4.1096, val mf1: 0.8534, (best 0.8593)
Epoch 66, loss: 4.0097, val mf1: 0.8537, (best 0.8593)
Epoch 67, loss: 2.9751, val mf1: 0.7599, (best 0.8593)
Epoch 68, loss: 4.6629, val mf1: 0.5651, (best 0.8593)
Epoch 69, loss: 3.4061, val mf1: 0.8461, (best 0.8593)
Epoch 70, loss: 4.2445, val mf1: 0.8494, (best 0.8593)
Epoch 71, loss: 3.9921, val mf1: 0.8261, (best 0.8593)
Epoch 72, loss: 2.9532, val mf1: 0.7462, (best 0.8593)
Epoch 73, loss: 2.7382, val mf1: 0.5298, (best 0.8593)
Epoch 74, loss: 3.4359, val mf1: 0.4678, (best 0.8593)
Epoch 75, loss: 2.2278, val mf1: 0.6408, (best 0.8593)
Epoch 76, loss: 2.6364, val mf1: 0.7491, (best 0.8593)
Epoch 77, loss: 2.6377, val mf1: 0.8289, (best 0.8593)
Epoch 78, loss: 1.7736, val mf1: 0.7416, (best 0.8593)
Epoch 79, loss: 2.8894, val mf1: 0.4355, (best 0.8593)
Epoch 80, loss: 1.3273, val mf1: 0.8017, (best 0.8593)
Epoch 81, loss: 1.6062, val mf1: 0.8383, (best 0.8593)
Epoch 82, loss: 1.0566, val mf1: 0.7866, (best 0.8593)
Epoch 83, loss: 2.7330, val mf1: 0.4584, (best 0.8593)
Epoch 84, loss: 2.6954, val mf1: 0.8570, (best 0.8593)
Epoch 85, loss: 4.2585, val mf1: 0.8573, (best 0.8593)
Epoch 86, loss: 4.6059, val mf1: 0.8580, (best 0.8593)
Epoch 87, loss: 3.9109, val mf1: 0.8437, (best 0.8593)
Epoch 88, loss: 2.5163, val mf1: 0.7542, (best 0.8593)
Epoch 89, loss: 1.4478, val mf1: 0.5822, (best 0.8593)
Epoch 90, loss: 7.6006, val mf1: 0.2991, (best 0.8593)
Epoch 91, loss: 5.9155, val mf1: 0.8375, (best 0.8593)
Epoch 92, loss: 11.4479, val mf1: 0.8593, (best 0.8593)
Epoch 93, loss: 15.5293, val mf1: 0.8539, (best 0.8593)
Epoch 94, loss: 18.1744, val mf1: 0.8498, (best 0.8593)
Epoch 95, loss: 19.4617, val mf1: 0.8481, (best 0.8593)
Epoch 96, loss: 19.5587, val mf1: 0.8530, (best 0.8593)
Epoch 97, loss: 18.6613, val mf1: 0.8571, (best 0.8593)
Epoch 98, loss: 16.9534, val mf1: 0.8587, (best 0.8593)
Epoch 99, loss: 14.6437, val mf1: 0.8421, (best 0.8593)
time cost:  26.171260118484497 s
Test: REC 63.72 PRE 85.56 MF1 85.96 AUC 90.26
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 26.7193, val mf1: 0.3005, (best 0.3005)
Epoch 1, loss: 98.1067, val mf1: 0.4911, (best 0.4911)
Epoch 2, loss: 125.7338, val mf1: 0.4911, (best 0.4911)
Epoch 3, loss: 126.5959, val mf1: 0.4967, (best 0.4967)
Epoch 4, loss: 113.0282, val mf1: 0.6116, (best 0.6116)
Epoch 5, loss: 99.9507, val mf1: 0.7991, (best 0.7991)
Epoch 6, loss: 88.9025, val mf1: 0.7171, (best 0.7991)
Epoch 7, loss: 77.8403, val mf1: 0.6517, (best 0.7991)
Epoch 8, loss: 67.4841, val mf1: 0.6008, (best 0.7991)
Epoch 9, loss: 57.5172, val mf1: 0.5520, (best 0.7991)
Epoch 10, loss: 48.1653, val mf1: 0.5138, (best 0.7991)
Epoch 11, loss: 39.9689, val mf1: 0.4601, (best 0.7991)
Epoch 12, loss: 35.0072, val mf1: 0.3666, (best 0.7991)
Epoch 13, loss: 41.6582, val mf1: 0.1002, (best 0.7991)
Epoch 14, loss: 17.3602, val mf1: 0.5245, (best 0.7991)
Epoch 15, loss: 20.7277, val mf1: 0.6372, (best 0.7991)
Epoch 16, loss: 26.5444, val mf1: 0.7372, (best 0.7991)
Epoch 17, loss: 32.0659, val mf1: 0.7955, (best 0.7991)
Epoch 18, loss: 36.2351, val mf1: 0.8313, (best 0.8313)
Epoch 19, loss: 38.7813, val mf1: 0.8538, (best 0.8538)
Epoch 20, loss: 39.7271, val mf1: 0.8493, (best 0.8538)
Epoch 21, loss: 39.1342, val mf1: 0.8408, (best 0.8538)
Epoch 22, loss: 37.0590, val mf1: 0.8361, (best 0.8538)
Epoch 23, loss: 33.6688, val mf1: 0.8443, (best 0.8538)
Epoch 24, loss: 29.3421, val mf1: 0.8531, (best 0.8538)
Epoch 25, loss: 24.3530, val mf1: 0.8561, (best 0.8561)
Epoch 26, loss: 18.9310, val mf1: 0.8479, (best 0.8561)
Epoch 27, loss: 13.2266, val mf1: 0.8236, (best 0.8561)
Epoch 28, loss: 9.5848, val mf1: 0.6448, (best 0.8561)
Epoch 29, loss: 17.9223, val mf1: 0.5586, (best 0.8561)
Epoch 30, loss: 14.1201, val mf1: 0.5614, (best 0.8561)
Epoch 31, loss: 7.5469, val mf1: 0.7480, (best 0.8561)
Epoch 32, loss: 9.5316, val mf1: 0.7414, (best 0.8561)
Epoch 33, loss: 10.5940, val mf1: 0.7302, (best 0.8561)
Epoch 34, loss: 10.8337, val mf1: 0.7168, (best 0.8561)
Epoch 35, loss: 10.3522, val mf1: 0.7003, (best 0.8561)
Epoch 36, loss: 9.2769, val mf1: 0.6804, (best 0.8561)
Epoch 37, loss: 7.7928, val mf1: 0.6334, (best 0.8561)
Epoch 38, loss: 6.3383, val mf1: 0.5694, (best 0.8561)
Epoch 39, loss: 6.2393, val mf1: 0.4882, (best 0.8561)
Epoch 40, loss: 6.6164, val mf1: 0.4594, (best 0.8561)
Epoch 41, loss: 4.8317, val mf1: 0.4970, (best 0.8561)
Epoch 42, loss: 3.6760, val mf1: 0.7098, (best 0.8561)
Epoch 43, loss: 4.4250, val mf1: 0.8201, (best 0.8561)
Epoch 44, loss: 4.3653, val mf1: 0.8326, (best 0.8561)
Epoch 45, loss: 3.3705, val mf1: 0.7955, (best 0.8561)
Epoch 46, loss: 3.1078, val mf1: 0.5206, (best 0.8561)
Epoch 47, loss: 2.3186, val mf1: 0.5630, (best 0.8561)
Epoch 48, loss: 2.7399, val mf1: 0.8088, (best 0.8561)
Epoch 49, loss: 2.8419, val mf1: 0.8227, (best 0.8561)
Epoch 50, loss: 2.1188, val mf1: 0.7834, (best 0.8561)
Epoch 51, loss: 2.2558, val mf1: 0.5356, (best 0.8561)
Epoch 52, loss: 1.8442, val mf1: 0.7514, (best 0.8561)
Epoch 53, loss: 2.1858, val mf1: 0.7508, (best 0.8561)
Epoch 54, loss: 2.0248, val mf1: 0.6823, (best 0.8561)
Epoch 55, loss: 2.0124, val mf1: 0.5491, (best 0.8561)
Epoch 56, loss: 1.9435, val mf1: 0.5508, (best 0.8561)
Epoch 57, loss: 1.7682, val mf1: 0.7233, (best 0.8561)
Epoch 58, loss: 1.7727, val mf1: 0.7711, (best 0.8561)
Epoch 59, loss: 1.2569, val mf1: 0.7263, (best 0.8561)
Epoch 60, loss: 3.2261, val mf1: 0.5667, (best 0.8561)
Epoch 61, loss: 4.4787, val mf1: 0.8165, (best 0.8561)
Epoch 62, loss: 7.2318, val mf1: 0.8289, (best 0.8561)
Epoch 63, loss: 8.8576, val mf1: 0.8276, (best 0.8561)
Epoch 64, loss: 9.4323, val mf1: 0.8137, (best 0.8561)
Epoch 65, loss: 9.0920, val mf1: 0.7831, (best 0.8561)
Epoch 66, loss: 8.0592, val mf1: 0.6853, (best 0.8561)
Epoch 67, loss: 6.8167, val mf1: 0.5643, (best 0.8561)
Epoch 68, loss: 5.6767, val mf1: 0.4965, (best 0.8561)
Epoch 69, loss: 4.7002, val mf1: 0.4299, (best 0.8561)
Epoch 70, loss: 4.3109, val mf1: 0.3194, (best 0.8561)
Epoch 71, loss: 1.4143, val mf1: 0.5836, (best 0.8561)
Epoch 72, loss: 1.7868, val mf1: 0.7964, (best 0.8561)
Epoch 73, loss: 2.0277, val mf1: 0.6699, (best 0.8561)
Epoch 74, loss: 5.3639, val mf1: 0.5383, (best 0.8561)
Epoch 75, loss: 4.5315, val mf1: 0.8113, (best 0.8561)
Epoch 76, loss: 6.0194, val mf1: 0.8440, (best 0.8561)
Epoch 77, loss: 6.5154, val mf1: 0.8579, (best 0.8579)
Epoch 78, loss: 6.1695, val mf1: 0.8489, (best 0.8579)
Epoch 79, loss: 5.0824, val mf1: 0.8209, (best 0.8579)
Epoch 80, loss: 3.4212, val mf1: 0.7896, (best 0.8579)
Epoch 81, loss: 1.4005, val mf1: 0.7298, (best 0.8579)
Epoch 82, loss: 15.8844, val mf1: 0.3718, (best 0.8579)
Epoch 83, loss: 3.4731, val mf1: 0.7251, (best 0.8579)
Epoch 84, loss: 6.8992, val mf1: 0.7413, (best 0.8579)
Epoch 85, loss: 9.4008, val mf1: 0.7505, (best 0.8579)
Epoch 86, loss: 11.0014, val mf1: 0.7520, (best 0.8579)
Epoch 87, loss: 11.7585, val mf1: 0.7514, (best 0.8579)
Epoch 88, loss: 11.7484, val mf1: 0.7483, (best 0.8579)
Epoch 89, loss: 11.0560, val mf1: 0.7400, (best 0.8579)
Epoch 90, loss: 9.7936, val mf1: 0.7238, (best 0.8579)
Epoch 91, loss: 8.0851, val mf1: 0.7027, (best 0.8579)
Epoch 92, loss: 6.1182, val mf1: 0.6471, (best 0.8579)
Epoch 93, loss: 4.3705, val mf1: 0.5525, (best 0.8579)
Epoch 94, loss: 4.9748, val mf1: 0.3559, (best 0.8579)
Epoch 95, loss: 6.5927, val mf1: 0.2981, (best 0.8579)
Epoch 96, loss: 2.5357, val mf1: 0.4918, (best 0.8579)
Epoch 97, loss: 2.5255, val mf1: 0.8100, (best 0.8579)
Epoch 98, loss: 3.8075, val mf1: 0.8470, (best 0.8579)
Epoch 99, loss: 4.3765, val mf1: 0.8541, (best 0.8579)
time cost:  26.518473386764526 s
Test: REC 61.38 PRE 87.94 MF1 85.59 AUC 91.47
MF1-mean: 85.53, MF1-std: 0.37, AUC-mean: 91.24, AUC-std: 0.72
