Using device: cuda
Namespace(dataset='tfinance', train_ratio=0.4, hid_dim=64, num_layers=3, epoch=100, run=1, knn_reconstruct_graph=False, knn_reconstruct_graph_approximate=False, alpha=1.0, top_k=3, save_model=False, model_path='./model', device=device(type='cuda', index=0), choose_model='GCN', hyperparameter_tuning=True)
Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={})
Trying hid_dim: 32, num_layers: 3
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 267.6438, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 176.9135, val mf1: 0.4967, (best 0.4967)
Epoch 2, loss: 87.2318, val mf1: 0.4929, (best 0.4967)
Epoch 3, loss: 89.1084, val mf1: 0.1437, (best 0.4967)
Epoch 4, loss: 123.0996, val mf1: 0.0440, (best 0.4967)
Epoch 5, loss: 101.5845, val mf1: 0.0443, (best 0.4967)
Epoch 6, loss: 55.7150, val mf1: 0.1348, (best 0.4967)
Epoch 7, loss: 36.1162, val mf1: 0.4158, (best 0.4967)
Epoch 8, loss: 47.1404, val mf1: 0.5212, (best 0.5212)
Epoch 9, loss: 49.6421, val mf1: 0.5249, (best 0.5249)
Epoch 10, loss: 37.5005, val mf1: 0.5249, (best 0.5249)
Epoch 11, loss: 13.0756, val mf1: 0.5180, (best 0.5249)
Epoch 12, loss: 36.2050, val mf1: 0.0439, (best 0.5249)
Epoch 13, loss: 43.5586, val mf1: 0.0438, (best 0.5249)
Epoch 14, loss: 22.0129, val mf1: 0.0453, (best 0.5249)
Epoch 15, loss: 10.6639, val mf1: 0.5261, (best 0.5261)
Epoch 16, loss: 23.2531, val mf1: 0.5285, (best 0.5285)
Epoch 17, loss: 25.1364, val mf1: 0.5288, (best 0.5288)
Epoch 18, loss: 17.7679, val mf1: 0.5295, (best 0.5295)
Epoch 19, loss: 3.7978, val mf1: 0.7720, (best 0.7720)
Epoch 20, loss: 10.8613, val mf1: 0.1748, (best 0.7720)
Epoch 21, loss: 18.6327, val mf1: 0.0477, (best 0.7720)
Epoch 22, loss: 8.0247, val mf1: 0.2715, (best 0.7720)
Epoch 23, loss: 4.1329, val mf1: 0.6948, (best 0.7720)
Epoch 24, loss: 10.8420, val mf1: 0.7031, (best 0.7720)
Epoch 25, loss: 12.6603, val mf1: 0.6754, (best 0.7720)
Epoch 26, loss: 7.8473, val mf1: 0.7791, (best 0.7791)
Epoch 27, loss: 4.6580, val mf1: 0.5589, (best 0.7791)
Epoch 28, loss: 6.7714, val mf1: 0.4326, (best 0.7791)
Epoch 29, loss: 9.6888, val mf1: 0.3438, (best 0.7791)
Epoch 30, loss: 8.5896, val mf1: 0.3879, (best 0.7791)
Epoch 31, loss: 5.8902, val mf1: 0.4746, (best 0.7791)
Epoch 32, loss: 5.2284, val mf1: 0.5937, (best 0.7791)
Epoch 33, loss: 7.0828, val mf1: 0.7609, (best 0.7791)
Epoch 34, loss: 8.0445, val mf1: 0.7863, (best 0.7863)
Epoch 35, loss: 6.7834, val mf1: 0.7536, (best 0.7863)
Epoch 36, loss: 5.0675, val mf1: 0.5999, (best 0.7863)
Epoch 37, loss: 5.2086, val mf1: 0.4970, (best 0.7863)
Epoch 38, loss: 6.2815, val mf1: 0.4461, (best 0.7863)
Epoch 39, loss: 6.3954, val mf1: 0.4376, (best 0.7863)
Epoch 40, loss: 5.2122, val mf1: 0.4752, (best 0.7863)
Epoch 41, loss: 4.2990, val mf1: 0.5502, (best 0.7863)
Epoch 42, loss: 4.6919, val mf1: 0.6975, (best 0.7863)
Epoch 43, loss: 5.2214, val mf1: 0.7671, (best 0.7863)
Epoch 44, loss: 4.5316, val mf1: 0.7361, (best 0.7863)
Epoch 45, loss: 3.6033, val mf1: 0.5869, (best 0.7863)
Epoch 46, loss: 3.7721, val mf1: 0.4948, (best 0.7863)
Epoch 47, loss: 4.1710, val mf1: 0.4584, (best 0.7863)
Epoch 48, loss: 3.5123, val mf1: 0.4870, (best 0.7863)
Epoch 49, loss: 2.8255, val mf1: 0.5824, (best 0.7863)
Epoch 50, loss: 3.1408, val mf1: 0.7536, (best 0.7863)
Epoch 51, loss: 3.1100, val mf1: 0.7828, (best 0.7863)
Epoch 52, loss: 2.3064, val mf1: 0.6727, (best 0.7863)
Epoch 53, loss: 2.3736, val mf1: 0.5035, (best 0.7863)
Epoch 54, loss: 2.5217, val mf1: 0.4726, (best 0.7863)
Epoch 55, loss: 1.7274, val mf1: 0.6692, (best 0.7863)
Epoch 56, loss: 2.1941, val mf1: 0.7974, (best 0.7974)
Epoch 57, loss: 1.7951, val mf1: 0.7887, (best 0.7974)
Epoch 58, loss: 1.5961, val mf1: 0.5301, (best 0.7974)
Epoch 59, loss: 1.3891, val mf1: 0.5685, (best 0.7974)
Epoch 60, loss: 1.6186, val mf1: 0.7976, (best 0.7976)
Epoch 61, loss: 1.5234, val mf1: 0.7900, (best 0.7976)
Epoch 62, loss: 1.3499, val mf1: 0.5822, (best 0.7976)
Epoch 63, loss: 1.0579, val mf1: 0.6825, (best 0.7976)
Epoch 64, loss: 1.2004, val mf1: 0.7332, (best 0.7976)
Epoch 65, loss: 1.0455, val mf1: 0.6678, (best 0.7976)
Epoch 66, loss: 1.1560, val mf1: 0.6181, (best 0.7976)
Epoch 67, loss: 1.2909, val mf1: 0.7296, (best 0.7976)
Epoch 68, loss: 1.0638, val mf1: 0.6996, (best 0.7976)
Epoch 69, loss: 1.9903, val mf1: 0.4614, (best 0.7976)
Epoch 70, loss: 5.6531, val mf1: 0.6759, (best 0.7976)
Epoch 71, loss: 5.6379, val mf1: 0.7454, (best 0.7976)
Epoch 72, loss: 0.8927, val mf1: 0.6609, (best 0.7976)
Epoch 73, loss: 7.1414, val mf1: 0.0932, (best 0.7976)
Epoch 74, loss: 2.7390, val mf1: 0.8334, (best 0.8334)
Epoch 75, loss: 5.8314, val mf1: 0.8091, (best 0.8334)
Epoch 76, loss: 4.5985, val mf1: 0.8382, (best 0.8382)
Epoch 77, loss: 1.9009, val mf1: 0.7825, (best 0.8382)
Epoch 78, loss: 5.1020, val mf1: 0.2821, (best 0.8382)
Epoch 79, loss: 2.8250, val mf1: 0.4694, (best 0.8382)
Epoch 80, loss: 2.4976, val mf1: 0.7807, (best 0.8382)
Epoch 81, loss: 3.8333, val mf1: 0.8288, (best 0.8382)
Epoch 82, loss: 3.6217, val mf1: 0.8233, (best 0.8382)
Epoch 83, loss: 2.1944, val mf1: 0.7699, (best 0.8382)
Epoch 84, loss: 2.5304, val mf1: 0.4750, (best 0.8382)
Epoch 85, loss: 3.1468, val mf1: 0.4112, (best 0.8382)
Epoch 86, loss: 1.7333, val mf1: 0.7475, (best 0.8382)
Epoch 87, loss: 2.7849, val mf1: 0.8296, (best 0.8382)
Epoch 88, loss: 2.6692, val mf1: 0.8277, (best 0.8382)
Epoch 89, loss: 1.4459, val mf1: 0.7796, (best 0.8382)
Epoch 90, loss: 2.7729, val mf1: 0.3911, (best 0.8382)
Epoch 91, loss: 1.1840, val mf1: 0.6310, (best 0.8382)
Epoch 92, loss: 1.8320, val mf1: 0.8270, (best 0.8382)
Epoch 93, loss: 1.8793, val mf1: 0.8327, (best 0.8382)
Epoch 94, loss: 0.9571, val mf1: 0.7745, (best 0.8382)
Epoch 95, loss: 2.7814, val mf1: 0.3520, (best 0.8382)
Epoch 96, loss: 3.0293, val mf1: 0.8390, (best 0.8390)
Epoch 97, loss: 5.6466, val mf1: 0.8062, (best 0.8390)
Epoch 98, loss: 3.5937, val mf1: 0.8363, (best 0.8390)
Epoch 99, loss: 0.8597, val mf1: 0.6881, (best 0.8390)
time cost:  16.458333730697632 s
Test: REC 57.10 PRE 82.31 MF1 83.06 AUC 87.56
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=32, normalization=both, activation=None)
    (1): GraphConv(in=32, out=32, normalization=both, activation=None)
    (2): GraphConv(in=32, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 165.2096, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 93.7517, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 31.0041, val mf1: 0.4967, (best 0.4967)
Epoch 3, loss: 47.3556, val mf1: 0.0451, (best 0.4967)
Epoch 4, loss: 44.4227, val mf1: 0.0442, (best 0.4967)
Epoch 5, loss: 15.0547, val mf1: 0.0558, (best 0.4967)
Epoch 6, loss: 12.2258, val mf1: 0.5289, (best 0.5289)
Epoch 7, loss: 21.2714, val mf1: 0.5291, (best 0.5291)
Epoch 8, loss: 22.7394, val mf1: 0.5291, (best 0.5291)
Epoch 9, loss: 18.2145, val mf1: 0.5291, (best 0.5291)
Epoch 10, loss: 8.1396, val mf1: 0.6771, (best 0.6771)
Epoch 11, loss: 5.6323, val mf1: 0.4715, (best 0.6771)
Epoch 12, loss: 11.3289, val mf1: 0.3155, (best 0.6771)
Epoch 13, loss: 14.4426, val mf1: 0.2620, (best 0.6771)
Epoch 14, loss: 12.3616, val mf1: 0.2991, (best 0.6771)
Epoch 15, loss: 7.8037, val mf1: 0.4194, (best 0.6771)
Epoch 16, loss: 4.7839, val mf1: 0.5067, (best 0.6771)
Epoch 17, loss: 5.7936, val mf1: 0.7471, (best 0.7471)
Epoch 18, loss: 7.8257, val mf1: 0.7051, (best 0.7471)
Epoch 19, loss: 5.8033, val mf1: 0.7462, (best 0.7471)
Epoch 20, loss: 4.1842, val mf1: 0.5812, (best 0.7471)
Epoch 21, loss: 4.4601, val mf1: 0.4952, (best 0.7471)
Epoch 22, loss: 5.0986, val mf1: 0.4584, (best 0.7471)
Epoch 23, loss: 5.0415, val mf1: 0.4421, (best 0.7471)
Epoch 24, loss: 3.6894, val mf1: 0.4622, (best 0.7471)
Epoch 25, loss: 2.1374, val mf1: 0.6710, (best 0.7471)
Epoch 26, loss: 3.9600, val mf1: 0.6148, (best 0.7471)
Epoch 27, loss: 1.8849, val mf1: 0.5634, (best 0.7471)
Epoch 28, loss: 3.0486, val mf1: 0.4298, (best 0.7471)
Epoch 29, loss: 2.6252, val mf1: 0.4534, (best 0.7471)
Epoch 30, loss: 1.4777, val mf1: 0.6728, (best 0.7471)
Epoch 31, loss: 2.7926, val mf1: 0.6803, (best 0.7471)
Epoch 32, loss: 1.4877, val mf1: 0.7181, (best 0.7471)
Epoch 33, loss: 1.7106, val mf1: 0.5241, (best 0.7471)
Epoch 34, loss: 2.1033, val mf1: 0.4724, (best 0.7471)
Epoch 35, loss: 1.4817, val mf1: 0.5474, (best 0.7471)
Epoch 36, loss: 1.2254, val mf1: 0.7625, (best 0.7625)
Epoch 37, loss: 1.7414, val mf1: 0.7687, (best 0.7687)
Epoch 38, loss: 1.0141, val mf1: 0.7497, (best 0.7687)
Epoch 39, loss: 1.2783, val mf1: 0.5441, (best 0.7687)
Epoch 40, loss: 1.3432, val mf1: 0.5264, (best 0.7687)
Epoch 41, loss: 0.8298, val mf1: 0.7480, (best 0.7687)
Epoch 42, loss: 1.3086, val mf1: 0.7840, (best 0.7840)
Epoch 43, loss: 0.7970, val mf1: 0.7613, (best 0.7840)
Epoch 44, loss: 1.2638, val mf1: 0.5418, (best 0.7840)
Epoch 45, loss: 0.8333, val mf1: 0.7897, (best 0.7897)
Epoch 46, loss: 1.1903, val mf1: 0.8133, (best 0.8133)
Epoch 47, loss: 0.8463, val mf1: 0.7944, (best 0.8133)
Epoch 48, loss: 1.0047, val mf1: 0.5919, (best 0.8133)
Epoch 49, loss: 1.0683, val mf1: 0.5709, (best 0.8133)
Epoch 50, loss: 0.7970, val mf1: 0.7491, (best 0.8133)
Epoch 51, loss: 0.9359, val mf1: 0.8226, (best 0.8226)
Epoch 52, loss: 0.8007, val mf1: 0.8164, (best 0.8226)
Epoch 53, loss: 0.7192, val mf1: 0.7043, (best 0.8226)
Epoch 54, loss: 0.8255, val mf1: 0.6724, (best 0.8226)
Epoch 55, loss: 1.2876, val mf1: 0.8276, (best 0.8276)
Epoch 56, loss: 1.0998, val mf1: 0.8324, (best 0.8324)
Epoch 57, loss: 0.7492, val mf1: 0.6925, (best 0.8324)
Epoch 58, loss: 1.1075, val mf1: 0.5613, (best 0.8324)
Epoch 59, loss: 1.1618, val mf1: 0.8468, (best 0.8468)
Epoch 60, loss: 1.7289, val mf1: 0.8422, (best 0.8468)
Epoch 61, loss: 1.1146, val mf1: 0.8500, (best 0.8500)
Epoch 62, loss: 1.0362, val mf1: 0.5627, (best 0.8500)
Epoch 63, loss: 1.6248, val mf1: 0.4727, (best 0.8500)
Epoch 64, loss: 0.8526, val mf1: 0.7944, (best 0.8500)
Epoch 65, loss: 1.4428, val mf1: 0.8472, (best 0.8500)
Epoch 66, loss: 1.4010, val mf1: 0.8479, (best 0.8500)
Epoch 67, loss: 0.7489, val mf1: 0.8207, (best 0.8500)
Epoch 68, loss: 1.4089, val mf1: 0.4979, (best 0.8500)
Epoch 69, loss: 0.8237, val mf1: 0.8520, (best 0.8520)
Epoch 70, loss: 1.3736, val mf1: 0.8501, (best 0.8520)
Epoch 71, loss: 0.9966, val mf1: 0.8537, (best 0.8537)
Epoch 72, loss: 0.7163, val mf1: 0.6794, (best 0.8537)
Epoch 73, loss: 1.4929, val mf1: 0.4489, (best 0.8537)
Epoch 74, loss: 1.6277, val mf1: 0.8458, (best 0.8537)
Epoch 75, loss: 2.8060, val mf1: 0.8158, (best 0.8537)
Epoch 76, loss: 1.7036, val mf1: 0.8513, (best 0.8537)
Epoch 77, loss: 0.7738, val mf1: 0.6729, (best 0.8537)
Epoch 78, loss: 2.9825, val mf1: 0.2939, (best 0.8537)
Epoch 79, loss: 0.9363, val mf1: 0.8306, (best 0.8537)
Epoch 80, loss: 2.0868, val mf1: 0.8404, (best 0.8537)
Epoch 81, loss: 2.3367, val mf1: 0.8393, (best 0.8537)
Epoch 82, loss: 1.5325, val mf1: 0.8386, (best 0.8537)
Epoch 83, loss: 1.1476, val mf1: 0.5810, (best 0.8537)
Epoch 84, loss: 1.9977, val mf1: 0.4530, (best 0.8537)
Epoch 85, loss: 1.3053, val mf1: 0.5230, (best 0.8537)
Epoch 86, loss: 1.0250, val mf1: 0.8315, (best 0.8537)
Epoch 87, loss: 1.4589, val mf1: 0.8507, (best 0.8537)
Epoch 88, loss: 1.2296, val mf1: 0.8533, (best 0.8537)
Epoch 89, loss: 0.6600, val mf1: 0.7919, (best 0.8537)
Epoch 90, loss: 1.5713, val mf1: 0.4349, (best 0.8537)
Epoch 91, loss: 1.0365, val mf1: 0.8542, (best 0.8542)
Epoch 92, loss: 1.9168, val mf1: 0.8378, (best 0.8542)
Epoch 93, loss: 1.2645, val mf1: 0.8545, (best 0.8545)
Epoch 94, loss: 0.6483, val mf1: 0.7286, (best 0.8545)
Epoch 95, loss: 2.3582, val mf1: 0.3581, (best 0.8545)
Epoch 96, loss: 1.1589, val mf1: 0.8562, (best 0.8562)
Epoch 97, loss: 2.4211, val mf1: 0.8383, (best 0.8562)
Epoch 98, loss: 2.0651, val mf1: 0.8508, (best 0.8562)
Epoch 99, loss: 0.9397, val mf1: 0.8389, (best 0.8562)
time cost:  15.077343225479126 s
Test: REC 62.07 PRE 77.19 MF1 83.73 AUC 90.08
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=32, normalization=both, activation=None)
    (1): GraphConv(in=32, out=32, normalization=both, activation=None)
    (2): GraphConv(in=32, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 250.5812, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 158.5462, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 69.4339, val mf1: 0.5291, (best 0.5291)
Epoch 3, loss: 15.2052, val mf1: 0.0746, (best 0.5291)
Epoch 4, loss: 41.6370, val mf1: 0.0495, (best 0.5291)
Epoch 5, loss: 26.6429, val mf1: 0.0560, (best 0.5291)
Epoch 6, loss: 3.7681, val mf1: 0.4682, (best 0.5291)
Epoch 7, loss: 14.2996, val mf1: 0.5969, (best 0.5969)
Epoch 8, loss: 22.6555, val mf1: 0.5331, (best 0.5969)
Epoch 9, loss: 20.3237, val mf1: 0.5429, (best 0.5969)
Epoch 10, loss: 10.4140, val mf1: 0.7970, (best 0.7970)
Epoch 11, loss: 4.5847, val mf1: 0.5682, (best 0.7970)
Epoch 12, loss: 9.4671, val mf1: 0.3301, (best 0.7970)
Epoch 13, loss: 14.1629, val mf1: 0.2548, (best 0.7970)
Epoch 14, loss: 12.7073, val mf1: 0.2810, (best 0.7970)
Epoch 15, loss: 7.6278, val mf1: 0.4125, (best 0.7970)
Epoch 16, loss: 5.3506, val mf1: 0.5650, (best 0.7970)
Epoch 17, loss: 7.5307, val mf1: 0.8210, (best 0.8210)
Epoch 18, loss: 9.9986, val mf1: 0.8335, (best 0.8335)
Epoch 19, loss: 10.2062, val mf1: 0.8347, (best 0.8347)
Epoch 20, loss: 8.3136, val mf1: 0.8239, (best 0.8347)
Epoch 21, loss: 5.9187, val mf1: 0.6716, (best 0.8347)
Epoch 22, loss: 5.7786, val mf1: 0.5120, (best 0.8347)
Epoch 23, loss: 7.1098, val mf1: 0.4440, (best 0.8347)
Epoch 24, loss: 7.8849, val mf1: 0.4070, (best 0.8347)
Epoch 25, loss: 7.0164, val mf1: 0.4278, (best 0.8347)
Epoch 26, loss: 5.3897, val mf1: 0.4903, (best 0.8347)
Epoch 27, loss: 4.6498, val mf1: 0.5905, (best 0.8347)
Epoch 28, loss: 5.3800, val mf1: 0.7776, (best 0.8347)
Epoch 29, loss: 5.9878, val mf1: 0.8266, (best 0.8347)
Epoch 30, loss: 5.3961, val mf1: 0.8175, (best 0.8347)
Epoch 31, loss: 4.1677, val mf1: 0.6830, (best 0.8347)
Epoch 32, loss: 3.8462, val mf1: 0.5329, (best 0.8347)
Epoch 33, loss: 4.4440, val mf1: 0.4645, (best 0.8347)
Epoch 34, loss: 4.5191, val mf1: 0.4451, (best 0.8347)
Epoch 35, loss: 3.5968, val mf1: 0.4953, (best 0.8347)
Epoch 36, loss: 2.9990, val mf1: 0.6104, (best 0.8347)
Epoch 37, loss: 3.3933, val mf1: 0.7846, (best 0.8347)
Epoch 38, loss: 3.4993, val mf1: 0.8122, (best 0.8347)
Epoch 39, loss: 2.7921, val mf1: 0.7574, (best 0.8347)
Epoch 40, loss: 2.3105, val mf1: 0.5635, (best 0.8347)
Epoch 41, loss: 2.7207, val mf1: 0.4701, (best 0.8347)
Epoch 42, loss: 2.4835, val mf1: 0.4761, (best 0.8347)
Epoch 43, loss: 1.8290, val mf1: 0.6170, (best 0.8347)
Epoch 44, loss: 2.1301, val mf1: 0.7695, (best 0.8347)
Epoch 45, loss: 2.1069, val mf1: 0.7677, (best 0.8347)
Epoch 46, loss: 1.5402, val mf1: 0.6807, (best 0.8347)
Epoch 47, loss: 1.8336, val mf1: 0.4798, (best 0.8347)
Epoch 48, loss: 1.6110, val mf1: 0.5180, (best 0.8347)
Epoch 49, loss: 1.4962, val mf1: 0.6953, (best 0.8347)
Epoch 50, loss: 1.7551, val mf1: 0.7108, (best 0.8347)
Epoch 51, loss: 1.3747, val mf1: 0.6640, (best 0.8347)
Epoch 52, loss: 2.4799, val mf1: 0.4122, (best 0.8347)
Epoch 53, loss: 2.2299, val mf1: 0.7073, (best 0.8347)
Epoch 54, loss: 2.9439, val mf1: 0.6934, (best 0.8347)
Epoch 55, loss: 1.5028, val mf1: 0.6855, (best 0.8347)
Epoch 56, loss: 4.2744, val mf1: 0.2783, (best 0.8347)
Epoch 57, loss: 1.5468, val mf1: 0.7042, (best 0.8347)
Epoch 58, loss: 2.5744, val mf1: 0.7397, (best 0.8347)
Epoch 59, loss: 1.9277, val mf1: 0.7479, (best 0.8347)
Epoch 60, loss: 1.3101, val mf1: 0.5772, (best 0.8347)
Epoch 61, loss: 2.5501, val mf1: 0.3720, (best 0.8347)
Epoch 62, loss: 2.1673, val mf1: 0.7814, (best 0.8347)
Epoch 63, loss: 3.8291, val mf1: 0.7774, (best 0.8347)
Epoch 64, loss: 2.9537, val mf1: 0.7990, (best 0.8347)
Epoch 65, loss: 1.4489, val mf1: 0.6697, (best 0.8347)
Epoch 66, loss: 3.2187, val mf1: 0.3627, (best 0.8347)
Epoch 67, loss: 2.3930, val mf1: 0.4390, (best 0.8347)
Epoch 68, loss: 1.7367, val mf1: 0.7569, (best 0.8347)
Epoch 69, loss: 2.7064, val mf1: 0.8165, (best 0.8347)
Epoch 70, loss: 2.5405, val mf1: 0.8175, (best 0.8347)
Epoch 71, loss: 1.6243, val mf1: 0.7112, (best 0.8347)
Epoch 72, loss: 2.2111, val mf1: 0.4674, (best 0.8347)
Epoch 73, loss: 2.2852, val mf1: 0.4568, (best 0.8347)
Epoch 74, loss: 1.5029, val mf1: 0.6513, (best 0.8347)
Epoch 75, loss: 2.0524, val mf1: 0.8058, (best 0.8347)
Epoch 76, loss: 2.0256, val mf1: 0.8024, (best 0.8347)
Epoch 77, loss: 1.3679, val mf1: 0.7033, (best 0.8347)
Epoch 78, loss: 1.8052, val mf1: 0.4774, (best 0.8347)
Epoch 79, loss: 1.5137, val mf1: 0.5154, (best 0.8347)
Epoch 80, loss: 1.3245, val mf1: 0.7471, (best 0.8347)
Epoch 81, loss: 1.5973, val mf1: 0.7886, (best 0.8347)
Epoch 82, loss: 1.1761, val mf1: 0.7334, (best 0.8347)
Epoch 83, loss: 1.4561, val mf1: 0.5160, (best 0.8347)
Epoch 84, loss: 1.2923, val mf1: 0.7590, (best 0.8347)
Epoch 85, loss: 1.6088, val mf1: 0.7798, (best 0.8347)
Epoch 86, loss: 1.0590, val mf1: 0.7269, (best 0.8347)
Epoch 87, loss: 2.3794, val mf1: 0.3902, (best 0.8347)
Epoch 88, loss: 1.9725, val mf1: 0.7887, (best 0.8347)
Epoch 89, loss: 3.0133, val mf1: 0.7833, (best 0.8347)
Epoch 90, loss: 1.6232, val mf1: 0.7934, (best 0.8347)
Epoch 91, loss: 2.0844, val mf1: 0.3792, (best 0.8347)
Epoch 92, loss: 1.1910, val mf1: 0.7698, (best 0.8347)
Epoch 93, loss: 1.7628, val mf1: 0.8165, (best 0.8347)
Epoch 94, loss: 1.3983, val mf1: 0.7940, (best 0.8347)
Epoch 95, loss: 1.3132, val mf1: 0.5517, (best 0.8347)
Epoch 96, loss: 1.6555, val mf1: 0.4868, (best 0.8347)
Epoch 97, loss: 1.1650, val mf1: 0.6916, (best 0.8347)
Epoch 98, loss: 1.5174, val mf1: 0.8053, (best 0.8347)
Epoch 99, loss: 1.3795, val mf1: 0.7945, (best 0.8347)
time cost:  15.302855014801025 s
Test: REC 51.59 PRE 84.42 MF1 81.33 AUC 85.11
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=32, normalization=both, activation=None)
    (1): GraphConv(in=32, out=32, normalization=both, activation=None)
    (2): GraphConv(in=32, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
Average AUC: 0.5476752192191094, Average Recall: 0.638594013365552, Average Precision: 0.07373200227543748, Average F1: 0.13490737319076818 in 3 runs, with hid_dim: 32, num_layers: 3
Trying hid_dim: 32, num_layers: 4
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 105.9021, val mf1: 0.0451, (best 0.0451)
Epoch 1, loss: 72.1460, val mf1: 0.4875, (best 0.4875)
Epoch 2, loss: 78.4484, val mf1: 0.4963, (best 0.4963)
Epoch 3, loss: 50.4475, val mf1: 0.4946, (best 0.4963)
Epoch 4, loss: 36.0123, val mf1: 0.2113, (best 0.4963)
Epoch 5, loss: 57.7058, val mf1: 0.0470, (best 0.4963)
Epoch 6, loss: 44.1380, val mf1: 0.0490, (best 0.4963)
Epoch 7, loss: 21.0231, val mf1: 0.3422, (best 0.4963)
Epoch 8, loss: 34.9291, val mf1: 0.4962, (best 0.4963)
Epoch 9, loss: 40.0560, val mf1: 0.4967, (best 0.4967)
Epoch 10, loss: 31.4763, val mf1: 0.5289, (best 0.5289)
Epoch 11, loss: 11.7052, val mf1: 0.5233, (best 0.5289)
Epoch 12, loss: 27.4920, val mf1: 0.0448, (best 0.5289)
Epoch 13, loss: 34.8825, val mf1: 0.0439, (best 0.5289)
Epoch 14, loss: 21.4797, val mf1: 0.0451, (best 0.5289)
Epoch 15, loss: 2.6311, val mf1: 0.5257, (best 0.5289)
Epoch 16, loss: 10.1848, val mf1: 0.5294, (best 0.5294)
Epoch 17, loss: 8.4034, val mf1: 0.5289, (best 0.5294)
Epoch 18, loss: 1.4189, val mf1: 0.5958, (best 0.5958)
Epoch 19, loss: 5.5105, val mf1: 0.2305, (best 0.5958)
Epoch 20, loss: 5.0032, val mf1: 0.2481, (best 0.5958)
Epoch 21, loss: 1.5703, val mf1: 0.6739, (best 0.6739)
Epoch 22, loss: 5.5513, val mf1: 0.5340, (best 0.6739)
Epoch 23, loss: 1.9654, val mf1: 0.7170, (best 0.7170)
Epoch 24, loss: 3.1288, val mf1: 0.4316, (best 0.7170)
Epoch 25, loss: 3.9644, val mf1: 0.3824, (best 0.7170)
Epoch 26, loss: 2.1111, val mf1: 0.5218, (best 0.7170)
Epoch 27, loss: 2.9255, val mf1: 0.7446, (best 0.7446)
Epoch 28, loss: 3.3946, val mf1: 0.7429, (best 0.7446)
Epoch 29, loss: 1.9791, val mf1: 0.6350, (best 0.7446)
Epoch 30, loss: 2.7426, val mf1: 0.4664, (best 0.7446)
Epoch 31, loss: 3.0532, val mf1: 0.4462, (best 0.7446)
Epoch 32, loss: 2.0632, val mf1: 0.5306, (best 0.7446)
Epoch 33, loss: 2.4245, val mf1: 0.7787, (best 0.7787)
Epoch 34, loss: 2.2249, val mf1: 0.7873, (best 0.7873)
Epoch 35, loss: 1.8016, val mf1: 0.6044, (best 0.7873)
Epoch 36, loss: 2.1024, val mf1: 0.5043, (best 0.7873)
Epoch 37, loss: 1.9657, val mf1: 0.5167, (best 0.7873)
Epoch 38, loss: 1.5950, val mf1: 0.6672, (best 0.7873)
Epoch 39, loss: 1.8581, val mf1: 0.8213, (best 0.8213)
Epoch 40, loss: 1.5299, val mf1: 0.8130, (best 0.8213)
Epoch 41, loss: 1.4281, val mf1: 0.5699, (best 0.8213)
Epoch 42, loss: 1.4271, val mf1: 0.5399, (best 0.8213)
Epoch 43, loss: 1.0026, val mf1: 0.8241, (best 0.8241)
Epoch 44, loss: 1.1274, val mf1: 0.8400, (best 0.8400)
Epoch 45, loss: 1.3922, val mf1: 0.5086, (best 0.8400)
Epoch 46, loss: 0.8080, val mf1: 0.8113, (best 0.8400)
Epoch 47, loss: 0.6404, val mf1: 0.7924, (best 0.8400)
Epoch 48, loss: 1.2522, val mf1: 0.5400, (best 0.8400)
Epoch 49, loss: 2.1275, val mf1: 0.6173, (best 0.8400)
Epoch 50, loss: 1.7125, val mf1: 0.4121, (best 0.8400)
Epoch 51, loss: 0.6078, val mf1: 0.7954, (best 0.8400)
Epoch 52, loss: 2.2926, val mf1: 0.7050, (best 0.8400)
Epoch 53, loss: 1.8761, val mf1: 0.3998, (best 0.8400)
Epoch 54, loss: 0.7323, val mf1: 0.7639, (best 0.8400)
Epoch 55, loss: 1.4498, val mf1: 0.8364, (best 0.8400)
Epoch 56, loss: 1.2140, val mf1: 0.8406, (best 0.8406)
Epoch 57, loss: 1.0028, val mf1: 0.5878, (best 0.8406)
Epoch 58, loss: 0.8803, val mf1: 0.6524, (best 0.8406)
Epoch 59, loss: 1.1228, val mf1: 0.8422, (best 0.8422)
Epoch 60, loss: 1.0484, val mf1: 0.8416, (best 0.8422)
Epoch 61, loss: 0.8502, val mf1: 0.6702, (best 0.8422)
Epoch 62, loss: 0.6083, val mf1: 0.7830, (best 0.8422)
Epoch 63, loss: 0.9114, val mf1: 0.8446, (best 0.8446)
Epoch 64, loss: 0.5211, val mf1: 0.8075, (best 0.8446)
Epoch 65, loss: 0.7413, val mf1: 0.7308, (best 0.8446)
Epoch 66, loss: 1.7718, val mf1: 0.8242, (best 0.8446)
Epoch 67, loss: 0.5298, val mf1: 0.8557, (best 0.8557)
Epoch 68, loss: 3.1812, val mf1: 0.2064, (best 0.8557)
Epoch 69, loss: 4.0125, val mf1: 0.6088, (best 0.8557)
Epoch 70, loss: 2.9129, val mf1: 0.7081, (best 0.8557)
Epoch 71, loss: 3.1194, val mf1: 0.1851, (best 0.8557)
Epoch 72, loss: 0.6427, val mf1: 0.8357, (best 0.8557)
Epoch 73, loss: 1.4018, val mf1: 0.8482, (best 0.8557)
Epoch 74, loss: 1.2458, val mf1: 0.8423, (best 0.8557)
Epoch 75, loss: 1.0866, val mf1: 0.6285, (best 0.8557)
Epoch 76, loss: 1.4273, val mf1: 0.5254, (best 0.8557)
Epoch 77, loss: 1.0876, val mf1: 0.8133, (best 0.8557)
Epoch 78, loss: 1.3857, val mf1: 0.8378, (best 0.8557)
Epoch 79, loss: 1.1946, val mf1: 0.8377, (best 0.8557)
Epoch 80, loss: 1.1480, val mf1: 0.6204, (best 0.8557)
Epoch 81, loss: 1.1431, val mf1: 0.5975, (best 0.8557)
Epoch 82, loss: 0.9506, val mf1: 0.8360, (best 0.8557)
Epoch 83, loss: 0.9817, val mf1: 0.8373, (best 0.8557)
Epoch 84, loss: 0.7183, val mf1: 0.8172, (best 0.8557)
Epoch 85, loss: 0.8753, val mf1: 0.6596, (best 0.8557)
Epoch 86, loss: 0.7961, val mf1: 0.8410, (best 0.8557)
Epoch 87, loss: 0.7991, val mf1: 0.8443, (best 0.8557)
Epoch 88, loss: 0.5896, val mf1: 0.7655, (best 0.8557)
Epoch 89, loss: 0.4753, val mf1: 0.8048, (best 0.8557)
Epoch 90, loss: 0.5431, val mf1: 0.8317, (best 0.8557)
Epoch 91, loss: 0.4326, val mf1: 0.8045, (best 0.8557)
Epoch 92, loss: 0.5034, val mf1: 0.7753, (best 0.8557)
Epoch 93, loss: 0.9555, val mf1: 0.8246, (best 0.8557)
Epoch 94, loss: 0.4354, val mf1: 0.8175, (best 0.8557)
Epoch 95, loss: 2.7578, val mf1: 0.3539, (best 0.8557)
Epoch 96, loss: 5.6584, val mf1: 0.5318, (best 0.8557)
Epoch 97, loss: 4.8863, val mf1: 0.5565, (best 0.8557)
Epoch 98, loss: 2.5024, val mf1: 0.2955, (best 0.8557)
Epoch 99, loss: 0.5816, val mf1: 0.8402, (best 0.8557)
time cost:  16.001511812210083 s
Test: REC 59.31 PRE 81.90 MF1 83.76 AUC 90.72
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=32, normalization=both, activation=None)
    (1-2): 2 x GraphConv(in=32, out=32, normalization=both, activation=None)
    (3): GraphConv(in=32, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 431.3569, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 254.0938, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 85.4252, val mf1: 0.4966, (best 0.4966)
Epoch 3, loss: 88.0574, val mf1: 0.0438, (best 0.4966)
Epoch 4, loss: 109.1984, val mf1: 0.0438, (best 0.4966)
Epoch 5, loss: 58.4673, val mf1: 0.0439, (best 0.4966)
Epoch 6, loss: 5.6764, val mf1: 0.4788, (best 0.4966)
Epoch 7, loss: 25.9693, val mf1: 0.5257, (best 0.5257)
Epoch 8, loss: 33.4429, val mf1: 0.5269, (best 0.5269)
Epoch 9, loss: 24.5633, val mf1: 0.5252, (best 0.5269)
Epoch 10, loss: 9.2213, val mf1: 0.6278, (best 0.6278)
Epoch 11, loss: 12.9032, val mf1: 0.4293, (best 0.6278)
Epoch 12, loss: 18.6061, val mf1: 0.3268, (best 0.6278)
Epoch 13, loss: 16.8671, val mf1: 0.3087, (best 0.6278)
Epoch 14, loss: 14.0163, val mf1: 0.3621, (best 0.6278)
Epoch 15, loss: 9.9230, val mf1: 0.4400, (best 0.6278)
Epoch 16, loss: 7.3180, val mf1: 0.5199, (best 0.6278)
Epoch 17, loss: 8.0959, val mf1: 0.6645, (best 0.6645)
Epoch 18, loss: 10.7869, val mf1: 0.7364, (best 0.7364)
Epoch 19, loss: 11.1282, val mf1: 0.7441, (best 0.7441)
Epoch 20, loss: 8.7410, val mf1: 0.7263, (best 0.7441)
Epoch 21, loss: 6.5440, val mf1: 0.5976, (best 0.7441)
Epoch 22, loss: 6.8059, val mf1: 0.5021, (best 0.7441)
Epoch 23, loss: 7.9984, val mf1: 0.4542, (best 0.7441)
Epoch 24, loss: 8.5085, val mf1: 0.4383, (best 0.7441)
Epoch 25, loss: 7.9208, val mf1: 0.4470, (best 0.7441)
Epoch 26, loss: 6.6524, val mf1: 0.4789, (best 0.7441)
Epoch 27, loss: 5.7889, val mf1: 0.5360, (best 0.7441)
Epoch 28, loss: 6.1187, val mf1: 0.6349, (best 0.7441)
Epoch 29, loss: 6.9598, val mf1: 0.6837, (best 0.7441)
Epoch 30, loss: 6.6016, val mf1: 0.6743, (best 0.7441)
Epoch 31, loss: 5.5403, val mf1: 0.6051, (best 0.7441)
Epoch 32, loss: 5.3067, val mf1: 0.5250, (best 0.7441)
Epoch 33, loss: 5.7184, val mf1: 0.4834, (best 0.7441)
Epoch 34, loss: 5.9400, val mf1: 0.4703, (best 0.7441)
Epoch 35, loss: 5.5503, val mf1: 0.4798, (best 0.7441)
Epoch 36, loss: 4.9059, val mf1: 0.5162, (best 0.7441)
Epoch 37, loss: 4.6905, val mf1: 0.5803, (best 0.7441)
Epoch 38, loss: 4.9973, val mf1: 0.6441, (best 0.7441)
Epoch 39, loss: 4.9486, val mf1: 0.6513, (best 0.7441)
Epoch 40, loss: 4.3750, val mf1: 0.5995, (best 0.7441)
Epoch 41, loss: 4.1723, val mf1: 0.5313, (best 0.7441)
Epoch 42, loss: 4.3252, val mf1: 0.4975, (best 0.7441)
Epoch 43, loss: 4.2985, val mf1: 0.4904, (best 0.7441)
Epoch 44, loss: 3.9133, val mf1: 0.5133, (best 0.7441)
Epoch 45, loss: 3.6149, val mf1: 0.5665, (best 0.7441)
Epoch 46, loss: 3.6906, val mf1: 0.6274, (best 0.7441)
Epoch 47, loss: 3.6379, val mf1: 0.6391, (best 0.7441)
Epoch 48, loss: 3.2630, val mf1: 0.5916, (best 0.7441)
Epoch 49, loss: 3.1735, val mf1: 0.5289, (best 0.7441)
Epoch 50, loss: 3.2313, val mf1: 0.5038, (best 0.7441)
Epoch 51, loss: 3.0228, val mf1: 0.5177, (best 0.7441)
Epoch 52, loss: 2.7713, val mf1: 0.5701, (best 0.7441)
Epoch 53, loss: 2.8194, val mf1: 0.6262, (best 0.7441)
Epoch 54, loss: 2.6856, val mf1: 0.6220, (best 0.7441)
Epoch 55, loss: 2.4631, val mf1: 0.5616, (best 0.7441)
Epoch 56, loss: 2.4957, val mf1: 0.5189, (best 0.7441)
Epoch 57, loss: 2.3529, val mf1: 0.5266, (best 0.7441)
Epoch 58, loss: 2.1622, val mf1: 0.5857, (best 0.7441)
Epoch 59, loss: 2.2038, val mf1: 0.6209, (best 0.7441)
Epoch 60, loss: 1.9645, val mf1: 0.5892, (best 0.7441)
Epoch 61, loss: 1.9476, val mf1: 0.5325, (best 0.7441)
Epoch 62, loss: 1.8275, val mf1: 0.5371, (best 0.7441)
Epoch 63, loss: 1.6959, val mf1: 0.5988, (best 0.7441)
Epoch 64, loss: 1.6428, val mf1: 0.5949, (best 0.7441)
Epoch 65, loss: 1.5338, val mf1: 0.5424, (best 0.7441)
Epoch 66, loss: 1.4455, val mf1: 0.5406, (best 0.7441)
Epoch 67, loss: 1.3930, val mf1: 0.5783, (best 0.7441)
Epoch 68, loss: 1.2181, val mf1: 0.5579, (best 0.7441)
Epoch 69, loss: 1.1490, val mf1: 0.5489, (best 0.7441)
Epoch 70, loss: 1.1825, val mf1: 0.5538, (best 0.7441)
Epoch 71, loss: 1.5109, val mf1: 0.4796, (best 0.7441)
Epoch 72, loss: 1.3629, val mf1: 0.5363, (best 0.7441)
Epoch 73, loss: 3.1336, val mf1: 0.2712, (best 0.7441)
Epoch 74, loss: 6.5521, val mf1: 0.5257, (best 0.7441)
Epoch 75, loss: 4.6745, val mf1: 0.5253, (best 0.7441)
Epoch 76, loss: 6.8499, val mf1: 0.1340, (best 0.7441)
Epoch 77, loss: 2.0185, val mf1: 0.4392, (best 0.7441)
Epoch 78, loss: 7.0188, val mf1: 0.5293, (best 0.7441)
Epoch 79, loss: 7.2402, val mf1: 0.5379, (best 0.7441)
Epoch 80, loss: 1.5370, val mf1: 0.6810, (best 0.7441)
Epoch 81, loss: 5.6477, val mf1: 0.1964, (best 0.7441)
Epoch 82, loss: 2.7992, val mf1: 0.4748, (best 0.7441)
Epoch 83, loss: 2.5179, val mf1: 0.7082, (best 0.7441)
Epoch 84, loss: 4.1744, val mf1: 0.7768, (best 0.7768)
Epoch 85, loss: 4.0679, val mf1: 0.7728, (best 0.7768)
Epoch 86, loss: 2.9559, val mf1: 0.6518, (best 0.7768)
Epoch 87, loss: 3.2353, val mf1: 0.5152, (best 0.7768)
Epoch 88, loss: 3.9005, val mf1: 0.4693, (best 0.7768)
Epoch 89, loss: 3.6403, val mf1: 0.4795, (best 0.7768)
Epoch 90, loss: 2.8401, val mf1: 0.5398, (best 0.7768)
Epoch 91, loss: 2.6929, val mf1: 0.6856, (best 0.7768)
Epoch 92, loss: 3.0551, val mf1: 0.7646, (best 0.7768)
Epoch 93, loss: 2.5578, val mf1: 0.7464, (best 0.7768)
Epoch 94, loss: 1.9115, val mf1: 0.6055, (best 0.7768)
Epoch 95, loss: 2.1992, val mf1: 0.4961, (best 0.7768)
Epoch 96, loss: 2.1443, val mf1: 0.4833, (best 0.7768)
Epoch 97, loss: 1.3895, val mf1: 0.6115, (best 0.7768)
Epoch 98, loss: 1.6344, val mf1: 0.7775, (best 0.7775)
Epoch 99, loss: 1.5269, val mf1: 0.7789, (best 0.7789)
time cost:  16.19985318183899 s
Test: REC 52.55 PRE 58.08 MF1 76.57 AUC 85.82
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=32, normalization=both, activation=None)
    (1-2): 2 x GraphConv(in=32, out=32, normalization=both, activation=None)
    (3): GraphConv(in=32, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 40.0916, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 65.2701, val mf1: 0.0439, (best 0.4883)
Epoch 2, loss: 33.3072, val mf1: 0.0516, (best 0.4883)
Epoch 3, loss: 9.2745, val mf1: 0.6688, (best 0.6688)
Epoch 4, loss: 33.7123, val mf1: 0.4879, (best 0.6688)
Epoch 5, loss: 32.6200, val mf1: 0.4879, (best 0.6688)
Epoch 6, loss: 13.8266, val mf1: 0.6550, (best 0.6688)
Epoch 7, loss: 9.3987, val mf1: 0.4536, (best 0.6688)
Epoch 8, loss: 20.3382, val mf1: 0.2406, (best 0.6688)
Epoch 9, loss: 23.6842, val mf1: 0.2097, (best 0.6688)
Epoch 10, loss: 16.5560, val mf1: 0.2858, (best 0.6688)
Epoch 11, loss: 8.5510, val mf1: 0.4601, (best 0.6688)
Epoch 12, loss: 8.1980, val mf1: 0.6317, (best 0.6688)
Epoch 13, loss: 15.1930, val mf1: 0.5803, (best 0.6688)
Epoch 14, loss: 13.4577, val mf1: 0.6571, (best 0.6688)
Epoch 15, loss: 7.2934, val mf1: 0.6480, (best 0.6688)
Epoch 16, loss: 6.3766, val mf1: 0.4891, (best 0.6688)
Epoch 17, loss: 9.1184, val mf1: 0.4014, (best 0.6688)
Epoch 18, loss: 10.9756, val mf1: 0.3279, (best 0.6688)
Epoch 19, loss: 8.6703, val mf1: 0.3965, (best 0.6688)
Epoch 20, loss: 5.7782, val mf1: 0.4693, (best 0.6688)
Epoch 21, loss: 4.5619, val mf1: 0.5968, (best 0.6688)
Epoch 22, loss: 6.9884, val mf1: 0.7335, (best 0.7335)
Epoch 23, loss: 6.7758, val mf1: 0.7354, (best 0.7354)
Epoch 24, loss: 4.1018, val mf1: 0.6564, (best 0.7354)
Epoch 25, loss: 3.9633, val mf1: 0.4987, (best 0.7354)
Epoch 26, loss: 5.0508, val mf1: 0.4387, (best 0.7354)
Epoch 27, loss: 5.3137, val mf1: 0.4122, (best 0.7354)
Epoch 28, loss: 3.8127, val mf1: 0.4564, (best 0.7354)
Epoch 29, loss: 2.2516, val mf1: 0.6153, (best 0.7354)
Epoch 30, loss: 3.9458, val mf1: 0.7783, (best 0.7783)
Epoch 31, loss: 2.8067, val mf1: 0.8105, (best 0.8105)
Epoch 32, loss: 1.8244, val mf1: 0.5066, (best 0.8105)
Epoch 33, loss: 3.4277, val mf1: 0.3403, (best 0.8105)
Epoch 34, loss: 1.2184, val mf1: 0.5887, (best 0.8105)
Epoch 35, loss: 4.1734, val mf1: 0.5744, (best 0.8105)
Epoch 36, loss: 1.4803, val mf1: 0.8227, (best 0.8227)
Epoch 37, loss: 3.5693, val mf1: 0.2971, (best 0.8227)
Epoch 38, loss: 3.7306, val mf1: 0.2983, (best 0.8227)
Epoch 39, loss: 1.0463, val mf1: 0.7889, (best 0.8227)
Epoch 40, loss: 3.1339, val mf1: 0.7823, (best 0.8227)
Epoch 41, loss: 2.1150, val mf1: 0.8365, (best 0.8365)
Epoch 42, loss: 1.5395, val mf1: 0.5654, (best 0.8365)
Epoch 43, loss: 2.4757, val mf1: 0.4544, (best 0.8365)
Epoch 44, loss: 2.0756, val mf1: 0.4826, (best 0.8365)
Epoch 45, loss: 1.3077, val mf1: 0.7339, (best 0.8365)
Epoch 46, loss: 1.9405, val mf1: 0.8431, (best 0.8431)
Epoch 47, loss: 1.6851, val mf1: 0.8471, (best 0.8471)
Epoch 48, loss: 0.7871, val mf1: 0.8000, (best 0.8471)
Epoch 49, loss: 1.9152, val mf1: 0.3960, (best 0.8471)
Epoch 50, loss: 0.5768, val mf1: 0.8728, (best 0.8728)
Epoch 51, loss: 1.4018, val mf1: 0.8108, (best 0.8728)
Epoch 52, loss: 0.6507, val mf1: 0.7488, (best 0.8728)
Epoch 53, loss: 1.0726, val mf1: 0.5638, (best 0.8728)
Epoch 54, loss: 0.9660, val mf1: 0.8725, (best 0.8728)
Epoch 55, loss: 1.1684, val mf1: 0.8680, (best 0.8728)
Epoch 56, loss: 0.6767, val mf1: 0.8371, (best 0.8728)
Epoch 57, loss: 1.8908, val mf1: 0.4136, (best 0.8728)
Epoch 58, loss: 0.7872, val mf1: 0.8478, (best 0.8728)
Epoch 59, loss: 1.1810, val mf1: 0.8631, (best 0.8728)
Epoch 60, loss: 0.7390, val mf1: 0.8623, (best 0.8728)
Epoch 61, loss: 1.2539, val mf1: 0.5057, (best 0.8728)
Epoch 62, loss: 0.5711, val mf1: 0.8620, (best 0.8728)
Epoch 63, loss: 0.8137, val mf1: 0.8650, (best 0.8728)
Epoch 64, loss: 0.5046, val mf1: 0.8645, (best 0.8728)
Epoch 65, loss: 1.2068, val mf1: 0.5564, (best 0.8728)
Epoch 66, loss: 1.9723, val mf1: 0.8319, (best 0.8728)
Epoch 67, loss: 2.1231, val mf1: 0.8411, (best 0.8728)
Epoch 68, loss: 0.8648, val mf1: 0.8245, (best 0.8728)
Epoch 69, loss: 2.1416, val mf1: 0.4378, (best 0.8728)
Epoch 70, loss: 1.7825, val mf1: 0.4857, (best 0.8728)
Epoch 71, loss: 1.1510, val mf1: 0.7891, (best 0.8728)
Epoch 72, loss: 1.8277, val mf1: 0.8410, (best 0.8728)
Epoch 73, loss: 1.7839, val mf1: 0.8474, (best 0.8728)
Epoch 74, loss: 0.9796, val mf1: 0.8198, (best 0.8728)
Epoch 75, loss: 1.4088, val mf1: 0.5039, (best 0.8728)
Epoch 76, loss: 0.9045, val mf1: 0.6051, (best 0.8728)
Epoch 77, loss: 1.0869, val mf1: 0.8677, (best 0.8728)
Epoch 78, loss: 1.5208, val mf1: 0.8446, (best 0.8728)
Epoch 79, loss: 0.4631, val mf1: 0.8704, (best 0.8728)
Epoch 80, loss: 3.1888, val mf1: 0.3152, (best 0.8728)
Epoch 81, loss: 1.5157, val mf1: 0.8457, (best 0.8728)
Epoch 82, loss: 2.3828, val mf1: 0.8240, (best 0.8728)
Epoch 83, loss: 0.9916, val mf1: 0.8522, (best 0.8728)
Epoch 84, loss: 1.7397, val mf1: 0.4774, (best 0.8728)
Epoch 85, loss: 2.0073, val mf1: 0.4643, (best 0.8728)
Epoch 86, loss: 1.1925, val mf1: 0.6373, (best 0.8728)
Epoch 87, loss: 1.6709, val mf1: 0.8295, (best 0.8728)
Epoch 88, loss: 1.9655, val mf1: 0.8353, (best 0.8728)
Epoch 89, loss: 1.3763, val mf1: 0.8325, (best 0.8728)
Epoch 90, loss: 0.9702, val mf1: 0.6248, (best 0.8728)
Epoch 91, loss: 1.6360, val mf1: 0.4593, (best 0.8728)
Epoch 92, loss: 0.5787, val mf1: 0.8276, (best 0.8728)
Epoch 93, loss: 0.9926, val mf1: 0.8672, (best 0.8728)
Epoch 94, loss: 0.7897, val mf1: 0.8702, (best 0.8728)
Epoch 95, loss: 1.5189, val mf1: 0.5100, (best 0.8728)
Epoch 96, loss: 1.2282, val mf1: 0.8539, (best 0.8728)
Epoch 97, loss: 1.2159, val mf1: 0.8614, (best 0.8728)
Epoch 98, loss: 0.4501, val mf1: 0.8459, (best 0.8728)
Epoch 99, loss: 2.3318, val mf1: 0.3004, (best 0.8728)
time cost:  16.034518480300903 s
Test: REC 66.90 PRE 79.64 MF1 85.76 AUC 90.98
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=32, normalization=both, activation=None)
    (1-2): 2 x GraphConv(in=32, out=32, normalization=both, activation=None)
    (3): GraphConv(in=32, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
Average AUC: 0.5843822809750244, Average Recall: 0.7958259981149972, Average Precision: 0.4928678163366613, Average F1: 0.5112875041269057 in 3 runs, with hid_dim: 32, num_layers: 4
Trying hid_dim: 32, num_layers: 5
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 148.1087, val mf1: 0.0438, (best 0.0438)
Epoch 1, loss: 31.8582, val mf1: 0.0449, (best 0.0449)
Epoch 2, loss: 16.2705, val mf1: 0.4967, (best 0.4967)
Epoch 3, loss: 20.5218, val mf1: 0.4967, (best 0.4967)
Epoch 4, loss: 16.6068, val mf1: 0.4967, (best 0.4967)
Epoch 5, loss: 8.1782, val mf1: 0.5074, (best 0.5074)
Epoch 6, loss: 9.2346, val mf1: 0.0917, (best 0.5074)
Epoch 7, loss: 9.8587, val mf1: 0.0748, (best 0.5074)
Epoch 8, loss: 1.5824, val mf1: 0.4448, (best 0.5074)
Epoch 9, loss: 5.3056, val mf1: 0.5365, (best 0.5365)
Epoch 10, loss: 7.4185, val mf1: 0.5351, (best 0.5365)
Epoch 11, loss: 5.0087, val mf1: 0.5367, (best 0.5367)
Epoch 12, loss: 1.5806, val mf1: 0.5868, (best 0.5868)
Epoch 13, loss: 3.7922, val mf1: 0.3343, (best 0.5868)
Epoch 14, loss: 4.6112, val mf1: 0.2764, (best 0.5868)
Epoch 15, loss: 3.0695, val mf1: 0.4232, (best 0.5868)
Epoch 16, loss: 1.8685, val mf1: 0.5465, (best 0.5868)
Epoch 17, loss: 3.9339, val mf1: 0.5289, (best 0.5868)
Epoch 18, loss: 2.9182, val mf1: 0.6874, (best 0.6874)
Epoch 19, loss: 2.0278, val mf1: 0.7012, (best 0.7012)
Epoch 20, loss: 1.9977, val mf1: 0.5610, (best 0.7012)
Epoch 21, loss: 2.2967, val mf1: 0.5029, (best 0.7012)
Epoch 22, loss: 2.3477, val mf1: 0.4938, (best 0.7012)
Epoch 23, loss: 2.0135, val mf1: 0.5315, (best 0.7012)
Epoch 24, loss: 1.7327, val mf1: 0.6286, (best 0.7012)
Epoch 25, loss: 1.8486, val mf1: 0.7472, (best 0.7472)
Epoch 26, loss: 1.8845, val mf1: 0.7628, (best 0.7628)
Epoch 27, loss: 1.5337, val mf1: 0.7283, (best 0.7628)
Epoch 28, loss: 1.4371, val mf1: 0.5896, (best 0.7628)
Epoch 29, loss: 1.5747, val mf1: 0.5270, (best 0.7628)
Epoch 30, loss: 1.4622, val mf1: 0.5371, (best 0.7628)
Epoch 31, loss: 1.1719, val mf1: 0.6279, (best 0.7628)
Epoch 32, loss: 1.1689, val mf1: 0.7622, (best 0.7628)
Epoch 33, loss: 1.1651, val mf1: 0.7660, (best 0.7660)
Epoch 34, loss: 0.8889, val mf1: 0.7355, (best 0.7660)
Epoch 35, loss: 0.9421, val mf1: 0.5936, (best 0.7660)
Epoch 36, loss: 0.8929, val mf1: 0.5989, (best 0.7660)
Epoch 37, loss: 0.6851, val mf1: 0.7690, (best 0.7690)
Epoch 38, loss: 0.8081, val mf1: 0.7726, (best 0.7726)
Epoch 39, loss: 0.5781, val mf1: 0.7710, (best 0.7726)
Epoch 40, loss: 0.7831, val mf1: 0.6640, (best 0.7726)
Epoch 41, loss: 0.5764, val mf1: 0.7826, (best 0.7826)
Epoch 42, loss: 0.6527, val mf1: 0.7841, (best 0.7841)
Epoch 43, loss: 0.8433, val mf1: 0.6335, (best 0.7841)
Epoch 44, loss: 0.5674, val mf1: 0.7857, (best 0.7857)
Epoch 45, loss: 0.6986, val mf1: 0.7522, (best 0.7857)
Epoch 46, loss: 1.0028, val mf1: 0.5375, (best 0.7857)
Epoch 47, loss: 0.6313, val mf1: 0.7834, (best 0.7857)
Epoch 48, loss: 0.6244, val mf1: 0.7784, (best 0.7857)
Epoch 49, loss: 0.9050, val mf1: 0.5829, (best 0.7857)
Epoch 50, loss: 0.6772, val mf1: 0.7739, (best 0.7857)
Epoch 51, loss: 0.5718, val mf1: 0.7523, (best 0.7857)
Epoch 52, loss: 0.6624, val mf1: 0.6634, (best 0.7857)
Epoch 53, loss: 0.7210, val mf1: 0.7437, (best 0.7857)
Epoch 54, loss: 0.6528, val mf1: 0.6721, (best 0.7857)
Epoch 55, loss: 0.5631, val mf1: 0.7501, (best 0.7857)
Epoch 56, loss: 0.6209, val mf1: 0.7799, (best 0.7857)
Epoch 57, loss: 0.6713, val mf1: 0.7030, (best 0.7857)
Epoch 58, loss: 0.5732, val mf1: 0.7727, (best 0.7857)
Epoch 59, loss: 0.5739, val mf1: 0.7759, (best 0.7857)
Epoch 60, loss: 0.6285, val mf1: 0.7278, (best 0.7857)
Epoch 61, loss: 0.5679, val mf1: 0.7812, (best 0.7857)
Epoch 62, loss: 0.5559, val mf1: 0.7814, (best 0.7857)
Epoch 63, loss: 0.5945, val mf1: 0.7364, (best 0.7857)
Epoch 64, loss: 0.5526, val mf1: 0.7869, (best 0.7869)
Epoch 65, loss: 0.5468, val mf1: 0.7904, (best 0.7904)
Epoch 66, loss: 0.5693, val mf1: 0.7567, (best 0.7904)
Epoch 67, loss: 0.5346, val mf1: 0.7911, (best 0.7911)
Epoch 68, loss: 0.5381, val mf1: 0.7915, (best 0.7915)
Epoch 69, loss: 0.5426, val mf1: 0.7787, (best 0.7915)
Epoch 70, loss: 0.5179, val mf1: 0.7943, (best 0.7943)
Epoch 71, loss: 0.5268, val mf1: 0.7953, (best 0.7953)
Epoch 72, loss: 0.5268, val mf1: 0.7972, (best 0.7972)
Epoch 73, loss: 0.5101, val mf1: 0.7990, (best 0.7990)
Epoch 74, loss: 0.5115, val mf1: 0.8001, (best 0.8001)
Epoch 75, loss: 0.5077, val mf1: 0.7933, (best 0.8001)
Epoch 76, loss: 0.4951, val mf1: 0.7979, (best 0.8001)
Epoch 77, loss: 0.4950, val mf1: 0.8013, (best 0.8013)
Epoch 78, loss: 0.4901, val mf1: 0.7997, (best 0.8013)
Epoch 79, loss: 0.4790, val mf1: 0.8027, (best 0.8027)
Epoch 80, loss: 0.4770, val mf1: 0.8018, (best 0.8027)
Epoch 81, loss: 0.4744, val mf1: 0.8022, (best 0.8027)
Epoch 82, loss: 0.4658, val mf1: 0.8024, (best 0.8027)
Epoch 83, loss: 0.4603, val mf1: 0.8047, (best 0.8047)
Epoch 84, loss: 0.4588, val mf1: 0.8039, (best 0.8047)
Epoch 85, loss: 0.4527, val mf1: 0.8079, (best 0.8079)
Epoch 86, loss: 0.4460, val mf1: 0.8072, (best 0.8079)
Epoch 87, loss: 0.4837, val mf1: 0.8088, (best 0.8088)
Epoch 88, loss: 0.5152, val mf1: 0.8042, (best 0.8088)
Epoch 89, loss: 0.7067, val mf1: 0.8147, (best 0.8147)
Epoch 90, loss: 0.9256, val mf1: 0.6335, (best 0.8147)
Epoch 91, loss: 0.7830, val mf1: 0.8109, (best 0.8147)
Epoch 92, loss: 0.7548, val mf1: 0.8095, (best 0.8147)
Epoch 93, loss: 0.6993, val mf1: 0.6937, (best 0.8147)
Epoch 94, loss: 0.5113, val mf1: 0.7948, (best 0.8147)
Epoch 95, loss: 0.5828, val mf1: 0.8276, (best 0.8276)
Epoch 96, loss: 0.4228, val mf1: 0.8208, (best 0.8276)
Epoch 97, loss: 0.7776, val mf1: 0.7577, (best 0.8276)
Epoch 98, loss: 1.9349, val mf1: 0.5379, (best 0.8276)
Epoch 99, loss: 0.5036, val mf1: 0.8107, (best 0.8276)
time cost:  17.099066734313965 s
Test: REC 60.83 PRE 66.42 MF1 80.91 AUC 88.00
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=32, normalization=both, activation=None)
    (1-3): 3 x GraphConv(in=32, out=32, normalization=both, activation=None)
    (4): GraphConv(in=32, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 135.2325, val mf1: 0.0435, (best 0.0435)
Epoch 1, loss: 211.9468, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 187.2630, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 85.5425, val mf1: 0.4883, (best 0.4883)
Epoch 4, loss: 64.1336, val mf1: 0.0444, (best 0.4883)
Epoch 5, loss: 78.0432, val mf1: 0.0442, (best 0.4883)
Epoch 6, loss: 25.5269, val mf1: 0.0503, (best 0.4883)
Epoch 7, loss: 51.2151, val mf1: 0.4883, (best 0.4883)
Epoch 8, loss: 77.8271, val mf1: 0.4883, (best 0.4883)
Epoch 9, loss: 69.7688, val mf1: 0.4883, (best 0.4883)
Epoch 10, loss: 37.8533, val mf1: 0.4883, (best 0.4883)
Epoch 11, loss: 5.8736, val mf1: 0.2678, (best 0.4883)
Epoch 12, loss: 36.7969, val mf1: 0.0455, (best 0.4883)
Epoch 13, loss: 30.5975, val mf1: 0.0465, (best 0.4883)
Epoch 14, loss: 2.4178, val mf1: 0.5031, (best 0.5031)
Epoch 15, loss: 22.8208, val mf1: 0.4962, (best 0.5031)
Epoch 16, loss: 29.2583, val mf1: 0.4967, (best 0.5031)
Epoch 17, loss: 18.1084, val mf1: 0.4962, (best 0.5031)
Epoch 18, loss: 3.0822, val mf1: 0.4657, (best 0.5031)
Epoch 19, loss: 18.7064, val mf1: 0.0553, (best 0.5031)
Epoch 20, loss: 13.4075, val mf1: 0.0679, (best 0.5031)
Epoch 21, loss: 2.9010, val mf1: 0.6971, (best 0.6971)
Epoch 22, loss: 15.5111, val mf1: 0.5277, (best 0.6971)
Epoch 23, loss: 16.0854, val mf1: 0.5276, (best 0.6971)
Epoch 24, loss: 4.7211, val mf1: 0.7454, (best 0.7454)
Epoch 25, loss: 5.5625, val mf1: 0.3902, (best 0.7454)
Epoch 26, loss: 11.4890, val mf1: 0.1847, (best 0.7454)
Epoch 27, loss: 8.1430, val mf1: 0.2663, (best 0.7454)
Epoch 28, loss: 3.3126, val mf1: 0.5412, (best 0.7454)
Epoch 29, loss: 6.4509, val mf1: 0.7438, (best 0.7454)
Epoch 30, loss: 8.6150, val mf1: 0.6523, (best 0.7454)
Epoch 31, loss: 3.6072, val mf1: 0.7344, (best 0.7454)
Epoch 32, loss: 4.2574, val mf1: 0.4530, (best 0.7454)
Epoch 33, loss: 7.3414, val mf1: 0.2926, (best 0.7454)
Epoch 34, loss: 5.8092, val mf1: 0.3736, (best 0.7454)
Epoch 35, loss: 3.0503, val mf1: 0.5322, (best 0.7454)
Epoch 36, loss: 4.2299, val mf1: 0.7617, (best 0.7617)
Epoch 37, loss: 5.7565, val mf1: 0.7443, (best 0.7617)
Epoch 38, loss: 3.3670, val mf1: 0.7578, (best 0.7617)
Epoch 39, loss: 2.5658, val mf1: 0.5186, (best 0.7617)
Epoch 40, loss: 4.5725, val mf1: 0.3621, (best 0.7617)
Epoch 41, loss: 3.6888, val mf1: 0.4159, (best 0.7617)
Epoch 42, loss: 1.9403, val mf1: 0.6158, (best 0.7617)
Epoch 43, loss: 3.2501, val mf1: 0.7798, (best 0.7798)
Epoch 44, loss: 3.5912, val mf1: 0.7766, (best 0.7798)
Epoch 45, loss: 1.9447, val mf1: 0.7517, (best 0.7798)
Epoch 46, loss: 2.5957, val mf1: 0.4696, (best 0.7798)
Epoch 47, loss: 3.1516, val mf1: 0.4223, (best 0.7798)
Epoch 48, loss: 1.7254, val mf1: 0.5496, (best 0.7798)
Epoch 49, loss: 2.1764, val mf1: 0.7730, (best 0.7798)
Epoch 50, loss: 2.4710, val mf1: 0.7525, (best 0.7798)
Epoch 51, loss: 1.4612, val mf1: 0.5998, (best 0.7798)
Epoch 52, loss: 2.3134, val mf1: 0.4529, (best 0.7798)
Epoch 53, loss: 1.7069, val mf1: 0.5076, (best 0.7798)
Epoch 54, loss: 1.5647, val mf1: 0.7446, (best 0.7798)
Epoch 55, loss: 1.9039, val mf1: 0.7427, (best 0.7798)
Epoch 56, loss: 1.2930, val mf1: 0.5803, (best 0.7798)
Epoch 57, loss: 1.8466, val mf1: 0.4767, (best 0.7798)
Epoch 58, loss: 1.1509, val mf1: 0.6226, (best 0.7798)
Epoch 59, loss: 1.7434, val mf1: 0.7431, (best 0.7798)
Epoch 60, loss: 1.0353, val mf1: 0.6761, (best 0.7798)
Epoch 61, loss: 1.4811, val mf1: 0.5006, (best 0.7798)
Epoch 62, loss: 0.9368, val mf1: 0.6738, (best 0.7798)
Epoch 63, loss: 1.4733, val mf1: 0.7505, (best 0.7798)
Epoch 64, loss: 1.0905, val mf1: 0.5488, (best 0.7798)
Epoch 65, loss: 1.0337, val mf1: 0.5552, (best 0.7798)
Epoch 66, loss: 1.4564, val mf1: 0.7396, (best 0.7798)
Epoch 67, loss: 1.1688, val mf1: 0.5200, (best 0.7798)
Epoch 68, loss: 0.6803, val mf1: 0.7455, (best 0.7798)
Epoch 69, loss: 1.3001, val mf1: 0.7399, (best 0.7798)
Epoch 70, loss: 2.6885, val mf1: 0.2604, (best 0.7798)
Epoch 71, loss: 4.4744, val mf1: 0.5335, (best 0.7798)
Epoch 72, loss: 1.6637, val mf1: 0.7126, (best 0.7798)
Epoch 73, loss: 8.5622, val mf1: 0.0857, (best 0.7798)
Epoch 74, loss: 2.6654, val mf1: 0.3260, (best 0.7798)
Epoch 75, loss: 9.5809, val mf1: 0.5309, (best 0.7798)
Epoch 76, loss: 12.5803, val mf1: 0.5295, (best 0.7798)
Epoch 77, loss: 4.9773, val mf1: 0.5490, (best 0.7798)
Epoch 78, loss: 7.7332, val mf1: 0.0887, (best 0.7798)
Epoch 79, loss: 7.3765, val mf1: 0.2015, (best 0.7798)
Epoch 80, loss: 2.7116, val mf1: 0.5047, (best 0.7798)
Epoch 81, loss: 5.2355, val mf1: 0.7654, (best 0.7798)
Epoch 82, loss: 6.8208, val mf1: 0.7356, (best 0.7798)
Epoch 83, loss: 2.9710, val mf1: 0.7113, (best 0.7798)
Epoch 84, loss: 4.0207, val mf1: 0.4002, (best 0.7798)
Epoch 85, loss: 5.0486, val mf1: 0.2957, (best 0.7798)
Epoch 86, loss: 2.3671, val mf1: 0.5065, (best 0.7798)
Epoch 87, loss: 2.5232, val mf1: 0.7872, (best 0.7872)
Epoch 88, loss: 3.7430, val mf1: 0.7787, (best 0.7872)
Epoch 89, loss: 2.6491, val mf1: 0.7909, (best 0.7909)
Epoch 90, loss: 1.7291, val mf1: 0.6099, (best 0.7909)
Epoch 91, loss: 2.6551, val mf1: 0.4619, (best 0.7909)
Epoch 92, loss: 2.8307, val mf1: 0.4490, (best 0.7909)
Epoch 93, loss: 1.8362, val mf1: 0.5554, (best 0.7909)
Epoch 94, loss: 1.9519, val mf1: 0.7724, (best 0.7909)
Epoch 95, loss: 2.6166, val mf1: 0.7881, (best 0.7909)
Epoch 96, loss: 1.7788, val mf1: 0.7734, (best 0.7909)
Epoch 97, loss: 1.5973, val mf1: 0.5642, (best 0.7909)
Epoch 98, loss: 2.1401, val mf1: 0.4759, (best 0.7909)
Epoch 99, loss: 1.7041, val mf1: 0.5189, (best 0.7909)
time cost:  17.057250499725342 s
Test: REC 51.59 PRE 60.13 MF1 76.78 AUC 85.20
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=32, normalization=both, activation=None)
    (1-3): 3 x GraphConv(in=32, out=32, normalization=both, activation=None)
    (4): GraphConv(in=32, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 37.9172, val mf1: 0.0436, (best 0.0436)
Epoch 1, loss: 101.6841, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 88.4450, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 51.0670, val mf1: 0.4883, (best 0.4883)
Epoch 4, loss: 9.1509, val mf1: 0.5002, (best 0.5002)
Epoch 5, loss: 38.2714, val mf1: 0.0439, (best 0.5002)
Epoch 6, loss: 32.1343, val mf1: 0.0441, (best 0.5002)
Epoch 7, loss: 4.0404, val mf1: 0.4102, (best 0.5002)
Epoch 8, loss: 23.5985, val mf1: 0.4962, (best 0.5002)
Epoch 9, loss: 19.2302, val mf1: 0.5269, (best 0.5269)
Epoch 10, loss: 1.2406, val mf1: 0.6382, (best 0.6382)
Epoch 11, loss: 13.8661, val mf1: 0.0524, (best 0.6382)
Epoch 12, loss: 2.2084, val mf1: 0.4785, (best 0.6382)
Epoch 13, loss: 12.6624, val mf1: 0.5288, (best 0.6382)
Epoch 14, loss: 9.2387, val mf1: 0.5309, (best 0.6382)
Epoch 15, loss: 4.2781, val mf1: 0.3664, (best 0.6382)
Epoch 16, loss: 8.5851, val mf1: 0.1905, (best 0.6382)
Epoch 17, loss: 3.3307, val mf1: 0.4495, (best 0.6382)
Epoch 18, loss: 4.9481, val mf1: 0.7103, (best 0.7103)
Epoch 19, loss: 4.2631, val mf1: 0.7392, (best 0.7392)
Epoch 20, loss: 2.8167, val mf1: 0.4991, (best 0.7392)
Epoch 21, loss: 5.1655, val mf1: 0.3484, (best 0.7392)
Epoch 22, loss: 3.2372, val mf1: 0.4676, (best 0.7392)
Epoch 23, loss: 2.8334, val mf1: 0.7381, (best 0.7392)
Epoch 24, loss: 4.2077, val mf1: 0.7456, (best 0.7456)
Epoch 25, loss: 2.4706, val mf1: 0.6730, (best 0.7456)
Epoch 26, loss: 3.0386, val mf1: 0.4772, (best 0.7456)
Epoch 27, loss: 3.4144, val mf1: 0.4505, (best 0.7456)
Epoch 28, loss: 2.1960, val mf1: 0.5521, (best 0.7456)
Epoch 29, loss: 3.3735, val mf1: 0.7652, (best 0.7652)
Epoch 30, loss: 1.9456, val mf1: 0.5802, (best 0.7652)
Epoch 31, loss: 2.7414, val mf1: 0.4680, (best 0.7652)
Epoch 32, loss: 2.1866, val mf1: 0.5087, (best 0.7652)
Epoch 33, loss: 2.0324, val mf1: 0.7896, (best 0.7896)
Epoch 34, loss: 1.6704, val mf1: 0.7993, (best 0.7993)
Epoch 35, loss: 2.0749, val mf1: 0.4740, (best 0.7993)
Epoch 36, loss: 1.1467, val mf1: 0.7523, (best 0.7993)
Epoch 37, loss: 2.6846, val mf1: 0.6234, (best 0.7993)
Epoch 38, loss: 6.8284, val mf1: 0.0911, (best 0.7993)
Epoch 39, loss: 1.2537, val mf1: 0.5587, (best 0.7993)
Epoch 40, loss: 8.4159, val mf1: 0.5336, (best 0.7993)
Epoch 41, loss: 3.9632, val mf1: 0.5863, (best 0.7993)
Epoch 42, loss: 8.0073, val mf1: 0.0840, (best 0.7993)
Epoch 43, loss: 5.8216, val mf1: 0.2383, (best 0.7993)
Epoch 44, loss: 1.8967, val mf1: 0.7099, (best 0.7993)
Epoch 45, loss: 6.7969, val mf1: 0.5803, (best 0.7993)
Epoch 46, loss: 3.6491, val mf1: 0.7700, (best 0.7993)
Epoch 47, loss: 2.4924, val mf1: 0.4973, (best 0.7993)
Epoch 48, loss: 5.1846, val mf1: 0.3037, (best 0.7993)
Epoch 49, loss: 3.4894, val mf1: 0.4318, (best 0.7993)
Epoch 50, loss: 2.1565, val mf1: 0.6709, (best 0.7993)
Epoch 51, loss: 4.1101, val mf1: 0.7578, (best 0.7993)
Epoch 52, loss: 3.3352, val mf1: 0.7728, (best 0.7993)
Epoch 53, loss: 2.1085, val mf1: 0.5790, (best 0.7993)
Epoch 54, loss: 3.1779, val mf1: 0.4490, (best 0.7993)
Epoch 55, loss: 3.2173, val mf1: 0.4450, (best 0.7993)
Epoch 56, loss: 2.0992, val mf1: 0.5514, (best 0.7993)
Epoch 57, loss: 2.4836, val mf1: 0.7743, (best 0.7993)
Epoch 58, loss: 2.8456, val mf1: 0.7752, (best 0.7993)
Epoch 59, loss: 1.9120, val mf1: 0.7069, (best 0.7993)
Epoch 60, loss: 2.0999, val mf1: 0.5124, (best 0.7993)
Epoch 61, loss: 2.4479, val mf1: 0.4732, (best 0.7993)
Epoch 62, loss: 1.8303, val mf1: 0.5383, (best 0.7993)
Epoch 63, loss: 1.7069, val mf1: 0.7491, (best 0.7993)
Epoch 64, loss: 2.0356, val mf1: 0.7820, (best 0.7993)
Epoch 65, loss: 1.4592, val mf1: 0.7163, (best 0.7993)
Epoch 66, loss: 1.6484, val mf1: 0.5247, (best 0.7993)
Epoch 67, loss: 1.6947, val mf1: 0.5104, (best 0.7993)
Epoch 68, loss: 1.2803, val mf1: 0.6621, (best 0.7993)
Epoch 69, loss: 1.6116, val mf1: 0.7801, (best 0.7993)
Epoch 70, loss: 1.2639, val mf1: 0.7587, (best 0.7993)
Epoch 71, loss: 1.3271, val mf1: 0.5518, (best 0.7993)
Epoch 72, loss: 1.3425, val mf1: 0.5413, (best 0.7993)
Epoch 73, loss: 1.0868, val mf1: 0.7494, (best 0.7993)
Epoch 74, loss: 1.3019, val mf1: 0.7825, (best 0.7993)
Epoch 75, loss: 0.9848, val mf1: 0.6840, (best 0.7993)
Epoch 76, loss: 1.1852, val mf1: 0.5508, (best 0.7993)
Epoch 77, loss: 0.9034, val mf1: 0.7200, (best 0.7993)
Epoch 78, loss: 1.0952, val mf1: 0.7865, (best 0.7993)
Epoch 79, loss: 0.8314, val mf1: 0.7281, (best 0.7993)
Epoch 80, loss: 0.9893, val mf1: 0.5845, (best 0.7993)
Epoch 81, loss: 0.7929, val mf1: 0.7891, (best 0.7993)
Epoch 82, loss: 0.8530, val mf1: 0.7931, (best 0.7993)
Epoch 83, loss: 0.8214, val mf1: 0.6473, (best 0.7993)
Epoch 84, loss: 0.6863, val mf1: 0.7702, (best 0.7993)
Epoch 85, loss: 0.8032, val mf1: 0.7970, (best 0.7993)
Epoch 86, loss: 0.6972, val mf1: 0.7274, (best 0.7993)
Epoch 87, loss: 0.6150, val mf1: 0.7915, (best 0.7993)
Epoch 88, loss: 0.6916, val mf1: 0.7991, (best 0.7993)
Epoch 89, loss: 0.7080, val mf1: 0.7240, (best 0.7993)
Epoch 90, loss: 0.6979, val mf1: 0.8047, (best 0.8047)
Epoch 91, loss: 0.6113, val mf1: 0.7859, (best 0.8047)
Epoch 92, loss: 0.5730, val mf1: 0.8052, (best 0.8052)
Epoch 93, loss: 0.5472, val mf1: 0.7997, (best 0.8052)
Epoch 94, loss: 0.5543, val mf1: 0.8122, (best 0.8122)
Epoch 95, loss: 0.6135, val mf1: 0.7886, (best 0.8122)
Epoch 96, loss: 1.0892, val mf1: 0.7635, (best 0.8122)
Epoch 97, loss: 2.9164, val mf1: 0.2219, (best 0.8122)
Epoch 98, loss: 4.4021, val mf1: 0.5317, (best 0.8122)
Epoch 99, loss: 2.3094, val mf1: 0.5697, (best 0.8122)
time cost:  17.07794189453125 s
Test: REC 48.41 PRE 78.70 MF1 79.20 AUC 87.31
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=32, normalization=both, activation=None)
    (1-3): 3 x GraphConv(in=32, out=32, normalization=both, activation=None)
    (4): GraphConv(in=32, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
Average AUC: 0.6108997005007896, Average Recall: 0.5924063931737934, Average Precision: 0.0876238022805254, Average F1: 0.15060177685401235 in 3 runs, with hid_dim: 32, num_layers: 5
Trying hid_dim: 64, num_layers: 3
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 75.7099, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 112.6087, val mf1: 0.0438, (best 0.4883)
Epoch 2, loss: 36.2497, val mf1: 0.0438, (best 0.4883)
Epoch 3, loss: 40.6286, val mf1: 0.5291, (best 0.5291)
Epoch 4, loss: 67.5746, val mf1: 0.5291, (best 0.5291)
Epoch 5, loss: 66.6292, val mf1: 0.5291, (best 0.5291)
Epoch 6, loss: 46.9385, val mf1: 0.5291, (best 0.5291)
Epoch 7, loss: 14.8976, val mf1: 0.6955, (best 0.6955)
Epoch 8, loss: 13.5382, val mf1: 0.3418, (best 0.6955)
Epoch 9, loss: 42.7969, val mf1: 0.0553, (best 0.6955)
Epoch 10, loss: 37.1962, val mf1: 0.0612, (best 0.6955)
Epoch 11, loss: 13.3353, val mf1: 0.3856, (best 0.6955)
Epoch 12, loss: 8.7565, val mf1: 0.5639, (best 0.6955)
Epoch 13, loss: 19.4136, val mf1: 0.6977, (best 0.6977)
Epoch 14, loss: 25.7380, val mf1: 0.5598, (best 0.6977)
Epoch 15, loss: 21.6349, val mf1: 0.6976, (best 0.6977)
Epoch 16, loss: 13.6322, val mf1: 0.7062, (best 0.7062)
Epoch 17, loss: 9.9481, val mf1: 0.5166, (best 0.7062)
Epoch 18, loss: 12.9664, val mf1: 0.4337, (best 0.7062)
Epoch 19, loss: 16.5789, val mf1: 0.3698, (best 0.7062)
Epoch 20, loss: 16.4006, val mf1: 0.3680, (best 0.7062)
Epoch 21, loss: 13.0264, val mf1: 0.4222, (best 0.7062)
Epoch 22, loss: 9.8453, val mf1: 0.4723, (best 0.7062)
Epoch 23, loss: 8.6053, val mf1: 0.5304, (best 0.7062)
Epoch 24, loss: 9.2961, val mf1: 0.6243, (best 0.7062)
Epoch 25, loss: 10.7042, val mf1: 0.7005, (best 0.7062)
Epoch 26, loss: 10.5523, val mf1: 0.7085, (best 0.7085)
Epoch 27, loss: 8.7556, val mf1: 0.6602, (best 0.7085)
Epoch 28, loss: 7.1620, val mf1: 0.5669, (best 0.7085)
Epoch 29, loss: 6.8943, val mf1: 0.5015, (best 0.7085)
Epoch 30, loss: 7.3724, val mf1: 0.4658, (best 0.7085)
Epoch 31, loss: 7.3632, val mf1: 0.4518, (best 0.7085)
Epoch 32, loss: 5.8778, val mf1: 0.4660, (best 0.7085)
Epoch 33, loss: 3.8386, val mf1: 0.5426, (best 0.7085)
Epoch 34, loss: 4.4832, val mf1: 0.7997, (best 0.7997)
Epoch 35, loss: 4.3269, val mf1: 0.8149, (best 0.8149)
Epoch 36, loss: 2.2206, val mf1: 0.6970, (best 0.8149)
Epoch 37, loss: 3.0080, val mf1: 0.4056, (best 0.8149)
Epoch 38, loss: 1.6893, val mf1: 0.5066, (best 0.8149)
Epoch 39, loss: 1.9313, val mf1: 0.8345, (best 0.8345)
Epoch 40, loss: 2.4815, val mf1: 0.8359, (best 0.8359)
Epoch 41, loss: 1.0367, val mf1: 0.6139, (best 0.8359)
Epoch 42, loss: 1.6344, val mf1: 0.5503, (best 0.8359)
Epoch 43, loss: 2.5968, val mf1: 0.8233, (best 0.8359)
Epoch 44, loss: 2.2272, val mf1: 0.8362, (best 0.8362)
Epoch 45, loss: 0.6277, val mf1: 0.7209, (best 0.8362)
Epoch 46, loss: 3.1924, val mf1: 0.2357, (best 0.8362)
Epoch 47, loss: 3.5818, val mf1: 0.8445, (best 0.8445)
Epoch 48, loss: 6.6616, val mf1: 0.8005, (best 0.8445)
Epoch 49, loss: 5.0283, val mf1: 0.8454, (best 0.8454)
Epoch 50, loss: 2.3254, val mf1: 0.8056, (best 0.8454)
Epoch 51, loss: 3.3307, val mf1: 0.4369, (best 0.8454)
Epoch 52, loss: 5.4526, val mf1: 0.3130, (best 0.8454)
Epoch 53, loss: 2.8605, val mf1: 0.4978, (best 0.8454)
Epoch 54, loss: 2.8082, val mf1: 0.7338, (best 0.8454)
Epoch 55, loss: 4.0893, val mf1: 0.8219, (best 0.8454)
Epoch 56, loss: 4.1257, val mf1: 0.8256, (best 0.8454)
Epoch 57, loss: 2.8379, val mf1: 0.7970, (best 0.8454)
Epoch 58, loss: 2.0655, val mf1: 0.5531, (best 0.8454)
Epoch 59, loss: 3.4356, val mf1: 0.4034, (best 0.8454)
Epoch 60, loss: 2.2461, val mf1: 0.4845, (best 0.8454)
Epoch 61, loss: 1.7516, val mf1: 0.8025, (best 0.8454)
Epoch 62, loss: 2.3401, val mf1: 0.8409, (best 0.8454)
Epoch 63, loss: 1.8599, val mf1: 0.8414, (best 0.8454)
Epoch 64, loss: 1.1619, val mf1: 0.6130, (best 0.8454)
Epoch 65, loss: 2.0115, val mf1: 0.4376, (best 0.8454)
Epoch 66, loss: 0.9866, val mf1: 0.8371, (best 0.8454)
Epoch 67, loss: 1.4924, val mf1: 0.8500, (best 0.8500)
Epoch 68, loss: 0.8993, val mf1: 0.8452, (best 0.8500)
Epoch 69, loss: 1.9807, val mf1: 0.3727, (best 0.8500)
Epoch 70, loss: 3.1429, val mf1: 0.8285, (best 0.8500)
Epoch 71, loss: 5.2138, val mf1: 0.7640, (best 0.8500)
Epoch 72, loss: 2.2641, val mf1: 0.8464, (best 0.8500)
Epoch 73, loss: 3.0941, val mf1: 0.2213, (best 0.8500)
Epoch 74, loss: 1.3056, val mf1: 0.8508, (best 0.8508)
Epoch 75, loss: 2.2561, val mf1: 0.8522, (best 0.8522)
Epoch 76, loss: 1.6622, val mf1: 0.8485, (best 0.8522)
Epoch 77, loss: 0.7854, val mf1: 0.7216, (best 0.8522)
Epoch 78, loss: 2.4670, val mf1: 0.3411, (best 0.8522)
Epoch 79, loss: 2.3849, val mf1: 0.8503, (best 0.8522)
Epoch 80, loss: 4.5037, val mf1: 0.8452, (best 0.8522)
Epoch 81, loss: 4.3915, val mf1: 0.8491, (best 0.8522)
Epoch 82, loss: 2.5551, val mf1: 0.8435, (best 0.8522)
Epoch 83, loss: 1.3235, val mf1: 0.5712, (best 0.8522)
Epoch 84, loss: 4.8861, val mf1: 0.1498, (best 0.8522)
Epoch 85, loss: 1.9455, val mf1: 0.8321, (best 0.8522)
Epoch 86, loss: 4.1739, val mf1: 0.8529, (best 0.8529)
Epoch 87, loss: 4.9138, val mf1: 0.8468, (best 0.8529)
Epoch 88, loss: 3.7852, val mf1: 0.8501, (best 0.8529)
Epoch 89, loss: 1.8318, val mf1: 0.8177, (best 0.8529)
Epoch 90, loss: 2.8846, val mf1: 0.3825, (best 0.8529)
Epoch 91, loss: 2.8179, val mf1: 0.3850, (best 0.8529)
Epoch 92, loss: 1.6046, val mf1: 0.8151, (best 0.8529)
Epoch 93, loss: 2.8191, val mf1: 0.8416, (best 0.8529)
Epoch 94, loss: 2.9847, val mf1: 0.8491, (best 0.8529)
Epoch 95, loss: 2.0171, val mf1: 0.8382, (best 0.8529)
Epoch 96, loss: 0.9132, val mf1: 0.7032, (best 0.8529)
Epoch 97, loss: 4.1910, val mf1: 0.1693, (best 0.8529)
Epoch 98, loss: 1.9575, val mf1: 0.8445, (best 0.8529)
Epoch 99, loss: 4.1827, val mf1: 0.8516, (best 0.8529)
time cost:  15.104797124862671 s
Test: REC 59.86 PRE 79.34 MF1 83.45 AUC 88.18
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=64, normalization=both, activation=None)
    (1): GraphConv(in=64, out=64, normalization=both, activation=None)
    (2): GraphConv(in=64, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 142.2581, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 157.2996, val mf1: 0.0438, (best 0.4883)
Epoch 2, loss: 43.2606, val mf1: 0.0441, (best 0.4883)
Epoch 3, loss: 98.0970, val mf1: 0.4967, (best 0.4967)
Epoch 4, loss: 139.4754, val mf1: 0.4967, (best 0.4967)
Epoch 5, loss: 132.7719, val mf1: 0.4967, (best 0.4967)
Epoch 6, loss: 94.5387, val mf1: 0.4967, (best 0.4967)
Epoch 7, loss: 35.7716, val mf1: 0.5291, (best 0.5291)
Epoch 8, loss: 30.1341, val mf1: 0.0664, (best 0.5291)
Epoch 9, loss: 59.9201, val mf1: 0.0513, (best 0.5291)
Epoch 10, loss: 30.5575, val mf1: 0.1732, (best 0.5291)
Epoch 11, loss: 8.8566, val mf1: 0.5023, (best 0.5291)
Epoch 12, loss: 24.1119, val mf1: 0.5996, (best 0.5996)
Epoch 13, loss: 34.6874, val mf1: 0.5295, (best 0.5996)
Epoch 14, loss: 27.0726, val mf1: 0.6255, (best 0.6255)
Epoch 15, loss: 13.2464, val mf1: 0.6431, (best 0.6431)
Epoch 16, loss: 13.8773, val mf1: 0.4595, (best 0.6431)
Epoch 17, loss: 21.7040, val mf1: 0.3583, (best 0.6431)
Epoch 18, loss: 25.5696, val mf1: 0.3078, (best 0.6431)
Epoch 19, loss: 20.7810, val mf1: 0.3739, (best 0.6431)
Epoch 20, loss: 14.4685, val mf1: 0.4548, (best 0.6431)
Epoch 21, loss: 12.0634, val mf1: 0.5452, (best 0.6431)
Epoch 22, loss: 15.7191, val mf1: 0.7164, (best 0.7164)
Epoch 23, loss: 18.9136, val mf1: 0.7605, (best 0.7605)
Epoch 24, loss: 17.0826, val mf1: 0.7535, (best 0.7605)
Epoch 25, loss: 12.1815, val mf1: 0.6424, (best 0.7605)
Epoch 26, loss: 10.3574, val mf1: 0.5096, (best 0.7605)
Epoch 27, loss: 12.2030, val mf1: 0.4464, (best 0.7605)
Epoch 28, loss: 13.9591, val mf1: 0.4055, (best 0.7605)
Epoch 29, loss: 12.7137, val mf1: 0.4139, (best 0.7605)
Epoch 30, loss: 9.4670, val mf1: 0.4660, (best 0.7605)
Epoch 31, loss: 7.8266, val mf1: 0.5554, (best 0.7605)
Epoch 32, loss: 9.6385, val mf1: 0.7193, (best 0.7605)
Epoch 33, loss: 10.5257, val mf1: 0.7617, (best 0.7617)
Epoch 34, loss: 8.0901, val mf1: 0.6979, (best 0.7617)
Epoch 35, loss: 6.3451, val mf1: 0.5265, (best 0.7617)
Epoch 36, loss: 7.6010, val mf1: 0.4461, (best 0.7617)
Epoch 37, loss: 8.3752, val mf1: 0.4093, (best 0.7617)
Epoch 38, loss: 6.3285, val mf1: 0.4605, (best 0.7617)
Epoch 39, loss: 4.9268, val mf1: 0.5778, (best 0.7617)
Epoch 40, loss: 6.3809, val mf1: 0.7749, (best 0.7749)
Epoch 41, loss: 5.9753, val mf1: 0.7830, (best 0.7830)
Epoch 42, loss: 3.8122, val mf1: 0.5874, (best 0.7830)
Epoch 43, loss: 4.6730, val mf1: 0.4387, (best 0.7830)
Epoch 44, loss: 4.5386, val mf1: 0.4205, (best 0.7830)
Epoch 45, loss: 2.8084, val mf1: 0.6478, (best 0.7830)
Epoch 46, loss: 4.1530, val mf1: 0.8034, (best 0.8034)
Epoch 47, loss: 2.9698, val mf1: 0.7836, (best 0.8034)
Epoch 48, loss: 2.8080, val mf1: 0.4271, (best 0.8034)
Epoch 49, loss: 1.7418, val mf1: 0.5434, (best 0.8034)
Epoch 50, loss: 2.4906, val mf1: 0.7906, (best 0.8034)
Epoch 51, loss: 1.8539, val mf1: 0.7727, (best 0.8034)
Epoch 52, loss: 3.3222, val mf1: 0.2909, (best 0.8034)
Epoch 53, loss: 2.1059, val mf1: 0.7682, (best 0.8034)
Epoch 54, loss: 2.0164, val mf1: 0.7482, (best 0.8034)
Epoch 55, loss: 4.0743, val mf1: 0.1998, (best 0.8034)
Epoch 56, loss: 8.8067, val mf1: 0.5636, (best 0.8034)
Epoch 57, loss: 8.2308, val mf1: 0.6138, (best 0.8034)
Epoch 58, loss: 1.9536, val mf1: 0.4554, (best 0.8034)
Epoch 59, loss: 4.5934, val mf1: 0.1591, (best 0.8034)
Epoch 60, loss: 8.4997, val mf1: 0.7195, (best 0.8034)
Epoch 61, loss: 11.7441, val mf1: 0.6785, (best 0.8034)
Epoch 62, loss: 4.9850, val mf1: 0.8202, (best 0.8202)
Epoch 63, loss: 4.1557, val mf1: 0.4017, (best 0.8202)
Epoch 64, loss: 8.1730, val mf1: 0.2438, (best 0.8202)
Epoch 65, loss: 3.4552, val mf1: 0.5308, (best 0.8202)
Epoch 66, loss: 5.1206, val mf1: 0.7873, (best 0.8202)
Epoch 67, loss: 6.7103, val mf1: 0.8073, (best 0.8202)
Epoch 68, loss: 5.5433, val mf1: 0.7912, (best 0.8202)
Epoch 69, loss: 3.7050, val mf1: 0.5887, (best 0.8202)
Epoch 70, loss: 4.9701, val mf1: 0.4301, (best 0.8202)
Epoch 71, loss: 4.9778, val mf1: 0.4124, (best 0.8202)
Epoch 72, loss: 3.0069, val mf1: 0.5898, (best 0.8202)
Epoch 73, loss: 3.9975, val mf1: 0.7903, (best 0.8202)
Epoch 74, loss: 4.0212, val mf1: 0.8041, (best 0.8202)
Epoch 75, loss: 2.3429, val mf1: 0.7535, (best 0.8202)
Epoch 76, loss: 3.7136, val mf1: 0.3295, (best 0.8202)
Epoch 77, loss: 1.5951, val mf1: 0.6482, (best 0.8202)
Epoch 78, loss: 2.4224, val mf1: 0.8082, (best 0.8202)
Epoch 79, loss: 2.0356, val mf1: 0.7982, (best 0.8202)
Epoch 80, loss: 1.5299, val mf1: 0.5153, (best 0.8202)
Epoch 81, loss: 1.0638, val mf1: 0.7490, (best 0.8202)
Epoch 82, loss: 1.0415, val mf1: 0.7600, (best 0.8202)
Epoch 83, loss: 1.2473, val mf1: 0.5684, (best 0.8202)
Epoch 84, loss: 2.0093, val mf1: 0.8190, (best 0.8202)
Epoch 85, loss: 1.5399, val mf1: 0.8146, (best 0.8202)
Epoch 86, loss: 3.9593, val mf1: 0.2124, (best 0.8202)
Epoch 87, loss: 8.0587, val mf1: 0.6383, (best 0.8202)
Epoch 88, loss: 8.3643, val mf1: 0.6389, (best 0.8202)
Epoch 89, loss: 0.7912, val mf1: 0.6976, (best 0.8202)
Epoch 90, loss: 13.1532, val mf1: 0.0706, (best 0.8202)
Epoch 91, loss: 1.8194, val mf1: 0.8431, (best 0.8431)
Epoch 92, loss: 5.4179, val mf1: 0.8098, (best 0.8431)
Epoch 93, loss: 3.5908, val mf1: 0.8387, (best 0.8431)
Epoch 94, loss: 1.6193, val mf1: 0.5217, (best 0.8431)
Epoch 95, loss: 3.8142, val mf1: 0.3091, (best 0.8431)
Epoch 96, loss: 2.4283, val mf1: 0.8189, (best 0.8431)
Epoch 97, loss: 3.9109, val mf1: 0.8421, (best 0.8431)
Epoch 98, loss: 2.8079, val mf1: 0.8237, (best 0.8431)
Epoch 99, loss: 2.0409, val mf1: 0.5080, (best 0.8431)
time cost:  15.197113513946533 s
Test: REC 60.28 PRE 77.62 MF1 83.25 AUC 88.41
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=64, normalization=both, activation=None)
    (1): GraphConv(in=64, out=64, normalization=both, activation=None)
    (2): GraphConv(in=64, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 294.6677, val mf1: 0.0438, (best 0.0438)
Epoch 1, loss: 49.9440, val mf1: 0.4882, (best 0.4882)
Epoch 2, loss: 76.6738, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 33.9683, val mf1: 0.5291, (best 0.5291)
Epoch 4, loss: 78.6349, val mf1: 0.0445, (best 0.5291)
Epoch 5, loss: 67.2447, val mf1: 0.0448, (best 0.5291)
Epoch 6, loss: 8.6103, val mf1: 0.5294, (best 0.5294)
Epoch 7, loss: 18.8006, val mf1: 0.5302, (best 0.5302)
Epoch 8, loss: 2.8206, val mf1: 0.7377, (best 0.7377)
Epoch 9, loss: 20.6135, val mf1: 0.0746, (best 0.7377)
Epoch 10, loss: 4.2409, val mf1: 0.5471, (best 0.7377)
Epoch 11, loss: 13.2941, val mf1: 0.7640, (best 0.7640)
Epoch 12, loss: 11.0413, val mf1: 0.8045, (best 0.8045)
Epoch 13, loss: 6.4027, val mf1: 0.5254, (best 0.8045)
Epoch 14, loss: 10.6560, val mf1: 0.3882, (best 0.8045)
Epoch 15, loss: 10.2277, val mf1: 0.4053, (best 0.8045)
Epoch 16, loss: 6.8264, val mf1: 0.5187, (best 0.8045)
Epoch 17, loss: 8.7657, val mf1: 0.7600, (best 0.8045)
Epoch 18, loss: 9.2321, val mf1: 0.7832, (best 0.8045)
Epoch 19, loss: 6.1692, val mf1: 0.5860, (best 0.8045)
Epoch 20, loss: 7.0079, val mf1: 0.4619, (best 0.8045)
Epoch 21, loss: 7.6915, val mf1: 0.4231, (best 0.8045)
Epoch 22, loss: 5.0797, val mf1: 0.5061, (best 0.8045)
Epoch 23, loss: 5.6880, val mf1: 0.7812, (best 0.8045)
Epoch 24, loss: 5.6234, val mf1: 0.7981, (best 0.8045)
Epoch 25, loss: 3.4083, val mf1: 0.5481, (best 0.8045)
Epoch 26, loss: 4.9298, val mf1: 0.3965, (best 0.8045)
Epoch 27, loss: 2.5516, val mf1: 0.6038, (best 0.8045)
Epoch 28, loss: 3.9136, val mf1: 0.8175, (best 0.8175)
Epoch 29, loss: 2.1393, val mf1: 0.7553, (best 0.8175)
Epoch 30, loss: 5.5116, val mf1: 0.2606, (best 0.8175)
Epoch 31, loss: 2.5434, val mf1: 0.8150, (best 0.8175)
Epoch 32, loss: 3.1252, val mf1: 0.8013, (best 0.8175)
Epoch 33, loss: 3.1456, val mf1: 0.3143, (best 0.8175)
Epoch 34, loss: 2.9378, val mf1: 0.7794, (best 0.8175)
Epoch 35, loss: 1.5530, val mf1: 0.7892, (best 0.8175)
Epoch 36, loss: 9.4089, val mf1: 0.1037, (best 0.8175)
Epoch 37, loss: 10.2131, val mf1: 0.5827, (best 0.8175)
Epoch 38, loss: 9.6469, val mf1: 0.6266, (best 0.8175)
Epoch 39, loss: 4.1995, val mf1: 0.2209, (best 0.8175)
Epoch 40, loss: 2.8719, val mf1: 0.8195, (best 0.8195)
Epoch 41, loss: 3.5734, val mf1: 0.8290, (best 0.8290)
Epoch 42, loss: 1.6070, val mf1: 0.6821, (best 0.8290)
Epoch 43, loss: 5.2093, val mf1: 0.2781, (best 0.8290)
Epoch 44, loss: 2.7115, val mf1: 0.7845, (best 0.8290)
Epoch 45, loss: 4.2324, val mf1: 0.8289, (best 0.8290)
Epoch 46, loss: 2.8603, val mf1: 0.7837, (best 0.8290)
Epoch 47, loss: 3.8324, val mf1: 0.4030, (best 0.8290)
Epoch 48, loss: 2.4583, val mf1: 0.5252, (best 0.8290)
Epoch 49, loss: 3.1369, val mf1: 0.7962, (best 0.8290)
Epoch 50, loss: 2.9610, val mf1: 0.7995, (best 0.8290)
Epoch 51, loss: 2.1283, val mf1: 0.5249, (best 0.8290)
Epoch 52, loss: 2.6246, val mf1: 0.4493, (best 0.8290)
Epoch 53, loss: 2.6569, val mf1: 0.8202, (best 0.8290)
Epoch 54, loss: 2.8399, val mf1: 0.8308, (best 0.8308)
Epoch 55, loss: 1.3615, val mf1: 0.5874, (best 0.8308)
Epoch 56, loss: 2.5316, val mf1: 0.3733, (best 0.8308)
Epoch 57, loss: 4.8324, val mf1: 0.8170, (best 0.8308)
Epoch 58, loss: 5.3863, val mf1: 0.8037, (best 0.8308)
Epoch 59, loss: 1.0054, val mf1: 0.6227, (best 0.8308)
Epoch 60, loss: 6.2229, val mf1: 0.1566, (best 0.8308)
Epoch 61, loss: 13.5165, val mf1: 0.5998, (best 0.8308)
Epoch 62, loss: 16.4764, val mf1: 0.5575, (best 0.8308)
Epoch 63, loss: 3.3019, val mf1: 0.8416, (best 0.8416)
Epoch 64, loss: 20.1035, val mf1: 0.0738, (best 0.8416)
Epoch 65, loss: 4.7413, val mf1: 0.2806, (best 0.8416)
Epoch 66, loss: 12.8961, val mf1: 0.7801, (best 0.8416)
Epoch 67, loss: 23.0597, val mf1: 0.6457, (best 0.8416)
Epoch 68, loss: 14.8055, val mf1: 0.8138, (best 0.8416)
Epoch 69, loss: 5.1536, val mf1: 0.7286, (best 0.8416)
Epoch 70, loss: 17.4494, val mf1: 0.2333, (best 0.8416)
Epoch 71, loss: 16.6129, val mf1: 0.2434, (best 0.8416)
Epoch 72, loss: 5.8805, val mf1: 0.5112, (best 0.8416)
Epoch 73, loss: 8.8653, val mf1: 0.8072, (best 0.8416)
Epoch 74, loss: 12.7675, val mf1: 0.8344, (best 0.8416)
Epoch 75, loss: 11.6833, val mf1: 0.8323, (best 0.8416)
Epoch 76, loss: 6.9580, val mf1: 0.7866, (best 0.8416)
Epoch 77, loss: 5.3044, val mf1: 0.4900, (best 0.8416)
Epoch 78, loss: 10.0913, val mf1: 0.3055, (best 0.8416)
Epoch 79, loss: 6.3779, val mf1: 0.4211, (best 0.8416)
Epoch 80, loss: 4.2411, val mf1: 0.6904, (best 0.8416)
Epoch 81, loss: 6.7608, val mf1: 0.8273, (best 0.8416)
Epoch 82, loss: 6.9186, val mf1: 0.8347, (best 0.8416)
Epoch 83, loss: 4.3255, val mf1: 0.8055, (best 0.8416)
Epoch 84, loss: 3.6077, val mf1: 0.4741, (best 0.8416)
Epoch 85, loss: 6.3249, val mf1: 0.3151, (best 0.8416)
Epoch 86, loss: 2.3143, val mf1: 0.6364, (best 0.8416)
Epoch 87, loss: 4.4777, val mf1: 0.8345, (best 0.8416)
Epoch 88, loss: 4.7745, val mf1: 0.8419, (best 0.8419)
Epoch 89, loss: 2.3938, val mf1: 0.8164, (best 0.8419)
Epoch 90, loss: 4.7778, val mf1: 0.2826, (best 0.8419)
Epoch 91, loss: 2.2650, val mf1: 0.8256, (best 0.8419)
Epoch 92, loss: 3.8797, val mf1: 0.8443, (best 0.8443)
Epoch 93, loss: 2.6390, val mf1: 0.8380, (best 0.8443)
Epoch 94, loss: 1.7808, val mf1: 0.4677, (best 0.8443)
Epoch 95, loss: 0.9418, val mf1: 0.7152, (best 0.8443)
Epoch 96, loss: 1.3241, val mf1: 0.8195, (best 0.8443)
Epoch 97, loss: 0.8020, val mf1: 0.8061, (best 0.8443)
Epoch 98, loss: 3.6576, val mf1: 0.2555, (best 0.8443)
Epoch 99, loss: 8.4549, val mf1: 0.7677, (best 0.8443)
time cost:  15.161592721939087 s
Test: REC 60.28 PRE 79.17 MF1 83.56 AUC 88.87
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=64, normalization=both, activation=None)
    (1): GraphConv(in=64, out=64, normalization=both, activation=None)
    (2): GraphConv(in=64, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
Average AUC: 0.6128900531850912, Average Recall: 0.6604391995285971, Average Precision: 0.5728987375416871, Average F1: 0.34740487762015276 in 3 runs, with hid_dim: 64, num_layers: 3
Trying hid_dim: 64, num_layers: 4
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 136.6530, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 142.6736, val mf1: 0.0438, (best 0.4883)
Epoch 2, loss: 74.0914, val mf1: 0.0438, (best 0.4883)
Epoch 3, loss: 23.9157, val mf1: 0.5291, (best 0.5291)
Epoch 4, loss: 47.1066, val mf1: 0.4967, (best 0.5291)
Epoch 5, loss: 34.3165, val mf1: 0.5291, (best 0.5291)
Epoch 6, loss: 3.9848, val mf1: 0.7903, (best 0.7903)
Epoch 7, loss: 35.2802, val mf1: 0.0460, (best 0.7903)
Epoch 8, loss: 29.9927, val mf1: 0.0484, (best 0.7903)
Epoch 9, loss: 4.4570, val mf1: 0.4403, (best 0.7903)
Epoch 10, loss: 12.7524, val mf1: 0.5497, (best 0.7903)
Epoch 11, loss: 17.2883, val mf1: 0.5310, (best 0.7903)
Epoch 12, loss: 9.8911, val mf1: 0.6936, (best 0.7903)
Epoch 13, loss: 3.5756, val mf1: 0.5132, (best 0.7903)
Epoch 14, loss: 11.0748, val mf1: 0.2123, (best 0.7903)
Epoch 15, loss: 13.1490, val mf1: 0.1884, (best 0.7903)
Epoch 16, loss: 6.5853, val mf1: 0.3557, (best 0.7903)
Epoch 17, loss: 3.8433, val mf1: 0.7136, (best 0.7903)
Epoch 18, loss: 8.9788, val mf1: 0.7488, (best 0.7903)
Epoch 19, loss: 9.4761, val mf1: 0.7348, (best 0.7903)
Epoch 20, loss: 4.7087, val mf1: 0.7802, (best 0.7903)
Epoch 21, loss: 4.1533, val mf1: 0.4838, (best 0.7903)
Epoch 22, loss: 7.7037, val mf1: 0.2951, (best 0.7903)
Epoch 23, loss: 7.1753, val mf1: 0.3129, (best 0.7903)
Epoch 24, loss: 3.7527, val mf1: 0.4929, (best 0.7903)
Epoch 25, loss: 3.8962, val mf1: 0.7624, (best 0.7903)
Epoch 26, loss: 5.9414, val mf1: 0.7970, (best 0.7970)
Epoch 27, loss: 5.5832, val mf1: 0.7983, (best 0.7983)
Epoch 28, loss: 3.3780, val mf1: 0.7692, (best 0.7983)
Epoch 29, loss: 3.4492, val mf1: 0.4968, (best 0.7983)
Epoch 30, loss: 4.4297, val mf1: 0.4142, (best 0.7983)
Epoch 31, loss: 3.8837, val mf1: 0.4354, (best 0.7983)
Epoch 32, loss: 2.4857, val mf1: 0.5421, (best 0.7983)
Epoch 33, loss: 2.8395, val mf1: 0.7754, (best 0.7983)
Epoch 34, loss: 3.5515, val mf1: 0.8039, (best 0.8039)
Epoch 35, loss: 2.7716, val mf1: 0.7932, (best 0.8039)
Epoch 36, loss: 2.0045, val mf1: 0.5825, (best 0.8039)
Epoch 37, loss: 2.5486, val mf1: 0.4737, (best 0.8039)
Epoch 38, loss: 2.3393, val mf1: 0.4804, (best 0.8039)
Epoch 39, loss: 1.6286, val mf1: 0.6217, (best 0.8039)
Epoch 40, loss: 2.1332, val mf1: 0.8060, (best 0.8060)
Epoch 41, loss: 2.0153, val mf1: 0.8086, (best 0.8086)
Epoch 42, loss: 1.4185, val mf1: 0.6159, (best 0.8086)
Epoch 43, loss: 1.8726, val mf1: 0.4931, (best 0.8086)
Epoch 44, loss: 1.4541, val mf1: 0.5394, (best 0.8086)
Epoch 45, loss: 1.3439, val mf1: 0.8078, (best 0.8086)
Epoch 46, loss: 1.4817, val mf1: 0.8132, (best 0.8132)
Epoch 47, loss: 0.9873, val mf1: 0.6949, (best 0.8132)
Epoch 48, loss: 1.3448, val mf1: 0.5136, (best 0.8132)
Epoch 49, loss: 0.8463, val mf1: 0.8121, (best 0.8132)
Epoch 50, loss: 1.1037, val mf1: 0.8203, (best 0.8203)
Epoch 51, loss: 0.7043, val mf1: 0.7814, (best 0.8203)
Epoch 52, loss: 1.0193, val mf1: 0.5497, (best 0.8203)
Epoch 53, loss: 1.0144, val mf1: 0.8313, (best 0.8313)
Epoch 54, loss: 0.8006, val mf1: 0.8302, (best 0.8313)
Epoch 55, loss: 1.5645, val mf1: 0.4426, (best 0.8313)
Epoch 56, loss: 4.3129, val mf1: 0.5610, (best 0.8313)
Epoch 57, loss: 2.8196, val mf1: 0.6703, (best 0.8313)
Epoch 58, loss: 5.3145, val mf1: 0.1283, (best 0.8313)
Epoch 59, loss: 0.7857, val mf1: 0.6409, (best 0.8313)
Epoch 60, loss: 3.6202, val mf1: 0.6573, (best 0.8313)
Epoch 61, loss: 2.0143, val mf1: 0.8245, (best 0.8313)
Epoch 62, loss: 1.9878, val mf1: 0.3959, (best 0.8313)
Epoch 63, loss: 0.7743, val mf1: 0.8174, (best 0.8313)
Epoch 64, loss: 1.3752, val mf1: 0.8321, (best 0.8321)
Epoch 65, loss: 1.0843, val mf1: 0.8223, (best 0.8321)
Epoch 66, loss: 1.7209, val mf1: 0.5053, (best 0.8321)
Epoch 67, loss: 0.9649, val mf1: 0.6450, (best 0.8321)
Epoch 68, loss: 0.9358, val mf1: 0.8184, (best 0.8321)
Epoch 69, loss: 0.9151, val mf1: 0.8204, (best 0.8321)
Epoch 70, loss: 0.7999, val mf1: 0.7143, (best 0.8321)
Epoch 71, loss: 0.8630, val mf1: 0.6189, (best 0.8321)
Epoch 72, loss: 0.7105, val mf1: 0.8179, (best 0.8321)
Epoch 73, loss: 0.7702, val mf1: 0.8256, (best 0.8321)
Epoch 74, loss: 0.6376, val mf1: 0.8142, (best 0.8321)
Epoch 75, loss: 0.7136, val mf1: 0.6899, (best 0.8321)
Epoch 76, loss: 0.6099, val mf1: 0.8230, (best 0.8321)
Epoch 77, loss: 0.6211, val mf1: 0.8303, (best 0.8321)
Epoch 78, loss: 0.5821, val mf1: 0.8008, (best 0.8321)
Epoch 79, loss: 0.5199, val mf1: 0.8208, (best 0.8321)
Epoch 80, loss: 0.5525, val mf1: 0.8354, (best 0.8354)
Epoch 81, loss: 0.4734, val mf1: 0.8235, (best 0.8354)
Epoch 82, loss: 0.4928, val mf1: 0.8199, (best 0.8354)
Epoch 83, loss: 0.5465, val mf1: 0.8448, (best 0.8448)
Epoch 84, loss: 0.4155, val mf1: 0.8332, (best 0.8448)
Epoch 85, loss: 0.5577, val mf1: 0.8165, (best 0.8448)
Epoch 86, loss: 2.0027, val mf1: 0.6952, (best 0.8448)
Epoch 87, loss: 0.3834, val mf1: 0.8386, (best 0.8448)
Epoch 88, loss: 3.8275, val mf1: 0.1955, (best 0.8448)
Epoch 89, loss: 3.5720, val mf1: 0.5791, (best 0.8448)
Epoch 90, loss: 3.1904, val mf1: 0.6060, (best 0.8448)
Epoch 91, loss: 3.3339, val mf1: 0.2189, (best 0.8448)
Epoch 92, loss: 0.5411, val mf1: 0.8451, (best 0.8451)
Epoch 93, loss: 1.0912, val mf1: 0.8432, (best 0.8451)
Epoch 94, loss: 0.5108, val mf1: 0.8339, (best 0.8451)
Epoch 95, loss: 1.9430, val mf1: 0.3371, (best 0.8451)
Epoch 96, loss: 2.6934, val mf1: 0.7932, (best 0.8451)
Epoch 97, loss: 3.3215, val mf1: 0.7639, (best 0.8451)
Epoch 98, loss: 0.7701, val mf1: 0.8198, (best 0.8451)
Epoch 99, loss: 5.1285, val mf1: 0.1362, (best 0.8451)
time cost:  16.28158950805664 s
Test: REC 60.14 PRE 76.76 MF1 83.03 AUC 88.76
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=64, normalization=both, activation=None)
    (1-2): 2 x GraphConv(in=64, out=64, normalization=both, activation=None)
    (3): GraphConv(in=64, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 27.7062, val mf1: 0.0555, (best 0.0555)
Epoch 1, loss: 183.6653, val mf1: 0.4967, (best 0.4967)
Epoch 2, loss: 168.2412, val mf1: 0.4967, (best 0.4967)
Epoch 3, loss: 110.4780, val mf1: 0.4967, (best 0.4967)
Epoch 4, loss: 37.4408, val mf1: 0.5291, (best 0.5291)
Epoch 5, loss: 57.1040, val mf1: 0.0438, (best 0.5291)
Epoch 6, loss: 71.7462, val mf1: 0.0438, (best 0.5291)
Epoch 7, loss: 42.4816, val mf1: 0.0438, (best 0.5291)
Epoch 8, loss: 1.0837, val mf1: 0.7813, (best 0.7813)
Epoch 9, loss: 19.3349, val mf1: 0.5289, (best 0.7813)
Epoch 10, loss: 22.4267, val mf1: 0.5289, (best 0.7813)
Epoch 11, loss: 13.5011, val mf1: 0.5304, (best 0.7813)
Epoch 12, loss: 1.3926, val mf1: 0.5454, (best 0.7813)
Epoch 13, loss: 14.6392, val mf1: 0.0542, (best 0.7813)
Epoch 14, loss: 10.6070, val mf1: 0.0687, (best 0.7813)
Epoch 15, loss: 1.9258, val mf1: 0.7640, (best 0.7813)
Epoch 16, loss: 8.8718, val mf1: 0.5576, (best 0.7813)
Epoch 17, loss: 9.6231, val mf1: 0.5514, (best 0.7813)
Epoch 18, loss: 3.8919, val mf1: 0.7945, (best 0.7945)
Epoch 19, loss: 2.8942, val mf1: 0.4929, (best 0.7945)
Epoch 20, loss: 6.5017, val mf1: 0.2709, (best 0.7945)
Epoch 21, loss: 5.4372, val mf1: 0.3402, (best 0.7945)
Epoch 22, loss: 2.7279, val mf1: 0.5392, (best 0.7945)
Epoch 23, loss: 4.0730, val mf1: 0.7958, (best 0.7958)
Epoch 24, loss: 5.0691, val mf1: 0.7924, (best 0.7958)
Epoch 25, loss: 3.4767, val mf1: 0.7822, (best 0.7958)
Epoch 26, loss: 3.2385, val mf1: 0.5168, (best 0.7958)
Epoch 27, loss: 3.4931, val mf1: 0.4658, (best 0.7958)
Epoch 28, loss: 3.2611, val mf1: 0.4726, (best 0.7958)
Epoch 29, loss: 2.4666, val mf1: 0.5481, (best 0.7958)
Epoch 30, loss: 2.5956, val mf1: 0.7570, (best 0.7958)
Epoch 31, loss: 2.7815, val mf1: 0.7859, (best 0.7958)
Epoch 32, loss: 2.1184, val mf1: 0.7033, (best 0.7958)
Epoch 33, loss: 2.0607, val mf1: 0.5344, (best 0.7958)
Epoch 34, loss: 2.3399, val mf1: 0.4864, (best 0.7958)
Epoch 35, loss: 1.8412, val mf1: 0.5356, (best 0.7958)
Epoch 36, loss: 1.6384, val mf1: 0.7408, (best 0.7958)
Epoch 37, loss: 1.8714, val mf1: 0.8026, (best 0.8026)
Epoch 38, loss: 1.4478, val mf1: 0.7669, (best 0.8026)
Epoch 39, loss: 1.4528, val mf1: 0.5452, (best 0.8026)
Epoch 40, loss: 1.5410, val mf1: 0.5133, (best 0.8026)
Epoch 41, loss: 1.1264, val mf1: 0.7131, (best 0.8026)
Epoch 42, loss: 1.3749, val mf1: 0.8070, (best 0.8070)
Epoch 43, loss: 1.0528, val mf1: 0.8090, (best 0.8090)
Epoch 44, loss: 1.1458, val mf1: 0.5502, (best 0.8090)
Epoch 45, loss: 0.8872, val mf1: 0.6524, (best 0.8090)
Epoch 46, loss: 1.0068, val mf1: 0.8179, (best 0.8179)
Epoch 47, loss: 0.7840, val mf1: 0.8075, (best 0.8179)
Epoch 48, loss: 1.1429, val mf1: 0.5481, (best 0.8179)
Epoch 49, loss: 0.8503, val mf1: 0.8080, (best 0.8179)
Epoch 50, loss: 0.8113, val mf1: 0.8019, (best 0.8179)
Epoch 51, loss: 1.1287, val mf1: 0.5471, (best 0.8179)
Epoch 52, loss: 0.8876, val mf1: 0.7903, (best 0.8179)
Epoch 53, loss: 0.5978, val mf1: 0.7871, (best 0.8179)
Epoch 54, loss: 1.5883, val mf1: 0.4202, (best 0.8179)
Epoch 55, loss: 3.4995, val mf1: 0.5487, (best 0.8179)
Epoch 56, loss: 1.8092, val mf1: 0.6797, (best 0.8179)
Epoch 57, loss: 3.5922, val mf1: 0.2339, (best 0.8179)
Epoch 58, loss: 1.1502, val mf1: 0.5667, (best 0.8179)
Epoch 59, loss: 3.0604, val mf1: 0.7467, (best 0.8179)
Epoch 60, loss: 2.0805, val mf1: 0.8335, (best 0.8335)
Epoch 61, loss: 1.4435, val mf1: 0.5768, (best 0.8335)
Epoch 62, loss: 2.2967, val mf1: 0.4567, (best 0.8335)
Epoch 63, loss: 1.6851, val mf1: 0.5238, (best 0.8335)
Epoch 64, loss: 1.5346, val mf1: 0.7939, (best 0.8335)
Epoch 65, loss: 1.9825, val mf1: 0.8143, (best 0.8335)
Epoch 66, loss: 1.5723, val mf1: 0.8122, (best 0.8335)
Epoch 67, loss: 1.4385, val mf1: 0.5657, (best 0.8335)
Epoch 68, loss: 1.8031, val mf1: 0.4955, (best 0.8335)
Epoch 69, loss: 1.3519, val mf1: 0.5776, (best 0.8335)
Epoch 70, loss: 1.4046, val mf1: 0.8136, (best 0.8335)
Epoch 71, loss: 1.5305, val mf1: 0.8146, (best 0.8335)
Epoch 72, loss: 1.1595, val mf1: 0.7477, (best 0.8335)
Epoch 73, loss: 1.3449, val mf1: 0.5401, (best 0.8335)
Epoch 74, loss: 1.2343, val mf1: 0.5605, (best 0.8335)
Epoch 75, loss: 1.0719, val mf1: 0.8001, (best 0.8335)
Epoch 76, loss: 1.2146, val mf1: 0.8160, (best 0.8335)
Epoch 77, loss: 0.9498, val mf1: 0.7840, (best 0.8335)
Epoch 78, loss: 1.0854, val mf1: 0.5708, (best 0.8335)
Epoch 79, loss: 0.8949, val mf1: 0.6788, (best 0.8335)
Epoch 80, loss: 1.8004, val mf1: 0.8118, (best 0.8335)
Epoch 81, loss: 1.0186, val mf1: 0.5759, (best 0.8335)
Epoch 82, loss: 0.8564, val mf1: 0.6477, (best 0.8335)
Epoch 83, loss: 0.9118, val mf1: 0.8209, (best 0.8335)
Epoch 84, loss: 0.8362, val mf1: 0.8168, (best 0.8335)
Epoch 85, loss: 0.8055, val mf1: 0.6535, (best 0.8335)
Epoch 86, loss: 0.6441, val mf1: 0.7768, (best 0.8335)
Epoch 87, loss: 0.7692, val mf1: 0.8081, (best 0.8335)
Epoch 88, loss: 0.5857, val mf1: 0.7945, (best 0.8335)
Epoch 89, loss: 0.8690, val mf1: 0.6500, (best 0.8335)
Epoch 90, loss: 0.9420, val mf1: 0.7871, (best 0.8335)
Epoch 91, loss: 0.6043, val mf1: 0.7853, (best 0.8335)
Epoch 92, loss: 1.7802, val mf1: 0.3481, (best 0.8335)
Epoch 93, loss: 3.7579, val mf1: 0.5388, (best 0.8335)
Epoch 94, loss: 3.2041, val mf1: 0.5759, (best 0.8335)
Epoch 95, loss: 1.8465, val mf1: 0.3270, (best 0.8335)
Epoch 96, loss: 0.5756, val mf1: 0.8080, (best 0.8335)
Epoch 97, loss: 0.9403, val mf1: 0.8272, (best 0.8335)
Epoch 98, loss: 0.6304, val mf1: 0.8052, (best 0.8335)
Epoch 99, loss: 1.0841, val mf1: 0.5467, (best 0.8335)
time cost:  16.45182991027832 s
Test: REC 54.76 PRE 80.20 MF1 81.84 AUC 85.85
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=64, normalization=both, activation=None)
    (1-2): 2 x GraphConv(in=64, out=64, normalization=both, activation=None)
    (3): GraphConv(in=64, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 148.1476, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 179.5547, val mf1: 0.0438, (best 0.4883)
Epoch 2, loss: 76.5893, val mf1: 0.0439, (best 0.4883)
Epoch 3, loss: 69.6467, val mf1: 0.4967, (best 0.4967)
Epoch 4, loss: 102.1017, val mf1: 0.4967, (best 0.4967)
Epoch 5, loss: 83.4288, val mf1: 0.5291, (best 0.5291)
Epoch 6, loss: 39.5206, val mf1: 0.5282, (best 0.5291)
Epoch 7, loss: 11.6688, val mf1: 0.2202, (best 0.5291)
Epoch 8, loss: 43.3620, val mf1: 0.0470, (best 0.5291)
Epoch 9, loss: 28.1143, val mf1: 0.0542, (best 0.5291)
Epoch 10, loss: 4.6204, val mf1: 0.5349, (best 0.5349)
Epoch 11, loss: 19.9183, val mf1: 0.5261, (best 0.5349)
Epoch 12, loss: 24.3664, val mf1: 0.5269, (best 0.5349)
Epoch 13, loss: 14.1700, val mf1: 0.5478, (best 0.5478)
Epoch 14, loss: 5.8140, val mf1: 0.5030, (best 0.5478)
Epoch 15, loss: 14.4242, val mf1: 0.2477, (best 0.5478)
Epoch 16, loss: 15.8930, val mf1: 0.2244, (best 0.5478)
Epoch 17, loss: 9.5478, val mf1: 0.3753, (best 0.5478)
Epoch 18, loss: 5.2366, val mf1: 0.5091, (best 0.5478)
Epoch 19, loss: 6.4494, val mf1: 0.7002, (best 0.7002)
Epoch 20, loss: 9.8176, val mf1: 0.6775, (best 0.7002)
Epoch 21, loss: 7.4148, val mf1: 0.7127, (best 0.7127)
Epoch 22, loss: 4.8352, val mf1: 0.5780, (best 0.7127)
Epoch 23, loss: 5.5878, val mf1: 0.4681, (best 0.7127)
Epoch 24, loss: 7.1111, val mf1: 0.4164, (best 0.7127)
Epoch 25, loss: 7.1010, val mf1: 0.4106, (best 0.7127)
Epoch 26, loss: 5.4272, val mf1: 0.4557, (best 0.7127)
Epoch 27, loss: 4.0383, val mf1: 0.5429, (best 0.7127)
Epoch 28, loss: 4.9716, val mf1: 0.7061, (best 0.7127)
Epoch 29, loss: 5.6016, val mf1: 0.7302, (best 0.7302)
Epoch 30, loss: 4.0133, val mf1: 0.6799, (best 0.7302)
Epoch 31, loss: 3.4401, val mf1: 0.5261, (best 0.7302)
Epoch 32, loss: 4.1787, val mf1: 0.4599, (best 0.7302)
Epoch 33, loss: 4.3137, val mf1: 0.4458, (best 0.7302)
Epoch 34, loss: 3.4124, val mf1: 0.4858, (best 0.7302)
Epoch 35, loss: 2.8307, val mf1: 0.6032, (best 0.7302)
Epoch 36, loss: 3.4739, val mf1: 0.7282, (best 0.7302)
Epoch 37, loss: 3.2585, val mf1: 0.7299, (best 0.7302)
Epoch 38, loss: 2.3888, val mf1: 0.5976, (best 0.7302)
Epoch 39, loss: 2.7189, val mf1: 0.4854, (best 0.7302)
Epoch 40, loss: 2.8323, val mf1: 0.4651, (best 0.7302)
Epoch 41, loss: 2.0535, val mf1: 0.5386, (best 0.7302)
Epoch 42, loss: 2.1552, val mf1: 0.7255, (best 0.7302)
Epoch 43, loss: 2.2637, val mf1: 0.7417, (best 0.7417)
Epoch 44, loss: 1.5835, val mf1: 0.6051, (best 0.7417)
Epoch 45, loss: 1.9934, val mf1: 0.4827, (best 0.7417)
Epoch 46, loss: 1.5363, val mf1: 0.5318, (best 0.7417)
Epoch 47, loss: 1.5033, val mf1: 0.7545, (best 0.7545)
Epoch 48, loss: 1.3902, val mf1: 0.7620, (best 0.7620)
Epoch 49, loss: 1.2684, val mf1: 0.5281, (best 0.7620)
Epoch 50, loss: 1.1211, val mf1: 0.5449, (best 0.7620)
Epoch 51, loss: 1.2981, val mf1: 0.7798, (best 0.7798)
Epoch 52, loss: 0.6908, val mf1: 0.7749, (best 0.7798)
Epoch 53, loss: 1.4102, val mf1: 0.4732, (best 0.7798)
Epoch 54, loss: 2.7548, val mf1: 0.6328, (best 0.7798)
Epoch 55, loss: 0.5425, val mf1: 0.8102, (best 0.8102)
Epoch 56, loss: 4.6900, val mf1: 0.1466, (best 0.8102)
Epoch 57, loss: 2.8004, val mf1: 0.7313, (best 0.8102)
Epoch 58, loss: 2.5049, val mf1: 0.8108, (best 0.8108)
Epoch 59, loss: 1.0078, val mf1: 0.5897, (best 0.8108)
Epoch 60, loss: 3.3773, val mf1: 0.2800, (best 0.8108)
Epoch 61, loss: 2.2958, val mf1: 0.8219, (best 0.8219)
Epoch 62, loss: 4.8064, val mf1: 0.7996, (best 0.8219)
Epoch 63, loss: 3.2328, val mf1: 0.8159, (best 0.8219)
Epoch 64, loss: 1.9757, val mf1: 0.5771, (best 0.8219)
Epoch 65, loss: 3.7449, val mf1: 0.4139, (best 0.8219)
Epoch 66, loss: 2.9279, val mf1: 0.4624, (best 0.8219)
Epoch 67, loss: 1.7850, val mf1: 0.6742, (best 0.8219)
Epoch 68, loss: 2.6226, val mf1: 0.8129, (best 0.8219)
Epoch 69, loss: 2.6086, val mf1: 0.8230, (best 0.8230)
Epoch 70, loss: 1.3827, val mf1: 0.8133, (best 0.8230)
Epoch 71, loss: 1.8690, val mf1: 0.4610, (best 0.8230)
Epoch 72, loss: 1.4182, val mf1: 0.5062, (best 0.8230)
Epoch 73, loss: 1.2962, val mf1: 0.8292, (best 0.8292)
Epoch 74, loss: 1.9395, val mf1: 0.8322, (best 0.8322)
Epoch 75, loss: 1.0133, val mf1: 0.8320, (best 0.8322)
Epoch 76, loss: 2.0840, val mf1: 0.3105, (best 0.8322)
Epoch 77, loss: 1.9279, val mf1: 0.8300, (best 0.8322)
Epoch 78, loss: 3.1731, val mf1: 0.7502, (best 0.8322)
Epoch 79, loss: 0.6563, val mf1: 0.8280, (best 0.8322)
Epoch 80, loss: 5.7402, val mf1: 0.1122, (best 0.8322)
Epoch 81, loss: 0.6397, val mf1: 0.8106, (best 0.8322)
Epoch 82, loss: 2.1797, val mf1: 0.8329, (best 0.8329)
Epoch 83, loss: 2.1925, val mf1: 0.8340, (best 0.8340)
Epoch 84, loss: 0.8665, val mf1: 0.8123, (best 0.8340)
Epoch 85, loss: 2.5539, val mf1: 0.3376, (best 0.8340)
Epoch 86, loss: 0.9090, val mf1: 0.6680, (best 0.8340)
Epoch 87, loss: 1.5726, val mf1: 0.8320, (best 0.8340)
Epoch 88, loss: 1.8803, val mf1: 0.8343, (best 0.8343)
Epoch 89, loss: 1.1464, val mf1: 0.8209, (best 0.8343)
Epoch 90, loss: 1.3689, val mf1: 0.5147, (best 0.8343)
Epoch 91, loss: 1.4388, val mf1: 0.5015, (best 0.8343)
Epoch 92, loss: 0.9909, val mf1: 0.8165, (best 0.8343)
Epoch 93, loss: 1.4523, val mf1: 0.8361, (best 0.8361)
Epoch 94, loss: 1.1036, val mf1: 0.8343, (best 0.8361)
Epoch 95, loss: 0.8551, val mf1: 0.6416, (best 0.8361)
Epoch 96, loss: 1.1784, val mf1: 0.5285, (best 0.8361)
Epoch 97, loss: 0.8918, val mf1: 0.8354, (best 0.8361)
Epoch 98, loss: 1.2242, val mf1: 0.8434, (best 0.8434)
Epoch 99, loss: 0.6780, val mf1: 0.8358, (best 0.8434)
time cost:  16.388116121292114 s
Test: REC 61.79 PRE 73.20 MF1 82.78 AUC 88.27
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=64, normalization=both, activation=None)
    (1-2): 2 x GraphConv(in=64, out=64, normalization=both, activation=None)
    (3): GraphConv(in=64, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
Average AUC: 0.4423337337822015, Average Recall: 0.6940263230419497, Average Precision: 0.1441656311513664, Average F1: 0.22823788346555096 in 3 runs, with hid_dim: 64, num_layers: 4
Trying hid_dim: 64, num_layers: 5
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 82.3127, val mf1: 0.0438, (best 0.0438)
Epoch 1, loss: 135.6784, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 80.9155, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 4.3905, val mf1: 0.3660, (best 0.4883)
Epoch 4, loss: 16.9445, val mf1: 0.0527, (best 0.4883)
Epoch 5, loss: 34.7680, val mf1: 0.4967, (best 0.4967)
Epoch 6, loss: 26.2996, val mf1: 0.4967, (best 0.4967)
Epoch 7, loss: 2.1542, val mf1: 0.5088, (best 0.5088)
Epoch 8, loss: 21.6790, val mf1: 0.0483, (best 0.5088)
Epoch 9, loss: 8.7542, val mf1: 0.0990, (best 0.5088)
Epoch 10, loss: 9.0238, val mf1: 0.5334, (best 0.5334)
Epoch 11, loss: 12.7083, val mf1: 0.5284, (best 0.5334)
Epoch 12, loss: 3.1354, val mf1: 0.7661, (best 0.7661)
Epoch 13, loss: 5.9907, val mf1: 0.2864, (best 0.7661)
Epoch 14, loss: 8.2868, val mf1: 0.2072, (best 0.7661)
Epoch 15, loss: 2.8635, val mf1: 0.4672, (best 0.7661)
Epoch 16, loss: 4.4443, val mf1: 0.7189, (best 0.7661)
Epoch 17, loss: 5.1410, val mf1: 0.6835, (best 0.7661)
Epoch 18, loss: 2.0941, val mf1: 0.5786, (best 0.7661)
Epoch 19, loss: 4.0829, val mf1: 0.4030, (best 0.7661)
Epoch 20, loss: 4.4567, val mf1: 0.3785, (best 0.7661)
Epoch 21, loss: 2.4002, val mf1: 0.5056, (best 0.7661)
Epoch 22, loss: 2.4258, val mf1: 0.7649, (best 0.7661)
Epoch 23, loss: 3.6563, val mf1: 0.7522, (best 0.7661)
Epoch 24, loss: 2.1133, val mf1: 0.7683, (best 0.7683)
Epoch 25, loss: 1.8896, val mf1: 0.5223, (best 0.7683)
Epoch 26, loss: 3.0084, val mf1: 0.4157, (best 0.7683)
Epoch 27, loss: 2.1168, val mf1: 0.4782, (best 0.7683)
Epoch 28, loss: 1.3659, val mf1: 0.7277, (best 0.7683)
Epoch 29, loss: 2.2938, val mf1: 0.7703, (best 0.7703)
Epoch 30, loss: 1.6710, val mf1: 0.7779, (best 0.7779)
Epoch 31, loss: 1.3159, val mf1: 0.5582, (best 0.7779)
Epoch 32, loss: 2.0649, val mf1: 0.4509, (best 0.7779)
Epoch 33, loss: 1.2226, val mf1: 0.5653, (best 0.7779)
Epoch 34, loss: 1.4335, val mf1: 0.7755, (best 0.7779)
Epoch 35, loss: 1.5556, val mf1: 0.7703, (best 0.7779)
Epoch 36, loss: 0.9803, val mf1: 0.6388, (best 0.7779)
Epoch 37, loss: 1.5536, val mf1: 0.4852, (best 0.7779)
Epoch 38, loss: 0.8947, val mf1: 0.6573, (best 0.7779)
Epoch 39, loss: 1.2667, val mf1: 0.7765, (best 0.7779)
Epoch 40, loss: 0.9601, val mf1: 0.7812, (best 0.7812)
Epoch 41, loss: 0.9730, val mf1: 0.5747, (best 0.7812)
Epoch 42, loss: 0.9775, val mf1: 0.5678, (best 0.7812)
Epoch 43, loss: 0.8246, val mf1: 0.7858, (best 0.7858)
Epoch 44, loss: 0.9207, val mf1: 0.7865, (best 0.7865)
Epoch 45, loss: 0.7583, val mf1: 0.6459, (best 0.7865)
Epoch 46, loss: 0.7372, val mf1: 0.6578, (best 0.7865)
Epoch 47, loss: 0.8757, val mf1: 0.7896, (best 0.7896)
Epoch 48, loss: 0.5405, val mf1: 0.7928, (best 0.7928)
Epoch 49, loss: 1.0015, val mf1: 0.5611, (best 0.7928)
Epoch 50, loss: 1.3036, val mf1: 0.7155, (best 0.7928)
Epoch 51, loss: 0.5030, val mf1: 0.7927, (best 0.7928)
Epoch 52, loss: 1.4349, val mf1: 0.4692, (best 0.7928)
Epoch 53, loss: 2.6252, val mf1: 0.5913, (best 0.7928)
Epoch 54, loss: 1.4715, val mf1: 0.7821, (best 0.7928)
Epoch 55, loss: 1.6552, val mf1: 0.4608, (best 0.7928)
Epoch 56, loss: 2.1568, val mf1: 0.3927, (best 0.7928)
Epoch 57, loss: 0.8619, val mf1: 0.7762, (best 0.7928)
Epoch 58, loss: 2.0292, val mf1: 0.7785, (best 0.7928)
Epoch 59, loss: 1.1763, val mf1: 0.7949, (best 0.7949)
Epoch 60, loss: 1.2496, val mf1: 0.5363, (best 0.7949)
Epoch 61, loss: 1.7246, val mf1: 0.4743, (best 0.7949)
Epoch 62, loss: 0.9713, val mf1: 0.6578, (best 0.7949)
Epoch 63, loss: 1.3872, val mf1: 0.7987, (best 0.7987)
Epoch 64, loss: 1.3988, val mf1: 0.8010, (best 0.8010)
Epoch 65, loss: 0.8972, val mf1: 0.7267, (best 0.8010)
Epoch 66, loss: 1.3098, val mf1: 0.5165, (best 0.8010)
Epoch 67, loss: 1.0497, val mf1: 0.5691, (best 0.8010)
Epoch 68, loss: 0.8887, val mf1: 0.8002, (best 0.8010)
Epoch 69, loss: 1.1398, val mf1: 0.8058, (best 0.8058)
Epoch 70, loss: 0.7322, val mf1: 0.7961, (best 0.8058)
Epoch 71, loss: 1.1351, val mf1: 0.5264, (best 0.8058)
Epoch 72, loss: 0.6518, val mf1: 0.7956, (best 0.8058)
Epoch 73, loss: 0.9214, val mf1: 0.8110, (best 0.8110)
Epoch 74, loss: 0.6185, val mf1: 0.8023, (best 0.8110)
Epoch 75, loss: 0.8493, val mf1: 0.6014, (best 0.8110)
Epoch 76, loss: 0.5498, val mf1: 0.7985, (best 0.8110)
Epoch 77, loss: 0.7704, val mf1: 0.8175, (best 0.8175)
Epoch 78, loss: 0.4972, val mf1: 0.8024, (best 0.8175)
Epoch 79, loss: 0.7290, val mf1: 0.6913, (best 0.8175)
Epoch 80, loss: 0.6729, val mf1: 0.8239, (best 0.8239)
Epoch 81, loss: 0.4604, val mf1: 0.8241, (best 0.8241)
Epoch 82, loss: 0.8274, val mf1: 0.6908, (best 0.8241)
Epoch 83, loss: 1.7986, val mf1: 0.5580, (best 0.8241)
Epoch 84, loss: 0.4432, val mf1: 0.8272, (best 0.8272)
Epoch 85, loss: 2.2529, val mf1: 0.3007, (best 0.8272)
Epoch 86, loss: 1.5352, val mf1: 0.6355, (best 0.8272)
Epoch 87, loss: 0.9595, val mf1: 0.8191, (best 0.8272)
Epoch 88, loss: 1.3895, val mf1: 0.4660, (best 0.8272)
Epoch 89, loss: 0.6547, val mf1: 0.7430, (best 0.8272)
Epoch 90, loss: 0.9942, val mf1: 0.8186, (best 0.8272)
Epoch 91, loss: 1.0178, val mf1: 0.8170, (best 0.8272)
Epoch 92, loss: 0.7109, val mf1: 0.7693, (best 0.8272)
Epoch 93, loss: 1.0729, val mf1: 0.5495, (best 0.8272)
Epoch 94, loss: 0.8319, val mf1: 0.6463, (best 0.8272)
Epoch 95, loss: 0.8210, val mf1: 0.8122, (best 0.8272)
Epoch 96, loss: 0.9659, val mf1: 0.8116, (best 0.8272)
Epoch 97, loss: 0.7411, val mf1: 0.8102, (best 0.8272)
Epoch 98, loss: 0.7990, val mf1: 0.6496, (best 0.8272)
Epoch 99, loss: 0.8205, val mf1: 0.6258, (best 0.8272)
time cost:  17.64332389831543 s
Test: REC 60.69 PRE 68.43 MF1 81.36 AUC 88.81
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=64, normalization=both, activation=None)
    (1-3): 3 x GraphConv(in=64, out=64, normalization=both, activation=None)
    (4): GraphConv(in=64, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 60.7027, val mf1: 0.0438, (best 0.0438)
Epoch 1, loss: 101.3103, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 54.6726, val mf1: 0.4967, (best 0.4967)
Epoch 3, loss: 21.7424, val mf1: 0.0462, (best 0.4967)
Epoch 4, loss: 1.8652, val mf1: 0.3722, (best 0.4967)
Epoch 5, loss: 32.7899, val mf1: 0.4967, (best 0.4967)
Epoch 6, loss: 26.1688, val mf1: 0.4967, (best 0.4967)
Epoch 7, loss: 1.4457, val mf1: 0.5979, (best 0.5979)
Epoch 8, loss: 20.1570, val mf1: 0.0481, (best 0.5979)
Epoch 9, loss: 4.3478, val mf1: 0.2881, (best 0.5979)
Epoch 10, loss: 13.9181, val mf1: 0.4967, (best 0.5979)
Epoch 11, loss: 15.1864, val mf1: 0.4967, (best 0.5979)
Epoch 12, loss: 2.3753, val mf1: 0.7371, (best 0.7371)
Epoch 13, loss: 15.7591, val mf1: 0.0516, (best 0.7371)
Epoch 14, loss: 14.8364, val mf1: 0.0531, (best 0.7371)
Epoch 15, loss: 1.6340, val mf1: 0.5872, (best 0.7371)
Epoch 16, loss: 10.4406, val mf1: 0.5341, (best 0.7371)
Epoch 17, loss: 11.4270, val mf1: 0.5300, (best 0.7371)
Epoch 18, loss: 3.5186, val mf1: 0.6846, (best 0.7371)
Epoch 19, loss: 7.4394, val mf1: 0.0928, (best 0.7371)
Epoch 20, loss: 8.6168, val mf1: 0.0817, (best 0.7371)
Epoch 21, loss: 1.8534, val mf1: 0.5085, (best 0.7371)
Epoch 22, loss: 3.9774, val mf1: 0.7215, (best 0.7371)
Epoch 23, loss: 5.1326, val mf1: 0.6716, (best 0.7371)
Epoch 24, loss: 2.5488, val mf1: 0.7453, (best 0.7453)
Epoch 25, loss: 2.4744, val mf1: 0.5030, (best 0.7453)
Epoch 26, loss: 3.8807, val mf1: 0.4057, (best 0.7453)
Epoch 27, loss: 3.9993, val mf1: 0.3985, (best 0.7453)
Epoch 28, loss: 2.7896, val mf1: 0.4762, (best 0.7453)
Epoch 29, loss: 2.2026, val mf1: 0.6006, (best 0.7453)
Epoch 30, loss: 2.9274, val mf1: 0.7551, (best 0.7551)
Epoch 31, loss: 3.2924, val mf1: 0.7670, (best 0.7670)
Epoch 32, loss: 2.5673, val mf1: 0.7502, (best 0.7670)
Epoch 33, loss: 1.9855, val mf1: 0.6029, (best 0.7670)
Epoch 34, loss: 2.1916, val mf1: 0.5043, (best 0.7670)
Epoch 35, loss: 2.5040, val mf1: 0.4637, (best 0.7670)
Epoch 36, loss: 2.3033, val mf1: 0.4717, (best 0.7670)
Epoch 37, loss: 1.7472, val mf1: 0.5277, (best 0.7670)
Epoch 38, loss: 1.4803, val mf1: 0.6691, (best 0.7670)
Epoch 39, loss: 1.7633, val mf1: 0.7721, (best 0.7721)
Epoch 40, loss: 1.6989, val mf1: 0.7766, (best 0.7766)
Epoch 41, loss: 1.1065, val mf1: 0.7448, (best 0.7766)
Epoch 42, loss: 1.1605, val mf1: 0.5452, (best 0.7766)
Epoch 43, loss: 1.3350, val mf1: 0.4979, (best 0.7766)
Epoch 44, loss: 0.7564, val mf1: 0.7096, (best 0.7766)
Epoch 45, loss: 1.2293, val mf1: 0.6411, (best 0.7766)
Epoch 46, loss: 0.6680, val mf1: 0.8045, (best 0.8045)
Epoch 47, loss: 1.0912, val mf1: 0.5145, (best 0.8045)
Epoch 48, loss: 0.7857, val mf1: 0.6389, (best 0.8045)
Epoch 49, loss: 0.9881, val mf1: 0.6755, (best 0.8045)
Epoch 50, loss: 0.7240, val mf1: 0.8022, (best 0.8045)
Epoch 51, loss: 0.8272, val mf1: 0.6073, (best 0.8045)
Epoch 52, loss: 0.8326, val mf1: 0.6039, (best 0.8045)
Epoch 53, loss: 0.6077, val mf1: 0.7921, (best 0.8045)
Epoch 54, loss: 0.8297, val mf1: 0.7892, (best 0.8045)
Epoch 55, loss: 0.5743, val mf1: 0.7731, (best 0.8045)
Epoch 56, loss: 0.7547, val mf1: 0.6358, (best 0.8045)
Epoch 57, loss: 0.6397, val mf1: 0.7104, (best 0.8045)
Epoch 58, loss: 0.5750, val mf1: 0.7902, (best 0.8045)
Epoch 59, loss: 0.6663, val mf1: 0.7928, (best 0.8045)
Epoch 60, loss: 0.4806, val mf1: 0.7899, (best 0.8045)
Epoch 61, loss: 0.6538, val mf1: 0.7451, (best 0.8045)
Epoch 62, loss: 0.4704, val mf1: 0.8021, (best 0.8045)
Epoch 63, loss: 0.5969, val mf1: 0.7980, (best 0.8045)
Epoch 64, loss: 0.4397, val mf1: 0.7900, (best 0.8045)
Epoch 65, loss: 0.6358, val mf1: 0.7710, (best 0.8045)
Epoch 66, loss: 0.9531, val mf1: 0.7514, (best 0.8045)
Epoch 67, loss: 0.7218, val mf1: 0.7903, (best 0.8045)
Epoch 68, loss: 0.6010, val mf1: 0.7075, (best 0.8045)
Epoch 69, loss: 0.9581, val mf1: 0.5654, (best 0.8045)
Epoch 70, loss: 0.6077, val mf1: 0.7184, (best 0.8045)
Epoch 71, loss: 0.7025, val mf1: 0.7909, (best 0.8045)
Epoch 72, loss: 0.8007, val mf1: 0.7933, (best 0.8045)
Epoch 73, loss: 0.4995, val mf1: 0.7974, (best 0.8045)
Epoch 74, loss: 0.7336, val mf1: 0.7128, (best 0.8045)
Epoch 75, loss: 0.4791, val mf1: 0.8022, (best 0.8045)
Epoch 76, loss: 0.6833, val mf1: 0.7983, (best 0.8045)
Epoch 77, loss: 0.5159, val mf1: 0.8065, (best 0.8065)
Epoch 78, loss: 0.5000, val mf1: 0.7854, (best 0.8065)
Epoch 79, loss: 0.5385, val mf1: 0.7792, (best 0.8065)
Epoch 80, loss: 0.5230, val mf1: 0.8094, (best 0.8094)
Epoch 81, loss: 0.6594, val mf1: 0.8027, (best 0.8094)
Epoch 82, loss: 0.4494, val mf1: 0.8060, (best 0.8094)
Epoch 83, loss: 0.6291, val mf1: 0.7647, (best 0.8094)
Epoch 84, loss: 0.4609, val mf1: 0.8070, (best 0.8094)
Epoch 85, loss: 0.6057, val mf1: 0.8092, (best 0.8094)
Epoch 86, loss: 0.5147, val mf1: 0.8099, (best 0.8099)
Epoch 87, loss: 0.4644, val mf1: 0.7941, (best 0.8099)
Epoch 88, loss: 0.5896, val mf1: 0.7605, (best 0.8099)
Epoch 89, loss: 0.4586, val mf1: 0.8100, (best 0.8100)
Epoch 90, loss: 0.6023, val mf1: 0.8098, (best 0.8100)
Epoch 91, loss: 0.4702, val mf1: 0.8137, (best 0.8137)
Epoch 92, loss: 0.4915, val mf1: 0.8035, (best 0.8137)
Epoch 93, loss: 0.3992, val mf1: 0.8118, (best 0.8137)
Epoch 94, loss: 0.4352, val mf1: 0.8123, (best 0.8137)
Epoch 95, loss: 0.4143, val mf1: 0.8151, (best 0.8151)
Epoch 96, loss: 0.4069, val mf1: 0.8111, (best 0.8151)
Epoch 97, loss: 0.3850, val mf1: 0.8120, (best 0.8151)
Epoch 98, loss: 0.3986, val mf1: 0.8128, (best 0.8151)
Epoch 99, loss: 0.3829, val mf1: 0.8129, (best 0.8151)
time cost:  16.719800233840942 s
Test: REC 65.24 PRE 57.33 MF1 79.51 AUC 88.39
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=64, normalization=both, activation=None)
    (1-3): 3 x GraphConv(in=64, out=64, normalization=both, activation=None)
    (4): GraphConv(in=64, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 145.8886, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 173.3806, val mf1: 0.0438, (best 0.4883)
Epoch 2, loss: 92.7420, val mf1: 0.0438, (best 0.4883)
Epoch 3, loss: 10.7762, val mf1: 0.5291, (best 0.5291)
Epoch 4, loss: 22.6902, val mf1: 0.4967, (best 0.5291)
Epoch 5, loss: 6.4177, val mf1: 0.5644, (best 0.5644)
Epoch 6, loss: 21.3639, val mf1: 0.0474, (best 0.5644)
Epoch 7, loss: 15.1268, val mf1: 0.0513, (best 0.5644)
Epoch 8, loss: 1.5997, val mf1: 0.7928, (best 0.7928)
Epoch 9, loss: 8.0856, val mf1: 0.5362, (best 0.7928)
Epoch 10, loss: 3.2073, val mf1: 0.6331, (best 0.7928)
Epoch 11, loss: 7.6538, val mf1: 0.0846, (best 0.7928)
Epoch 12, loss: 5.2359, val mf1: 0.1206, (best 0.7928)
Epoch 13, loss: 1.4422, val mf1: 0.7871, (best 0.7928)
Epoch 14, loss: 4.8250, val mf1: 0.5916, (best 0.7928)
Epoch 15, loss: 2.4656, val mf1: 0.7777, (best 0.7928)
Epoch 16, loss: 2.0302, val mf1: 0.4963, (best 0.7928)
Epoch 17, loss: 3.9675, val mf1: 0.3243, (best 0.7928)
Epoch 18, loss: 2.6326, val mf1: 0.4498, (best 0.7928)
Epoch 19, loss: 1.6685, val mf1: 0.7219, (best 0.7928)
Epoch 20, loss: 3.2154, val mf1: 0.7641, (best 0.7928)
Epoch 21, loss: 2.2443, val mf1: 0.7849, (best 0.7928)
Epoch 22, loss: 1.5055, val mf1: 0.5817, (best 0.7928)
Epoch 23, loss: 2.2759, val mf1: 0.4604, (best 0.7928)
Epoch 24, loss: 2.0225, val mf1: 0.4737, (best 0.7928)
Epoch 25, loss: 1.1062, val mf1: 0.6669, (best 0.7928)
Epoch 26, loss: 2.1406, val mf1: 0.7612, (best 0.7928)
Epoch 27, loss: 1.0710, val mf1: 0.7872, (best 0.7928)
Epoch 28, loss: 1.2913, val mf1: 0.5238, (best 0.7928)
Epoch 29, loss: 1.6422, val mf1: 0.4799, (best 0.7928)
Epoch 30, loss: 0.8165, val mf1: 0.7082, (best 0.7928)
Epoch 31, loss: 1.3257, val mf1: 0.7877, (best 0.7928)
Epoch 32, loss: 1.0917, val mf1: 0.7917, (best 0.7928)
Epoch 33, loss: 0.7418, val mf1: 0.6653, (best 0.7928)
Epoch 34, loss: 1.2876, val mf1: 0.4998, (best 0.7928)
Epoch 35, loss: 0.6436, val mf1: 0.7941, (best 0.7941)
Epoch 36, loss: 1.2371, val mf1: 0.7705, (best 0.7941)
Epoch 37, loss: 0.5503, val mf1: 0.7933, (best 0.7941)
Epoch 38, loss: 1.2785, val mf1: 0.5050, (best 0.7941)
Epoch 39, loss: 0.8919, val mf1: 0.7946, (best 0.7946)
Epoch 40, loss: 1.2443, val mf1: 0.7658, (best 0.7946)
Epoch 41, loss: 0.6255, val mf1: 0.7345, (best 0.7946)
Epoch 42, loss: 1.3514, val mf1: 0.4928, (best 0.7946)
Epoch 43, loss: 0.7536, val mf1: 0.7945, (best 0.7946)
Epoch 44, loss: 1.4372, val mf1: 0.7696, (best 0.7946)
Epoch 45, loss: 0.7106, val mf1: 0.7921, (best 0.7946)
Epoch 46, loss: 1.0472, val mf1: 0.5506, (best 0.7946)
Epoch 47, loss: 1.1022, val mf1: 0.5402, (best 0.7946)
Epoch 48, loss: 0.6919, val mf1: 0.7705, (best 0.7946)
Epoch 49, loss: 1.0644, val mf1: 0.7915, (best 0.7946)
Epoch 50, loss: 0.9458, val mf1: 0.7896, (best 0.7946)
Epoch 51, loss: 0.6576, val mf1: 0.7443, (best 0.7946)
Epoch 52, loss: 0.9622, val mf1: 0.5713, (best 0.7946)
Epoch 53, loss: 0.6891, val mf1: 0.6891, (best 0.7946)
Epoch 54, loss: 0.6722, val mf1: 0.7935, (best 0.7946)
Epoch 55, loss: 0.7995, val mf1: 0.7960, (best 0.7960)
Epoch 56, loss: 0.5220, val mf1: 0.7951, (best 0.7960)
Epoch 57, loss: 0.7730, val mf1: 0.6603, (best 0.7960)
Epoch 58, loss: 0.4828, val mf1: 0.7942, (best 0.7960)
Epoch 59, loss: 0.6737, val mf1: 0.7971, (best 0.7971)
Epoch 60, loss: 0.4727, val mf1: 0.8033, (best 0.8033)
Epoch 61, loss: 0.7388, val mf1: 0.7468, (best 0.8033)
Epoch 62, loss: 0.8817, val mf1: 0.7782, (best 0.8033)
Epoch 63, loss: 0.6202, val mf1: 0.7998, (best 0.8033)
Epoch 64, loss: 0.9372, val mf1: 0.6949, (best 0.8033)
Epoch 65, loss: 0.7462, val mf1: 0.7974, (best 0.8033)
Epoch 66, loss: 0.8686, val mf1: 0.7970, (best 0.8033)
Epoch 67, loss: 0.5091, val mf1: 0.7924, (best 0.8033)
Epoch 68, loss: 0.9731, val mf1: 0.5840, (best 0.8033)
Epoch 69, loss: 0.5625, val mf1: 0.7952, (best 0.8033)
Epoch 70, loss: 0.8767, val mf1: 0.7957, (best 0.8033)
Epoch 71, loss: 0.7816, val mf1: 0.7985, (best 0.8033)
Epoch 72, loss: 0.6147, val mf1: 0.7600, (best 0.8033)
Epoch 73, loss: 0.8274, val mf1: 0.6043, (best 0.8033)
Epoch 74, loss: 0.6608, val mf1: 0.7061, (best 0.8033)
Epoch 75, loss: 0.6060, val mf1: 0.7994, (best 0.8033)
Epoch 76, loss: 0.7080, val mf1: 0.8022, (best 0.8033)
Epoch 77, loss: 0.5299, val mf1: 0.8051, (best 0.8051)
Epoch 78, loss: 0.5846, val mf1: 0.7560, (best 0.8051)
Epoch 79, loss: 0.5218, val mf1: 0.7952, (best 0.8051)
Epoch 80, loss: 0.5114, val mf1: 0.8122, (best 0.8122)
Epoch 81, loss: 0.5454, val mf1: 0.8107, (best 0.8122)
Epoch 82, loss: 0.4543, val mf1: 0.8055, (best 0.8122)
Epoch 83, loss: 0.4906, val mf1: 0.8010, (best 0.8122)
Epoch 84, loss: 0.7309, val mf1: 0.8170, (best 0.8170)
Epoch 85, loss: 0.4217, val mf1: 0.8185, (best 0.8185)
Epoch 86, loss: 0.9826, val mf1: 0.5761, (best 0.8185)
Epoch 87, loss: 1.5224, val mf1: 0.6126, (best 0.8185)
Epoch 88, loss: 0.9072, val mf1: 0.8081, (best 0.8185)
Epoch 89, loss: 0.9738, val mf1: 0.6477, (best 0.8185)
Epoch 90, loss: 0.5048, val mf1: 0.7991, (best 0.8185)
Epoch 91, loss: 0.6951, val mf1: 0.8075, (best 0.8185)
Epoch 92, loss: 0.7525, val mf1: 0.8084, (best 0.8185)
Epoch 93, loss: 0.6691, val mf1: 0.7862, (best 0.8185)
Epoch 94, loss: 0.7618, val mf1: 0.6627, (best 0.8185)
Epoch 95, loss: 0.7843, val mf1: 0.6407, (best 0.8185)
Epoch 96, loss: 0.6768, val mf1: 0.7547, (best 0.8185)
Epoch 97, loss: 0.6797, val mf1: 0.8032, (best 0.8185)
Epoch 98, loss: 0.6746, val mf1: 0.8098, (best 0.8185)
Epoch 99, loss: 0.5588, val mf1: 0.8074, (best 0.8185)
time cost:  15.734584331512451 s
Test: REC 58.21 PRE 64.92 MF1 79.81 AUC 87.81
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=64, normalization=both, activation=None)
    (1-3): 3 x GraphConv(in=64, out=64, normalization=both, activation=None)
    (4): GraphConv(in=64, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
Average AUC: 0.5788420480447284, Average Recall: 0.7944179407183413, Average Precision: 0.20295687884703617, Average F1: 0.3107921712603294 in 3 runs, with hid_dim: 64, num_layers: 5
Trying hid_dim: 128, num_layers: 3
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 69.6647, val mf1: 0.0438, (best 0.0438)
Epoch 1, loss: 416.4526, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 435.0373, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 330.6734, val mf1: 0.4967, (best 0.4967)
Epoch 4, loss: 162.0275, val mf1: 0.5291, (best 0.5291)
Epoch 5, loss: 24.6161, val mf1: 0.1993, (best 0.5291)
Epoch 6, loss: 125.2512, val mf1: 0.0442, (best 0.5291)
Epoch 7, loss: 73.6461, val mf1: 0.0520, (best 0.5291)
Epoch 8, loss: 14.7325, val mf1: 0.7259, (best 0.7259)
Epoch 9, loss: 57.5970, val mf1: 0.5289, (best 0.7259)
Epoch 10, loss: 58.9370, val mf1: 0.5289, (best 0.7259)
Epoch 11, loss: 29.3319, val mf1: 0.6876, (best 0.7259)
Epoch 12, loss: 15.7370, val mf1: 0.4800, (best 0.7259)
Epoch 13, loss: 32.9789, val mf1: 0.2970, (best 0.7259)
Epoch 14, loss: 41.5678, val mf1: 0.2422, (best 0.7259)
Epoch 15, loss: 29.4301, val mf1: 0.3391, (best 0.7259)
Epoch 16, loss: 16.6443, val mf1: 0.4731, (best 0.7259)
Epoch 17, loss: 17.3756, val mf1: 0.6562, (best 0.7259)
Epoch 18, loss: 26.7614, val mf1: 0.7593, (best 0.7593)
Epoch 19, loss: 27.7543, val mf1: 0.7588, (best 0.7593)
Epoch 20, loss: 19.6435, val mf1: 0.7480, (best 0.7593)
Epoch 21, loss: 13.1363, val mf1: 0.5525, (best 0.7593)
Epoch 22, loss: 15.6952, val mf1: 0.4531, (best 0.7593)
Epoch 23, loss: 19.9939, val mf1: 0.3958, (best 0.7593)
Epoch 24, loss: 19.4634, val mf1: 0.3870, (best 0.7593)
Epoch 25, loss: 14.1993, val mf1: 0.4408, (best 0.7593)
Epoch 26, loss: 10.1281, val mf1: 0.5259, (best 0.7593)
Epoch 27, loss: 11.6979, val mf1: 0.6986, (best 0.7593)
Epoch 28, loss: 14.2453, val mf1: 0.7756, (best 0.7756)
Epoch 29, loss: 12.0459, val mf1: 0.7574, (best 0.7756)
Epoch 30, loss: 8.0286, val mf1: 0.5831, (best 0.7756)
Epoch 31, loss: 8.6957, val mf1: 0.4643, (best 0.7756)
Epoch 32, loss: 10.7280, val mf1: 0.4125, (best 0.7756)
Epoch 33, loss: 9.1809, val mf1: 0.4292, (best 0.7756)
Epoch 34, loss: 6.1331, val mf1: 0.5134, (best 0.7756)
Epoch 35, loss: 6.9727, val mf1: 0.7251, (best 0.7756)
Epoch 36, loss: 8.0975, val mf1: 0.7896, (best 0.7896)
Epoch 37, loss: 5.6392, val mf1: 0.7107, (best 0.7896)
Epoch 38, loss: 4.8395, val mf1: 0.4893, (best 0.7896)
Epoch 39, loss: 6.4525, val mf1: 0.4158, (best 0.7896)
Epoch 40, loss: 4.5443, val mf1: 0.4663, (best 0.7896)
Epoch 41, loss: 3.7730, val mf1: 0.7349, (best 0.7896)
Epoch 42, loss: 4.8891, val mf1: 0.8160, (best 0.8160)
Epoch 43, loss: 2.9236, val mf1: 0.7493, (best 0.8160)
Epoch 44, loss: 3.7713, val mf1: 0.4283, (best 0.8160)
Epoch 45, loss: 2.8260, val mf1: 0.4603, (best 0.8160)
Epoch 46, loss: 2.9012, val mf1: 0.8331, (best 0.8331)
Epoch 47, loss: 3.1314, val mf1: 0.8359, (best 0.8359)
Epoch 48, loss: 1.1795, val mf1: 0.6019, (best 0.8359)
Epoch 49, loss: 3.0643, val mf1: 0.3028, (best 0.8359)
Epoch 50, loss: 10.2339, val mf1: 0.6483, (best 0.8359)
Epoch 51, loss: 10.2386, val mf1: 0.6810, (best 0.8359)
Epoch 52, loss: 0.8423, val mf1: 0.8138, (best 0.8359)
Epoch 53, loss: 25.7179, val mf1: 0.0453, (best 0.8359)
Epoch 54, loss: 6.0682, val mf1: 0.1061, (best 0.8359)
Epoch 55, loss: 18.8401, val mf1: 0.6503, (best 0.8359)
Epoch 56, loss: 32.6254, val mf1: 0.5429, (best 0.8359)
Epoch 57, loss: 25.0472, val mf1: 0.6962, (best 0.8359)
Epoch 58, loss: 10.4080, val mf1: 0.8321, (best 0.8359)
Epoch 59, loss: 10.4497, val mf1: 0.4077, (best 0.8359)
Epoch 60, loss: 23.2673, val mf1: 0.2134, (best 0.8359)
Epoch 61, loss: 14.9238, val mf1: 0.3153, (best 0.8359)
Epoch 62, loss: 6.8863, val mf1: 0.5605, (best 0.8359)
Epoch 63, loss: 10.4513, val mf1: 0.8198, (best 0.8359)
Epoch 64, loss: 14.0615, val mf1: 0.8389, (best 0.8389)
Epoch 65, loss: 13.5015, val mf1: 0.8400, (best 0.8400)
Epoch 66, loss: 9.3186, val mf1: 0.8287, (best 0.8400)
Epoch 67, loss: 4.9007, val mf1: 0.6449, (best 0.8400)
Epoch 68, loss: 7.3567, val mf1: 0.4074, (best 0.8400)
Epoch 69, loss: 10.8109, val mf1: 0.2331, (best 0.8400)
Epoch 70, loss: 3.8642, val mf1: 0.5244, (best 0.8400)
Epoch 71, loss: 5.4381, val mf1: 0.8334, (best 0.8400)
Epoch 72, loss: 7.6028, val mf1: 0.8480, (best 0.8480)
Epoch 73, loss: 7.1194, val mf1: 0.8508, (best 0.8508)
Epoch 74, loss: 4.1884, val mf1: 0.8350, (best 0.8508)
Epoch 75, loss: 2.3984, val mf1: 0.4985, (best 0.8508)
Epoch 76, loss: 7.7349, val mf1: 0.1079, (best 0.8508)
Epoch 77, loss: 3.7829, val mf1: 0.8394, (best 0.8508)
Epoch 78, loss: 8.4654, val mf1: 0.8446, (best 0.8508)
Epoch 79, loss: 9.4460, val mf1: 0.8410, (best 0.8508)
Epoch 80, loss: 5.7896, val mf1: 0.8516, (best 0.8516)
Epoch 81, loss: 1.5620, val mf1: 0.7166, (best 0.8516)
Epoch 82, loss: 12.4652, val mf1: 0.0654, (best 0.8516)
Epoch 83, loss: 1.5770, val mf1: 0.6819, (best 0.8516)
Epoch 84, loss: 4.7362, val mf1: 0.8490, (best 0.8516)
Epoch 85, loss: 6.4867, val mf1: 0.8501, (best 0.8516)
Epoch 86, loss: 5.0725, val mf1: 0.8514, (best 0.8516)
Epoch 87, loss: 2.0222, val mf1: 0.8224, (best 0.8516)
Epoch 88, loss: 6.8365, val mf1: 0.1306, (best 0.8516)
Epoch 89, loss: 2.1057, val mf1: 0.8246, (best 0.8516)
Epoch 90, loss: 4.4420, val mf1: 0.8479, (best 0.8516)
Epoch 91, loss: 4.7731, val mf1: 0.8477, (best 0.8516)
Epoch 92, loss: 3.0351, val mf1: 0.8371, (best 0.8516)
Epoch 93, loss: 2.2289, val mf1: 0.5001, (best 0.8516)
Epoch 94, loss: 4.2557, val mf1: 0.3416, (best 0.8516)
Epoch 95, loss: 1.8685, val mf1: 0.8125, (best 0.8516)
Epoch 96, loss: 3.2809, val mf1: 0.8390, (best 0.8516)
Epoch 97, loss: 3.0603, val mf1: 0.8391, (best 0.8516)
Epoch 98, loss: 1.5240, val mf1: 0.8037, (best 0.8516)
Epoch 99, loss: 3.7223, val mf1: 0.3335, (best 0.8516)
time cost:  14.898657321929932 s
Test: REC 61.79 PRE 78.05 MF1 83.82 AUC 88.34
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=128, normalization=both, activation=None)
    (1): GraphConv(in=128, out=128, normalization=both, activation=None)
    (2): GraphConv(in=128, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 26.4148, val mf1: 0.4876, (best 0.4876)
Epoch 1, loss: 657.4265, val mf1: 0.0438, (best 0.4876)
Epoch 2, loss: 451.6037, val mf1: 0.0438, (best 0.4876)
Epoch 3, loss: 83.7224, val mf1: 0.0438, (best 0.4876)
Epoch 4, loss: 185.9598, val mf1: 0.4967, (best 0.4967)
Epoch 5, loss: 299.2061, val mf1: 0.4967, (best 0.4967)
Epoch 6, loss: 323.5257, val mf1: 0.4967, (best 0.4967)
Epoch 7, loss: 293.3789, val mf1: 0.4967, (best 0.4967)
Epoch 8, loss: 225.8915, val mf1: 0.5291, (best 0.5291)
Epoch 9, loss: 132.5533, val mf1: 0.5289, (best 0.5291)
Epoch 10, loss: 25.1541, val mf1: 0.7632, (best 0.7632)
Epoch 11, loss: 74.3493, val mf1: 0.0534, (best 0.7632)
Epoch 12, loss: 125.7183, val mf1: 0.0449, (best 0.7632)
Epoch 13, loss: 102.1227, val mf1: 0.0481, (best 0.7632)
Epoch 14, loss: 36.0411, val mf1: 0.2237, (best 0.7632)
Epoch 15, loss: 13.6425, val mf1: 0.5623, (best 0.7632)
Epoch 16, loss: 37.2312, val mf1: 0.6502, (best 0.7632)
Epoch 17, loss: 55.1813, val mf1: 0.5310, (best 0.7632)
Epoch 18, loss: 53.6548, val mf1: 0.5361, (best 0.7632)
Epoch 19, loss: 37.8185, val mf1: 0.7036, (best 0.7632)
Epoch 20, loss: 21.4148, val mf1: 0.7240, (best 0.7632)
Epoch 21, loss: 16.6482, val mf1: 0.5150, (best 0.7632)
Epoch 22, loss: 23.2558, val mf1: 0.4292, (best 0.7632)
Epoch 23, loss: 31.0598, val mf1: 0.3480, (best 0.7632)
Epoch 24, loss: 33.2519, val mf1: 0.3119, (best 0.7632)
Epoch 25, loss: 27.8557, val mf1: 0.3659, (best 0.7632)
Epoch 26, loss: 20.4318, val mf1: 0.4328, (best 0.7632)
Epoch 27, loss: 14.8781, val mf1: 0.4914, (best 0.7632)
Epoch 28, loss: 13.7263, val mf1: 0.5861, (best 0.7632)
Epoch 29, loss: 16.7690, val mf1: 0.7213, (best 0.7632)
Epoch 30, loss: 18.7644, val mf1: 0.7699, (best 0.7699)
Epoch 31, loss: 17.3474, val mf1: 0.7693, (best 0.7699)
Epoch 32, loss: 13.3420, val mf1: 0.7187, (best 0.7699)
Epoch 33, loss: 9.8106, val mf1: 0.5866, (best 0.7699)
Epoch 34, loss: 9.4961, val mf1: 0.4954, (best 0.7699)
Epoch 35, loss: 11.0760, val mf1: 0.4469, (best 0.7699)
Epoch 36, loss: 12.1373, val mf1: 0.4168, (best 0.7699)
Epoch 37, loss: 11.4854, val mf1: 0.4173, (best 0.7699)
Epoch 38, loss: 9.3348, val mf1: 0.4493, (best 0.7699)
Epoch 39, loss: 7.1982, val mf1: 0.4989, (best 0.7699)
Epoch 40, loss: 6.6753, val mf1: 0.5935, (best 0.7699)
Epoch 41, loss: 8.1290, val mf1: 0.7234, (best 0.7699)
Epoch 42, loss: 8.1412, val mf1: 0.7638, (best 0.7699)
Epoch 43, loss: 6.7766, val mf1: 0.7253, (best 0.7699)
Epoch 44, loss: 5.0225, val mf1: 0.6010, (best 0.7699)
Epoch 45, loss: 4.8791, val mf1: 0.4950, (best 0.7699)
Epoch 46, loss: 5.7215, val mf1: 0.4430, (best 0.7699)
Epoch 47, loss: 5.5890, val mf1: 0.4319, (best 0.7699)
Epoch 48, loss: 4.0905, val mf1: 0.4829, (best 0.7699)
Epoch 49, loss: 3.2638, val mf1: 0.6170, (best 0.7699)
Epoch 50, loss: 4.0736, val mf1: 0.8024, (best 0.8024)
Epoch 51, loss: 4.0018, val mf1: 0.8196, (best 0.8196)
Epoch 52, loss: 2.5929, val mf1: 0.7266, (best 0.8196)
Epoch 53, loss: 2.5871, val mf1: 0.4944, (best 0.8196)
Epoch 54, loss: 3.3306, val mf1: 0.4199, (best 0.8196)
Epoch 55, loss: 1.8125, val mf1: 0.5472, (best 0.8196)
Epoch 56, loss: 2.3400, val mf1: 0.8467, (best 0.8467)
Epoch 57, loss: 2.4638, val mf1: 0.8473, (best 0.8473)
Epoch 58, loss: 1.1847, val mf1: 0.7889, (best 0.8473)
Epoch 59, loss: 2.5296, val mf1: 0.3703, (best 0.8473)
Epoch 60, loss: 0.8658, val mf1: 0.7916, (best 0.8473)
Epoch 61, loss: 1.6116, val mf1: 0.8457, (best 0.8473)
Epoch 62, loss: 1.1616, val mf1: 0.8447, (best 0.8473)
Epoch 63, loss: 1.5997, val mf1: 0.4335, (best 0.8473)
Epoch 64, loss: 3.4242, val mf1: 0.7953, (best 0.8473)
Epoch 65, loss: 4.5004, val mf1: 0.7640, (best 0.8473)
Epoch 66, loss: 1.0080, val mf1: 0.8392, (best 0.8473)
Epoch 67, loss: 9.3256, val mf1: 0.0951, (best 0.8473)
Epoch 68, loss: 0.5827, val mf1: 0.8016, (best 0.8473)
Epoch 69, loss: 2.4336, val mf1: 0.8355, (best 0.8473)
Epoch 70, loss: 2.4129, val mf1: 0.8409, (best 0.8473)
Epoch 71, loss: 0.8266, val mf1: 0.8053, (best 0.8473)
Epoch 72, loss: 5.8830, val mf1: 0.1426, (best 0.8473)
Epoch 73, loss: 2.0253, val mf1: 0.8436, (best 0.8473)
Epoch 74, loss: 4.4556, val mf1: 0.8276, (best 0.8473)
Epoch 75, loss: 3.8295, val mf1: 0.8357, (best 0.8473)
Epoch 76, loss: 1.4835, val mf1: 0.8133, (best 0.8473)
Epoch 77, loss: 5.3298, val mf1: 0.1657, (best 0.8473)
Epoch 78, loss: 1.4943, val mf1: 0.8005, (best 0.8473)
Epoch 79, loss: 3.1694, val mf1: 0.8438, (best 0.8473)
Epoch 80, loss: 3.3323, val mf1: 0.8440, (best 0.8473)
Epoch 81, loss: 1.9366, val mf1: 0.8249, (best 0.8473)
Epoch 82, loss: 2.0032, val mf1: 0.4623, (best 0.8473)
Epoch 83, loss: 2.2898, val mf1: 0.4185, (best 0.8473)
Epoch 84, loss: 1.5885, val mf1: 0.8249, (best 0.8473)
Epoch 85, loss: 2.3883, val mf1: 0.8406, (best 0.8473)
Epoch 86, loss: 1.8583, val mf1: 0.8370, (best 0.8473)
Epoch 87, loss: 1.0510, val mf1: 0.6292, (best 0.8473)
Epoch 88, loss: 2.2757, val mf1: 0.3844, (best 0.8473)
Epoch 89, loss: 1.2858, val mf1: 0.8310, (best 0.8473)
Epoch 90, loss: 2.0298, val mf1: 0.8453, (best 0.8473)
Epoch 91, loss: 1.4057, val mf1: 0.8418, (best 0.8473)
Epoch 92, loss: 1.2300, val mf1: 0.5147, (best 0.8473)
Epoch 93, loss: 0.7347, val mf1: 0.7459, (best 0.8473)
Epoch 94, loss: 1.0295, val mf1: 0.8401, (best 0.8473)
Epoch 95, loss: 0.8268, val mf1: 0.8300, (best 0.8473)
Epoch 96, loss: 1.1247, val mf1: 0.5368, (best 0.8473)
Epoch 97, loss: 2.1650, val mf1: 0.8426, (best 0.8473)
Epoch 98, loss: 2.9967, val mf1: 0.8289, (best 0.8473)
Epoch 99, loss: 1.1305, val mf1: 0.8476, (best 0.8476)
time cost:  15.982110738754272 s
Test: REC 61.93 PRE 78.36 MF1 83.93 AUC 89.99
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=128, normalization=both, activation=None)
    (1): GraphConv(in=128, out=128, normalization=both, activation=None)
    (2): GraphConv(in=128, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 38.1907, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 845.9824, val mf1: 0.0438, (best 0.4883)
Epoch 2, loss: 544.2350, val mf1: 0.0438, (best 0.4883)
Epoch 3, loss: 137.4121, val mf1: 0.0438, (best 0.4883)
Epoch 4, loss: 181.7916, val mf1: 0.4967, (best 0.4967)
Epoch 5, loss: 311.6384, val mf1: 0.4967, (best 0.4967)
Epoch 6, loss: 339.8793, val mf1: 0.4967, (best 0.4967)
Epoch 7, loss: 308.3934, val mf1: 0.4967, (best 0.4967)
Epoch 8, loss: 236.8775, val mf1: 0.5291, (best 0.5291)
Epoch 9, loss: 140.0077, val mf1: 0.5291, (best 0.5291)
Epoch 10, loss: 27.7476, val mf1: 0.7441, (best 0.7441)
Epoch 11, loss: 83.4052, val mf1: 0.0519, (best 0.7441)
Epoch 12, loss: 146.6499, val mf1: 0.0446, (best 0.7441)
Epoch 13, loss: 130.3003, val mf1: 0.0465, (best 0.7441)
Epoch 14, loss: 59.4481, val mf1: 0.0625, (best 0.7441)
Epoch 15, loss: 13.2485, val mf1: 0.5201, (best 0.7441)
Epoch 16, loss: 44.9127, val mf1: 0.5413, (best 0.7441)
Epoch 17, loss: 71.9986, val mf1: 0.5289, (best 0.7441)
Epoch 18, loss: 78.4294, val mf1: 0.5289, (best 0.7441)
Epoch 19, loss: 67.9189, val mf1: 0.5289, (best 0.7441)
Epoch 20, loss: 42.8802, val mf1: 0.6151, (best 0.7441)
Epoch 21, loss: 18.9431, val mf1: 0.7048, (best 0.7441)
Epoch 22, loss: 18.2270, val mf1: 0.4629, (best 0.7441)
Epoch 23, loss: 30.4202, val mf1: 0.3344, (best 0.7441)
Epoch 24, loss: 41.0090, val mf1: 0.2404, (best 0.7441)
Epoch 25, loss: 41.7481, val mf1: 0.2299, (best 0.7441)
Epoch 26, loss: 32.3710, val mf1: 0.2866, (best 0.7441)
Epoch 27, loss: 20.6020, val mf1: 0.4183, (best 0.7441)
Epoch 28, loss: 14.1449, val mf1: 0.4991, (best 0.7441)
Epoch 29, loss: 14.6287, val mf1: 0.6482, (best 0.7441)
Epoch 30, loss: 20.9277, val mf1: 0.7920, (best 0.7920)
Epoch 31, loss: 24.3028, val mf1: 0.7888, (best 0.7920)
Epoch 32, loss: 23.5427, val mf1: 0.7902, (best 0.7920)
Epoch 33, loss: 19.1186, val mf1: 0.7897, (best 0.7920)
Epoch 34, loss: 13.4434, val mf1: 0.6864, (best 0.7920)
Epoch 35, loss: 11.2332, val mf1: 0.5321, (best 0.7920)
Epoch 36, loss: 12.6635, val mf1: 0.4654, (best 0.7920)
Epoch 37, loss: 14.9271, val mf1: 0.4243, (best 0.7920)
Epoch 38, loss: 15.9820, val mf1: 0.3974, (best 0.7920)
Epoch 39, loss: 14.7369, val mf1: 0.4044, (best 0.7920)
Epoch 40, loss: 11.8885, val mf1: 0.4421, (best 0.7920)
Epoch 41, loss: 9.1917, val mf1: 0.4913, (best 0.7920)
Epoch 42, loss: 8.3375, val mf1: 0.5721, (best 0.7920)
Epoch 43, loss: 9.5627, val mf1: 0.7104, (best 0.7920)
Epoch 44, loss: 10.7746, val mf1: 0.7748, (best 0.7920)
Epoch 45, loss: 10.1152, val mf1: 0.7719, (best 0.7920)
Epoch 46, loss: 7.9095, val mf1: 0.7074, (best 0.7920)
Epoch 47, loss: 6.2807, val mf1: 0.5625, (best 0.7920)
Epoch 48, loss: 6.5309, val mf1: 0.4843, (best 0.7920)
Epoch 49, loss: 7.5108, val mf1: 0.4417, (best 0.7920)
Epoch 50, loss: 7.4746, val mf1: 0.4315, (best 0.7920)
Epoch 51, loss: 6.0347, val mf1: 0.4631, (best 0.7920)
Epoch 52, loss: 4.6386, val mf1: 0.5317, (best 0.7920)
Epoch 53, loss: 4.7841, val mf1: 0.6964, (best 0.7920)
Epoch 54, loss: 5.5801, val mf1: 0.7949, (best 0.7949)
Epoch 55, loss: 5.0518, val mf1: 0.7916, (best 0.7949)
Epoch 56, loss: 3.6406, val mf1: 0.6553, (best 0.7949)
Epoch 57, loss: 3.4789, val mf1: 0.5083, (best 0.7949)
Epoch 58, loss: 4.1652, val mf1: 0.4506, (best 0.7949)
Epoch 59, loss: 3.6518, val mf1: 0.4627, (best 0.7949)
Epoch 60, loss: 2.3556, val mf1: 0.5733, (best 0.7949)
Epoch 61, loss: 7.6419, val mf1: 0.5503, (best 0.7949)
Epoch 62, loss: 2.1395, val mf1: 0.5299, (best 0.7949)
Epoch 63, loss: 3.3390, val mf1: 0.4187, (best 0.7949)
Epoch 64, loss: 2.0252, val mf1: 0.5155, (best 0.7949)
Epoch 65, loss: 1.9987, val mf1: 0.8203, (best 0.8203)
Epoch 66, loss: 2.4510, val mf1: 0.8462, (best 0.8462)
Epoch 67, loss: 1.6094, val mf1: 0.8259, (best 0.8462)
Epoch 68, loss: 1.6291, val mf1: 0.4975, (best 0.8462)
Epoch 69, loss: 1.3733, val mf1: 0.5202, (best 0.8462)
Epoch 70, loss: 1.4585, val mf1: 0.8405, (best 0.8462)
Epoch 71, loss: 1.7599, val mf1: 0.8464, (best 0.8464)
Epoch 72, loss: 0.7963, val mf1: 0.8210, (best 0.8464)
Epoch 73, loss: 4.2491, val mf1: 0.1779, (best 0.8464)
Epoch 74, loss: 3.1652, val mf1: 0.8284, (best 0.8464)
Epoch 75, loss: 6.1000, val mf1: 0.7662, (best 0.8464)
Epoch 76, loss: 3.3288, val mf1: 0.8303, (best 0.8464)
Epoch 77, loss: 0.9211, val mf1: 0.6488, (best 0.8464)
Epoch 78, loss: 0.7360, val mf1: 0.7032, (best 0.8464)
Epoch 79, loss: 1.1339, val mf1: 0.8233, (best 0.8464)
Epoch 80, loss: 1.1585, val mf1: 0.8214, (best 0.8464)
Epoch 81, loss: 0.7270, val mf1: 0.7328, (best 0.8464)
Epoch 82, loss: 1.6095, val mf1: 0.4640, (best 0.8464)
Epoch 83, loss: 4.0690, val mf1: 0.8348, (best 0.8464)
Epoch 84, loss: 7.2519, val mf1: 0.7980, (best 0.8464)
Epoch 85, loss: 5.4016, val mf1: 0.8320, (best 0.8464)
Epoch 86, loss: 1.9202, val mf1: 0.8224, (best 0.8464)
Epoch 87, loss: 7.0152, val mf1: 0.1170, (best 0.8464)
Epoch 88, loss: 1.4591, val mf1: 0.6211, (best 0.8464)
Epoch 89, loss: 2.9105, val mf1: 0.8275, (best 0.8464)
Epoch 90, loss: 3.8127, val mf1: 0.8391, (best 0.8464)
Epoch 91, loss: 3.0870, val mf1: 0.8301, (best 0.8464)
Epoch 92, loss: 1.5533, val mf1: 0.7409, (best 0.8464)
Epoch 93, loss: 3.3655, val mf1: 0.3387, (best 0.8464)
Epoch 94, loss: 1.4081, val mf1: 0.5899, (best 0.8464)
Epoch 95, loss: 1.9604, val mf1: 0.8251, (best 0.8464)
Epoch 96, loss: 2.2351, val mf1: 0.8317, (best 0.8464)
Epoch 97, loss: 1.3877, val mf1: 0.8208, (best 0.8464)
Epoch 98, loss: 1.6461, val mf1: 0.4696, (best 0.8464)
Epoch 99, loss: 0.8196, val mf1: 0.7889, (best 0.8464)
time cost:  15.961332082748413 s
Test: REC 60.69 PRE 78.15 MF1 83.49 AUC 88.93
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=128, normalization=both, activation=None)
    (1): GraphConv(in=128, out=128, normalization=both, activation=None)
    (2): GraphConv(in=128, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
Average AUC: 0.700732547357266, Average Recall: 0.7386340734785608, Average Precision: 0.2772495351344169, Average F1: 0.3661338289294 in 3 runs, with hid_dim: 128, num_layers: 3
Trying hid_dim: 128, num_layers: 4
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 68.0793, val mf1: 0.0452, (best 0.0452)
Epoch 1, loss: 569.7411, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 437.8421, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 155.7804, val mf1: 0.4967, (best 0.4967)
Epoch 4, loss: 220.4779, val mf1: 0.0438, (best 0.4967)
Epoch 5, loss: 238.5116, val mf1: 0.0438, (best 0.4967)
Epoch 6, loss: 104.4865, val mf1: 0.0438, (best 0.4967)
Epoch 7, loss: 61.4549, val mf1: 0.5291, (best 0.5291)
Epoch 8, loss: 107.5214, val mf1: 0.4967, (best 0.5291)
Epoch 9, loss: 100.5732, val mf1: 0.4967, (best 0.5291)
Epoch 10, loss: 64.8947, val mf1: 0.5291, (best 0.5291)
Epoch 11, loss: 14.4071, val mf1: 0.5338, (best 0.5338)
Epoch 12, loss: 49.8548, val mf1: 0.0444, (best 0.5338)
Epoch 13, loss: 72.2179, val mf1: 0.0438, (best 0.5338)
Epoch 14, loss: 50.2921, val mf1: 0.0442, (best 0.5338)
Epoch 15, loss: 5.9053, val mf1: 0.3869, (best 0.5338)
Epoch 16, loss: 21.2574, val mf1: 0.5289, (best 0.5338)
Epoch 17, loss: 36.2993, val mf1: 0.5289, (best 0.5338)
Epoch 18, loss: 36.9783, val mf1: 0.5289, (best 0.5338)
Epoch 19, loss: 26.1356, val mf1: 0.5289, (best 0.5338)
Epoch 20, loss: 8.3958, val mf1: 0.7956, (best 0.7956)
Epoch 21, loss: 9.5831, val mf1: 0.3906, (best 0.7956)
Epoch 22, loss: 17.0627, val mf1: 0.2149, (best 0.7956)
Epoch 23, loss: 15.3199, val mf1: 0.2217, (best 0.7956)
Epoch 24, loss: 10.7308, val mf1: 0.3034, (best 0.7956)
Epoch 25, loss: 6.1511, val mf1: 0.4546, (best 0.7956)
Epoch 26, loss: 4.5856, val mf1: 0.5856, (best 0.7956)
Epoch 27, loss: 6.5222, val mf1: 0.7801, (best 0.7956)
Epoch 28, loss: 8.6080, val mf1: 0.7692, (best 0.7956)
Epoch 29, loss: 8.0612, val mf1: 0.7721, (best 0.7956)
Epoch 30, loss: 5.4400, val mf1: 0.7822, (best 0.7956)
Epoch 31, loss: 3.7101, val mf1: 0.5890, (best 0.7956)
Epoch 32, loss: 3.9347, val mf1: 0.4852, (best 0.7956)
Epoch 33, loss: 4.7548, val mf1: 0.4314, (best 0.7956)
Epoch 34, loss: 5.1161, val mf1: 0.4045, (best 0.7956)
Epoch 35, loss: 4.4502, val mf1: 0.4241, (best 0.7956)
Epoch 36, loss: 3.2798, val mf1: 0.4768, (best 0.7956)
Epoch 37, loss: 2.5364, val mf1: 0.5638, (best 0.7956)
Epoch 38, loss: 2.7087, val mf1: 0.7343, (best 0.7956)
Epoch 39, loss: 3.3201, val mf1: 0.7816, (best 0.7956)
Epoch 40, loss: 3.3059, val mf1: 0.7837, (best 0.7956)
Epoch 41, loss: 2.5769, val mf1: 0.7711, (best 0.7956)
Epoch 42, loss: 1.9289, val mf1: 0.6474, (best 0.7956)
Epoch 43, loss: 1.9650, val mf1: 0.5273, (best 0.7956)
Epoch 44, loss: 2.2688, val mf1: 0.4776, (best 0.7956)
Epoch 45, loss: 2.2379, val mf1: 0.4678, (best 0.7956)
Epoch 46, loss: 1.7344, val mf1: 0.5061, (best 0.7956)
Epoch 47, loss: 1.2731, val mf1: 0.6214, (best 0.7956)
Epoch 48, loss: 1.4218, val mf1: 0.8127, (best 0.8127)
Epoch 49, loss: 1.4265, val mf1: 0.8038, (best 0.8127)
Epoch 50, loss: 1.1631, val mf1: 0.8008, (best 0.8127)
Epoch 51, loss: 0.8569, val mf1: 0.7520, (best 0.8127)
Epoch 52, loss: 0.9241, val mf1: 0.5901, (best 0.8127)
Epoch 53, loss: 1.0082, val mf1: 0.5510, (best 0.8127)
Epoch 54, loss: 0.6410, val mf1: 0.7499, (best 0.8127)
Epoch 55, loss: 0.6519, val mf1: 0.8180, (best 0.8180)
Epoch 56, loss: 0.7637, val mf1: 0.8197, (best 0.8197)
Epoch 57, loss: 0.4969, val mf1: 0.8224, (best 0.8224)
Epoch 58, loss: 0.6863, val mf1: 0.8072, (best 0.8224)
Epoch 59, loss: 0.4429, val mf1: 0.8347, (best 0.8347)
Epoch 60, loss: 0.6045, val mf1: 0.8378, (best 0.8378)
Epoch 61, loss: 0.3981, val mf1: 0.8433, (best 0.8433)
Epoch 62, loss: 0.8837, val mf1: 0.5661, (best 0.8433)
Epoch 63, loss: 1.1674, val mf1: 0.6714, (best 0.8433)
Epoch 64, loss: 1.1127, val mf1: 0.7118, (best 0.8433)
Epoch 65, loss: 0.4653, val mf1: 0.8251, (best 0.8433)
Epoch 66, loss: 0.9739, val mf1: 0.6859, (best 0.8433)
Epoch 67, loss: 0.9351, val mf1: 0.8328, (best 0.8433)
Epoch 68, loss: 1.4384, val mf1: 0.7983, (best 0.8433)
Epoch 69, loss: 0.7603, val mf1: 0.8445, (best 0.8445)
Epoch 70, loss: 0.7218, val mf1: 0.7267, (best 0.8445)
Epoch 71, loss: 1.0993, val mf1: 0.5393, (best 0.8445)
Epoch 72, loss: 0.5804, val mf1: 0.8193, (best 0.8445)
Epoch 73, loss: 0.7457, val mf1: 0.8316, (best 0.8445)
Epoch 74, loss: 0.8866, val mf1: 0.8393, (best 0.8445)
Epoch 75, loss: 0.7271, val mf1: 0.8322, (best 0.8445)
Epoch 76, loss: 0.5468, val mf1: 0.8242, (best 0.8445)
Epoch 77, loss: 0.7384, val mf1: 0.6757, (best 0.8445)
Epoch 78, loss: 0.7123, val mf1: 0.6957, (best 0.8445)
Epoch 79, loss: 0.5366, val mf1: 0.8223, (best 0.8445)
Epoch 80, loss: 0.6179, val mf1: 0.8304, (best 0.8445)
Epoch 81, loss: 0.6663, val mf1: 0.8335, (best 0.8445)
Epoch 82, loss: 0.5518, val mf1: 0.8321, (best 0.8445)
Epoch 83, loss: 0.4694, val mf1: 0.8225, (best 0.8445)
Epoch 84, loss: 0.5806, val mf1: 0.8090, (best 0.8445)
Epoch 85, loss: 0.4431, val mf1: 0.8258, (best 0.8445)
Epoch 86, loss: 0.4628, val mf1: 0.8357, (best 0.8445)
Epoch 87, loss: 0.4997, val mf1: 0.8461, (best 0.8461)
Epoch 88, loss: 0.4051, val mf1: 0.8411, (best 0.8461)
Epoch 89, loss: 0.4490, val mf1: 0.8298, (best 0.8461)
Epoch 90, loss: 0.3692, val mf1: 0.8405, (best 0.8461)
Epoch 91, loss: 0.4017, val mf1: 0.8504, (best 0.8504)
Epoch 92, loss: 0.3851, val mf1: 0.8504, (best 0.8504)
Epoch 93, loss: 0.3933, val mf1: 0.8447, (best 0.8504)
Epoch 94, loss: 0.3673, val mf1: 0.8508, (best 0.8508)
Epoch 95, loss: 0.3768, val mf1: 0.8547, (best 0.8547)
Epoch 96, loss: 0.3740, val mf1: 0.8480, (best 0.8547)
Epoch 97, loss: 0.3635, val mf1: 0.8522, (best 0.8547)
Epoch 98, loss: 0.3651, val mf1: 0.8511, (best 0.8547)
Epoch 99, loss: 0.3662, val mf1: 0.8431, (best 0.8547)
time cost:  18.066783905029297 s
Test: REC 60.83 PRE 79.75 MF1 83.86 AUC 89.32
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=128, normalization=both, activation=None)
    (1-2): 2 x GraphConv(in=128, out=128, normalization=both, activation=None)
    (3): GraphConv(in=128, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 179.6233, val mf1: 0.4883, (best 0.4883)
Epoch 1, loss: 450.0742, val mf1: 0.0438, (best 0.4883)
Epoch 2, loss: 241.7295, val mf1: 0.0438, (best 0.4883)
Epoch 3, loss: 2.9361, val mf1: 0.6918, (best 0.6918)
Epoch 4, loss: 94.9081, val mf1: 0.4967, (best 0.6918)
Epoch 5, loss: 74.7299, val mf1: 0.4967, (best 0.6918)
Epoch 6, loss: 7.2202, val mf1: 0.7771, (best 0.7771)
Epoch 7, loss: 76.9079, val mf1: 0.0438, (best 0.7771)
Epoch 8, loss: 63.5952, val mf1: 0.0438, (best 0.7771)
Epoch 9, loss: 8.2257, val mf1: 0.2916, (best 0.7771)
Epoch 10, loss: 28.7726, val mf1: 0.5291, (best 0.7771)
Epoch 11, loss: 42.9836, val mf1: 0.5291, (best 0.7771)
Epoch 12, loss: 35.2354, val mf1: 0.5291, (best 0.7771)
Epoch 13, loss: 16.1725, val mf1: 0.5285, (best 0.7771)
Epoch 14, loss: 4.7700, val mf1: 0.4182, (best 0.7771)
Epoch 15, loss: 20.4537, val mf1: 0.0526, (best 0.7771)
Epoch 16, loss: 19.1821, val mf1: 0.0553, (best 0.7771)
Epoch 17, loss: 6.8982, val mf1: 0.3223, (best 0.7771)
Epoch 18, loss: 4.0137, val mf1: 0.7103, (best 0.7771)
Epoch 19, loss: 11.1767, val mf1: 0.5389, (best 0.7771)
Epoch 20, loss: 12.5865, val mf1: 0.5295, (best 0.7771)
Epoch 21, loss: 8.0013, val mf1: 0.6631, (best 0.7771)
Epoch 22, loss: 3.3222, val mf1: 0.6902, (best 0.7771)
Epoch 23, loss: 3.6745, val mf1: 0.4730, (best 0.7771)
Epoch 24, loss: 5.9477, val mf1: 0.3541, (best 0.7771)
Epoch 25, loss: 7.2472, val mf1: 0.2658, (best 0.7771)
Epoch 26, loss: 6.0354, val mf1: 0.3102, (best 0.7771)
Epoch 27, loss: 3.3544, val mf1: 0.4542, (best 0.7771)
Epoch 28, loss: 2.1991, val mf1: 0.5966, (best 0.7771)
Epoch 29, loss: 3.2959, val mf1: 0.7636, (best 0.7771)
Epoch 30, loss: 3.8188, val mf1: 0.7498, (best 0.7771)
Epoch 31, loss: 2.4811, val mf1: 0.7629, (best 0.7771)
Epoch 32, loss: 1.5576, val mf1: 0.6209, (best 0.7771)
Epoch 33, loss: 1.8630, val mf1: 0.4894, (best 0.7771)
Epoch 34, loss: 2.0296, val mf1: 0.4589, (best 0.7771)
Epoch 35, loss: 1.2465, val mf1: 0.5971, (best 0.7771)
Epoch 36, loss: 0.9471, val mf1: 0.6633, (best 0.7771)
Epoch 37, loss: 0.9050, val mf1: 0.7634, (best 0.7771)
Epoch 38, loss: 0.8713, val mf1: 0.7681, (best 0.7771)
Epoch 39, loss: 0.6994, val mf1: 0.7606, (best 0.7771)
Epoch 40, loss: 0.6171, val mf1: 0.7130, (best 0.7771)
Epoch 41, loss: 0.6673, val mf1: 0.6731, (best 0.7771)
Epoch 42, loss: 0.4997, val mf1: 0.7606, (best 0.7771)
Epoch 43, loss: 0.5823, val mf1: 0.7790, (best 0.7790)
Epoch 44, loss: 0.4893, val mf1: 0.7808, (best 0.7808)
Epoch 45, loss: 0.8396, val mf1: 0.5302, (best 0.7808)
Epoch 46, loss: 0.8698, val mf1: 0.7263, (best 0.7808)
Epoch 47, loss: 0.8084, val mf1: 0.7755, (best 0.7808)
Epoch 48, loss: 0.4237, val mf1: 0.7851, (best 0.7851)
Epoch 49, loss: 1.0841, val mf1: 0.5440, (best 0.7851)
Epoch 50, loss: 0.5466, val mf1: 0.7875, (best 0.7875)
Epoch 51, loss: 0.8772, val mf1: 0.7893, (best 0.7893)
Epoch 52, loss: 0.9380, val mf1: 0.7887, (best 0.7893)
Epoch 53, loss: 0.7799, val mf1: 0.7718, (best 0.7893)
Epoch 54, loss: 0.7380, val mf1: 0.7019, (best 0.7893)
Epoch 55, loss: 0.8277, val mf1: 0.6168, (best 0.7893)
Epoch 56, loss: 0.6973, val mf1: 0.6930, (best 0.7893)
Epoch 57, loss: 0.5087, val mf1: 0.7886, (best 0.7893)
Epoch 58, loss: 0.6587, val mf1: 0.7945, (best 0.7945)
Epoch 59, loss: 0.4459, val mf1: 0.8022, (best 0.8022)
Epoch 60, loss: 0.7516, val mf1: 0.7103, (best 0.8022)
Epoch 61, loss: 0.4967, val mf1: 0.8047, (best 0.8047)
Epoch 62, loss: 0.6480, val mf1: 0.8048, (best 0.8048)
Epoch 63, loss: 0.4787, val mf1: 0.8057, (best 0.8057)
Epoch 64, loss: 0.5188, val mf1: 0.7687, (best 0.8057)
Epoch 65, loss: 0.5626, val mf1: 0.7572, (best 0.8057)
Epoch 66, loss: 0.4581, val mf1: 0.7957, (best 0.8057)
Epoch 67, loss: 0.5051, val mf1: 0.8056, (best 0.8057)
Epoch 68, loss: 0.4915, val mf1: 0.8079, (best 0.8079)
Epoch 69, loss: 0.4027, val mf1: 0.8094, (best 0.8094)
Epoch 70, loss: 0.5755, val mf1: 0.8076, (best 0.8094)
Epoch 71, loss: 0.5103, val mf1: 0.8126, (best 0.8126)
Epoch 72, loss: 0.6392, val mf1: 0.8091, (best 0.8126)
Epoch 73, loss: 0.4589, val mf1: 0.8146, (best 0.8146)
Epoch 74, loss: 0.5046, val mf1: 0.7984, (best 0.8146)
Epoch 75, loss: 0.4289, val mf1: 0.8001, (best 0.8146)
Epoch 76, loss: 0.4383, val mf1: 0.8083, (best 0.8146)
Epoch 77, loss: 0.4773, val mf1: 0.8097, (best 0.8146)
Epoch 78, loss: 0.4312, val mf1: 0.8061, (best 0.8146)
Epoch 79, loss: 0.4135, val mf1: 0.8007, (best 0.8146)
Epoch 80, loss: 0.4448, val mf1: 0.8064, (best 0.8146)
Epoch 81, loss: 0.4023, val mf1: 0.8131, (best 0.8146)
Epoch 82, loss: 0.4507, val mf1: 0.8185, (best 0.8185)
Epoch 83, loss: 0.3889, val mf1: 0.8180, (best 0.8185)
Epoch 84, loss: 0.5114, val mf1: 0.8215, (best 0.8215)
Epoch 85, loss: 0.4660, val mf1: 0.8190, (best 0.8215)
Epoch 86, loss: 0.5340, val mf1: 0.8200, (best 0.8215)
Epoch 87, loss: 0.4191, val mf1: 0.8155, (best 0.8215)
Epoch 88, loss: 0.4563, val mf1: 0.8047, (best 0.8215)
Epoch 89, loss: 0.4507, val mf1: 0.8043, (best 0.8215)
Epoch 90, loss: 0.4128, val mf1: 0.8156, (best 0.8215)
Epoch 91, loss: 0.4657, val mf1: 0.8180, (best 0.8215)
Epoch 92, loss: 0.4253, val mf1: 0.8160, (best 0.8215)
Epoch 93, loss: 0.3771, val mf1: 0.8197, (best 0.8215)
Epoch 94, loss: 0.4801, val mf1: 0.8215, (best 0.8215)
Epoch 95, loss: 0.4732, val mf1: 0.8215, (best 0.8215)
Epoch 96, loss: 0.5944, val mf1: 0.8225, (best 0.8225)
Epoch 97, loss: 0.4600, val mf1: 0.8234, (best 0.8234)
Epoch 98, loss: 0.4068, val mf1: 0.8215, (best 0.8234)
Epoch 99, loss: 0.4969, val mf1: 0.8179, (best 0.8234)
time cost:  17.997708320617676 s
Test: REC 60.97 PRE 64.06 MF1 80.36 AUC 88.81
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=128, normalization=both, activation=None)
    (1-2): 2 x GraphConv(in=128, out=128, normalization=both, activation=None)
    (3): GraphConv(in=128, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 30.4950, val mf1: 0.0523, (best 0.0523)
Epoch 1, loss: 661.7281, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 545.4847, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 326.0603, val mf1: 0.4883, (best 0.4883)
Epoch 4, loss: 86.0726, val mf1: 0.4967, (best 0.4967)
Epoch 5, loss: 156.6164, val mf1: 0.0438, (best 0.4967)
Epoch 6, loss: 182.2179, val mf1: 0.0438, (best 0.4967)
Epoch 7, loss: 113.0517, val mf1: 0.0438, (best 0.4967)
Epoch 8, loss: 5.8336, val mf1: 0.1751, (best 0.4967)
Epoch 9, loss: 66.1029, val mf1: 0.4967, (best 0.4967)
Epoch 10, loss: 99.7705, val mf1: 0.4967, (best 0.4967)
Epoch 11, loss: 105.4103, val mf1: 0.4967, (best 0.4967)
Epoch 12, loss: 92.6689, val mf1: 0.4967, (best 0.4967)
Epoch 13, loss: 69.6907, val mf1: 0.4967, (best 0.4967)
Epoch 14, loss: 39.7764, val mf1: 0.4967, (best 0.4967)
Epoch 15, loss: 6.2794, val mf1: 0.5336, (best 0.5336)
Epoch 16, loss: 31.4713, val mf1: 0.0444, (best 0.5336)
Epoch 17, loss: 47.3009, val mf1: 0.0438, (best 0.5336)
Epoch 18, loss: 42.0762, val mf1: 0.0438, (best 0.5336)
Epoch 19, loss: 25.2747, val mf1: 0.0455, (best 0.5336)
Epoch 20, loss: 2.9636, val mf1: 0.3584, (best 0.5336)
Epoch 21, loss: 12.2133, val mf1: 0.5325, (best 0.5336)
Epoch 22, loss: 19.6578, val mf1: 0.5291, (best 0.5336)
Epoch 23, loss: 18.5035, val mf1: 0.5291, (best 0.5336)
Epoch 24, loss: 12.1227, val mf1: 0.5326, (best 0.5336)
Epoch 25, loss: 3.7990, val mf1: 0.7115, (best 0.7115)
Epoch 26, loss: 2.3046, val mf1: 0.4614, (best 0.7115)
Epoch 27, loss: 8.0986, val mf1: 0.0853, (best 0.7115)
Epoch 28, loss: 8.5726, val mf1: 0.0793, (best 0.7115)
Epoch 29, loss: 4.4771, val mf1: 0.2820, (best 0.7115)
Epoch 30, loss: 1.7582, val mf1: 0.5142, (best 0.7115)
Epoch 31, loss: 2.1370, val mf1: 0.7618, (best 0.7618)
Epoch 32, loss: 4.1777, val mf1: 0.6359, (best 0.7618)
Epoch 33, loss: 4.2617, val mf1: 0.6352, (best 0.7618)
Epoch 34, loss: 2.7854, val mf1: 0.7334, (best 0.7618)
Epoch 35, loss: 1.5329, val mf1: 0.7030, (best 0.7618)
Epoch 36, loss: 1.6513, val mf1: 0.5153, (best 0.7618)
Epoch 37, loss: 2.3155, val mf1: 0.4401, (best 0.7618)
Epoch 38, loss: 2.7255, val mf1: 0.3933, (best 0.7618)
Epoch 39, loss: 2.3951, val mf1: 0.4151, (best 0.7618)
Epoch 40, loss: 1.5687, val mf1: 0.4769, (best 0.7618)
Epoch 41, loss: 1.5209, val mf1: 0.5291, (best 0.7618)
Epoch 42, loss: 1.7351, val mf1: 0.5291, (best 0.7618)
Epoch 43, loss: 1.2400, val mf1: 0.5309, (best 0.7618)
Epoch 44, loss: 1.1809, val mf1: 0.5887, (best 0.7618)
Epoch 45, loss: 1.2085, val mf1: 0.5796, (best 0.7618)
Epoch 46, loss: 1.2042, val mf1: 0.5772, (best 0.7618)
Epoch 47, loss: 1.1481, val mf1: 0.5910, (best 0.7618)
Epoch 48, loss: 1.0575, val mf1: 0.6297, (best 0.7618)
Epoch 49, loss: 0.9682, val mf1: 0.7387, (best 0.7618)
Epoch 50, loss: 0.9121, val mf1: 0.7968, (best 0.7968)
Epoch 51, loss: 0.9003, val mf1: 0.8306, (best 0.8306)
Epoch 52, loss: 0.8134, val mf1: 0.8353, (best 0.8353)
Epoch 53, loss: 0.6743, val mf1: 0.8311, (best 0.8353)
Epoch 54, loss: 0.6503, val mf1: 0.7952, (best 0.8353)
Epoch 55, loss: 0.5963, val mf1: 0.8064, (best 0.8353)
Epoch 56, loss: 0.5877, val mf1: 0.8292, (best 0.8353)
Epoch 57, loss: 0.5168, val mf1: 0.8543, (best 0.8543)
Epoch 58, loss: 0.5157, val mf1: 0.8306, (best 0.8543)
Epoch 59, loss: 0.4609, val mf1: 0.8652, (best 0.8652)
Epoch 60, loss: 0.4616, val mf1: 0.8620, (best 0.8652)
Epoch 61, loss: 0.4358, val mf1: 0.8481, (best 0.8652)
Epoch 62, loss: 0.4497, val mf1: 0.8352, (best 0.8652)
Epoch 63, loss: 0.4354, val mf1: 0.8364, (best 0.8652)
Epoch 64, loss: 0.4447, val mf1: 0.8459, (best 0.8652)
Epoch 65, loss: 0.4369, val mf1: 0.8409, (best 0.8652)
Epoch 66, loss: 0.4314, val mf1: 0.8268, (best 0.8652)
Epoch 67, loss: 0.4288, val mf1: 0.8286, (best 0.8652)
Epoch 68, loss: 0.4143, val mf1: 0.8437, (best 0.8652)
Epoch 69, loss: 0.4163, val mf1: 0.8514, (best 0.8652)
Epoch 70, loss: 0.4054, val mf1: 0.8484, (best 0.8652)
Epoch 71, loss: 0.4118, val mf1: 0.8475, (best 0.8652)
Epoch 72, loss: 0.4023, val mf1: 0.8552, (best 0.8652)
Epoch 73, loss: 0.4049, val mf1: 0.8599, (best 0.8652)
Epoch 74, loss: 0.3941, val mf1: 0.8539, (best 0.8652)
Epoch 75, loss: 0.3948, val mf1: 0.8467, (best 0.8652)
Epoch 76, loss: 0.3876, val mf1: 0.8517, (best 0.8652)
Epoch 77, loss: 0.3887, val mf1: 0.8519, (best 0.8652)
Epoch 78, loss: 0.3858, val mf1: 0.8414, (best 0.8652)
Epoch 79, loss: 0.3847, val mf1: 0.8417, (best 0.8652)
Epoch 80, loss: 0.3811, val mf1: 0.8513, (best 0.8652)
Epoch 81, loss: 0.3772, val mf1: 0.8513, (best 0.8652)
Epoch 82, loss: 0.3755, val mf1: 0.8476, (best 0.8652)
Epoch 83, loss: 0.3720, val mf1: 0.8528, (best 0.8652)
Epoch 84, loss: 0.3730, val mf1: 0.8577, (best 0.8652)
Epoch 85, loss: 0.3688, val mf1: 0.8557, (best 0.8652)
Epoch 86, loss: 0.3678, val mf1: 0.8514, (best 0.8652)
Epoch 87, loss: 0.3640, val mf1: 0.8550, (best 0.8652)
Epoch 88, loss: 0.3626, val mf1: 0.8552, (best 0.8652)
Epoch 89, loss: 0.3615, val mf1: 0.8520, (best 0.8652)
Epoch 90, loss: 0.3601, val mf1: 0.8524, (best 0.8652)
Epoch 91, loss: 0.3586, val mf1: 0.8517, (best 0.8652)
Epoch 92, loss: 0.3564, val mf1: 0.8517, (best 0.8652)
Epoch 93, loss: 0.3555, val mf1: 0.8531, (best 0.8652)
Epoch 94, loss: 0.3541, val mf1: 0.8563, (best 0.8652)
Epoch 95, loss: 0.3541, val mf1: 0.8570, (best 0.8652)
Epoch 96, loss: 0.3528, val mf1: 0.8568, (best 0.8652)
Epoch 97, loss: 0.3523, val mf1: 0.8545, (best 0.8652)
Epoch 98, loss: 0.3508, val mf1: 0.8570, (best 0.8652)
Epoch 99, loss: 0.3504, val mf1: 0.8563, (best 0.8652)
time cost:  17.974005460739136 s
Test: REC 60.83 PRE 86.81 MF1 85.19 AUC 91.93
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=128, normalization=both, activation=None)
    (1-2): 2 x GraphConv(in=128, out=128, normalization=both, activation=None)
    (3): GraphConv(in=128, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
Average AUC: 0.6100817037500591, Average Recall: 0.8438623673988942, Average Precision: 0.5117001260571415, Average F1: 0.5954049967578309 in 3 runs, with hid_dim: 128, num_layers: 4
Trying hid_dim: 128, num_layers: 5
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 74.9990, val mf1: 0.0438, (best 0.0438)
Epoch 1, loss: 623.1640, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 363.2350, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 60.5445, val mf1: 0.4883, (best 0.4883)
Epoch 4, loss: 233.2585, val mf1: 0.0438, (best 0.4883)
Epoch 5, loss: 190.1641, val mf1: 0.0438, (best 0.4883)
Epoch 6, loss: 67.3100, val mf1: 0.0438, (best 0.4883)
Epoch 7, loss: 51.8000, val mf1: 0.4967, (best 0.4967)
Epoch 8, loss: 82.6386, val mf1: 0.4883, (best 0.4967)
Epoch 9, loss: 73.5543, val mf1: 0.4967, (best 0.4967)
Epoch 10, loss: 46.9235, val mf1: 0.4967, (best 0.4967)
Epoch 11, loss: 14.7062, val mf1: 0.4967, (best 0.4967)
Epoch 12, loss: 20.3279, val mf1: 0.0463, (best 0.4967)
Epoch 13, loss: 29.0378, val mf1: 0.0441, (best 0.4967)
Epoch 14, loss: 18.8518, val mf1: 0.0467, (best 0.4967)
Epoch 15, loss: 0.7397, val mf1: 0.7608, (best 0.7608)
Epoch 16, loss: 7.7262, val mf1: 0.5301, (best 0.7608)
Epoch 17, loss: 4.5650, val mf1: 0.5325, (best 0.7608)
Epoch 18, loss: 2.9682, val mf1: 0.2263, (best 0.7608)
Epoch 19, loss: 0.9922, val mf1: 0.5886, (best 0.7608)
Epoch 20, loss: 3.1323, val mf1: 0.5464, (best 0.7608)
Epoch 21, loss: 0.7403, val mf1: 0.7493, (best 0.7608)
Epoch 22, loss: 1.7488, val mf1: 0.4030, (best 0.7608)
Epoch 23, loss: 0.5997, val mf1: 0.7329, (best 0.7608)
Epoch 24, loss: 2.1118, val mf1: 0.5315, (best 0.7608)
Epoch 25, loss: 1.1085, val mf1: 0.6698, (best 0.7608)
Epoch 26, loss: 0.9616, val mf1: 0.5626, (best 0.7608)
Epoch 27, loss: 1.2936, val mf1: 0.4959, (best 0.7608)
Epoch 28, loss: 0.7078, val mf1: 0.7155, (best 0.7608)
Epoch 29, loss: 1.0473, val mf1: 0.7774, (best 0.7774)
Epoch 30, loss: 0.9807, val mf1: 0.7753, (best 0.7774)
Epoch 31, loss: 0.7154, val mf1: 0.7304, (best 0.7774)
Epoch 32, loss: 0.9166, val mf1: 0.5732, (best 0.7774)
Epoch 33, loss: 0.8817, val mf1: 0.5804, (best 0.7774)
Epoch 34, loss: 0.6284, val mf1: 0.7433, (best 0.7774)
Epoch 35, loss: 0.7381, val mf1: 0.7780, (best 0.7780)
Epoch 36, loss: 0.6915, val mf1: 0.7810, (best 0.7810)
Epoch 37, loss: 0.5071, val mf1: 0.7670, (best 0.7810)
Epoch 38, loss: 0.8384, val mf1: 0.6666, (best 0.7810)
Epoch 39, loss: 0.7203, val mf1: 0.7799, (best 0.7810)
Epoch 40, loss: 0.9468, val mf1: 0.7259, (best 0.7810)
Epoch 41, loss: 0.4733, val mf1: 0.7795, (best 0.7810)
Epoch 42, loss: 1.0645, val mf1: 0.6072, (best 0.7810)
Epoch 43, loss: 0.5215, val mf1: 0.7764, (best 0.7810)
Epoch 44, loss: 0.8570, val mf1: 0.7748, (best 0.7810)
Epoch 45, loss: 0.7357, val mf1: 0.7776, (best 0.7810)
Epoch 46, loss: 0.5938, val mf1: 0.7557, (best 0.7810)
Epoch 47, loss: 0.7561, val mf1: 0.6171, (best 0.7810)
Epoch 48, loss: 0.7903, val mf1: 0.6052, (best 0.7810)
Epoch 49, loss: 0.6228, val mf1: 0.7173, (best 0.7810)
Epoch 50, loss: 0.6076, val mf1: 0.7755, (best 0.7810)
Epoch 51, loss: 0.7098, val mf1: 0.7793, (best 0.7810)
Epoch 52, loss: 0.6111, val mf1: 0.7809, (best 0.7810)
Epoch 53, loss: 0.5257, val mf1: 0.7680, (best 0.7810)
Epoch 54, loss: 0.6094, val mf1: 0.7118, (best 0.7810)
Epoch 55, loss: 0.5756, val mf1: 0.7354, (best 0.7810)
Epoch 56, loss: 0.4812, val mf1: 0.7757, (best 0.7810)
Epoch 57, loss: 0.5557, val mf1: 0.7873, (best 0.7873)
Epoch 58, loss: 0.5178, val mf1: 0.7879, (best 0.7879)
Epoch 59, loss: 0.4792, val mf1: 0.7789, (best 0.7879)
Epoch 60, loss: 0.5678, val mf1: 0.7675, (best 0.7879)
Epoch 61, loss: 0.5139, val mf1: 0.7913, (best 0.7913)
Epoch 62, loss: 0.5890, val mf1: 0.7897, (best 0.7913)
Epoch 63, loss: 0.4610, val mf1: 0.7882, (best 0.7913)
Epoch 64, loss: 0.5883, val mf1: 0.7678, (best 0.7913)
Epoch 65, loss: 0.4561, val mf1: 0.7879, (best 0.7913)
Epoch 66, loss: 0.5252, val mf1: 0.7897, (best 0.7913)
Epoch 67, loss: 0.4978, val mf1: 0.7878, (best 0.7913)
Epoch 68, loss: 0.4655, val mf1: 0.7812, (best 0.7913)
Epoch 69, loss: 0.5170, val mf1: 0.7747, (best 0.7913)
Epoch 70, loss: 0.4817, val mf1: 0.7789, (best 0.7913)
Epoch 71, loss: 0.4712, val mf1: 0.7863, (best 0.7913)
Epoch 72, loss: 0.4999, val mf1: 0.7905, (best 0.7913)
Epoch 73, loss: 0.4715, val mf1: 0.7875, (best 0.7913)
Epoch 74, loss: 0.4592, val mf1: 0.7817, (best 0.7913)
Epoch 75, loss: 0.4810, val mf1: 0.7823, (best 0.7913)
Epoch 76, loss: 0.4468, val mf1: 0.7879, (best 0.7913)
Epoch 77, loss: 0.4561, val mf1: 0.7936, (best 0.7936)
Epoch 78, loss: 0.4586, val mf1: 0.7980, (best 0.7980)
Epoch 79, loss: 0.4398, val mf1: 0.7953, (best 0.7980)
Epoch 80, loss: 0.4653, val mf1: 0.7883, (best 0.7980)
Epoch 81, loss: 0.4421, val mf1: 0.8015, (best 0.8015)
Epoch 82, loss: 0.4602, val mf1: 0.8000, (best 0.8015)
Epoch 83, loss: 0.4355, val mf1: 0.7962, (best 0.8015)
Epoch 84, loss: 0.4565, val mf1: 0.7902, (best 0.8015)
Epoch 85, loss: 0.4318, val mf1: 0.7962, (best 0.8015)
Epoch 86, loss: 0.4861, val mf1: 0.8013, (best 0.8015)
Epoch 87, loss: 0.4359, val mf1: 0.7932, (best 0.8015)
Epoch 88, loss: 0.4440, val mf1: 0.7884, (best 0.8015)
Epoch 89, loss: 0.4356, val mf1: 0.7928, (best 0.8015)
Epoch 90, loss: 0.4395, val mf1: 0.7945, (best 0.8015)
Epoch 91, loss: 0.4323, val mf1: 0.7970, (best 0.8015)
Epoch 92, loss: 0.4337, val mf1: 0.7960, (best 0.8015)
Epoch 93, loss: 0.4313, val mf1: 0.7924, (best 0.8015)
Epoch 94, loss: 0.4292, val mf1: 0.8008, (best 0.8015)
Epoch 95, loss: 0.4306, val mf1: 0.8009, (best 0.8015)
Epoch 96, loss: 0.4270, val mf1: 0.7974, (best 0.8015)
Epoch 97, loss: 0.4295, val mf1: 0.7981, (best 0.8015)
Epoch 98, loss: 0.4274, val mf1: 0.8069, (best 0.8069)
Epoch 99, loss: 0.4268, val mf1: 0.8069, (best 0.8069)
time cost:  20.317302227020264 s
Test: REC 60.14 PRE 59.73 MF1 79.00 AUC 86.54
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=128, normalization=both, activation=None)
    (1-3): 3 x GraphConv(in=128, out=128, normalization=both, activation=None)
    (4): GraphConv(in=128, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 96.0737, val mf1: 0.0438, (best 0.0438)
Epoch 1, loss: 219.4823, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 107.6900, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 70.1562, val mf1: 0.0438, (best 0.4883)
Epoch 4, loss: 6.5851, val mf1: 0.1010, (best 0.4883)
Epoch 5, loss: 74.2421, val mf1: 0.4967, (best 0.4967)
Epoch 6, loss: 66.1650, val mf1: 0.4967, (best 0.4967)
Epoch 7, loss: 25.5763, val mf1: 0.4967, (best 0.4967)
Epoch 8, loss: 33.5403, val mf1: 0.0438, (best 0.4967)
Epoch 9, loss: 35.4832, val mf1: 0.0438, (best 0.4967)
Epoch 10, loss: 6.0439, val mf1: 0.1094, (best 0.4967)
Epoch 11, loss: 24.2930, val mf1: 0.4967, (best 0.4967)
Epoch 12, loss: 32.1529, val mf1: 0.4967, (best 0.4967)
Epoch 13, loss: 22.8269, val mf1: 0.4967, (best 0.4967)
Epoch 14, loss: 2.3551, val mf1: 0.7616, (best 0.7616)
Epoch 15, loss: 23.8599, val mf1: 0.0455, (best 0.7616)
Epoch 16, loss: 26.6165, val mf1: 0.0445, (best 0.7616)
Epoch 17, loss: 9.8696, val mf1: 0.0693, (best 0.7616)
Epoch 18, loss: 8.4355, val mf1: 0.5310, (best 0.7616)
Epoch 19, loss: 15.4582, val mf1: 0.5291, (best 0.7616)
Epoch 20, loss: 13.5736, val mf1: 0.5291, (best 0.7616)
Epoch 21, loss: 5.8352, val mf1: 0.5344, (best 0.7616)
Epoch 22, loss: 3.8018, val mf1: 0.2440, (best 0.7616)
Epoch 23, loss: 6.0149, val mf1: 0.1076, (best 0.7616)
Epoch 24, loss: 1.3257, val mf1: 0.5297, (best 0.7616)
Epoch 25, loss: 2.4550, val mf1: 0.7278, (best 0.7616)
Epoch 26, loss: 3.0479, val mf1: 0.6485, (best 0.7616)
Epoch 27, loss: 1.2047, val mf1: 0.7766, (best 0.7766)
Epoch 28, loss: 1.3243, val mf1: 0.5190, (best 0.7766)
Epoch 29, loss: 2.2691, val mf1: 0.3916, (best 0.7766)
Epoch 30, loss: 1.8271, val mf1: 0.4540, (best 0.7766)
Epoch 31, loss: 0.9501, val mf1: 0.6323, (best 0.7766)
Epoch 32, loss: 1.2789, val mf1: 0.7740, (best 0.7766)
Epoch 33, loss: 1.8175, val mf1: 0.7476, (best 0.7766)
Epoch 34, loss: 1.1910, val mf1: 0.7745, (best 0.7766)
Epoch 35, loss: 0.8964, val mf1: 0.6588, (best 0.7766)
Epoch 36, loss: 1.2703, val mf1: 0.5141, (best 0.7766)
Epoch 37, loss: 1.4254, val mf1: 0.4947, (best 0.7766)
Epoch 38, loss: 1.0547, val mf1: 0.5588, (best 0.7766)
Epoch 39, loss: 0.8367, val mf1: 0.7414, (best 0.7766)
Epoch 40, loss: 1.0562, val mf1: 0.7785, (best 0.7785)
Epoch 41, loss: 1.1614, val mf1: 0.7801, (best 0.7801)
Epoch 42, loss: 0.8902, val mf1: 0.7796, (best 0.7801)
Epoch 43, loss: 0.7869, val mf1: 0.6968, (best 0.7801)
Epoch 44, loss: 0.9521, val mf1: 0.5749, (best 0.7801)
Epoch 45, loss: 0.9900, val mf1: 0.5589, (best 0.7801)
Epoch 46, loss: 0.7935, val mf1: 0.6419, (best 0.7801)
Epoch 47, loss: 0.7107, val mf1: 0.7802, (best 0.7802)
Epoch 48, loss: 0.9173, val mf1: 0.7884, (best 0.7884)
Epoch 49, loss: 0.7085, val mf1: 0.7859, (best 0.7884)
Epoch 50, loss: 0.6335, val mf1: 0.7422, (best 0.7884)
Epoch 51, loss: 0.7498, val mf1: 0.6419, (best 0.7884)
Epoch 52, loss: 0.6329, val mf1: 0.7311, (best 0.7884)
Epoch 53, loss: 0.5845, val mf1: 0.7987, (best 0.7987)
Epoch 54, loss: 0.6624, val mf1: 0.8048, (best 0.8048)
Epoch 55, loss: 0.5416, val mf1: 0.8017, (best 0.8048)
Epoch 56, loss: 0.5943, val mf1: 0.7596, (best 0.8048)
Epoch 57, loss: 0.5563, val mf1: 0.7799, (best 0.8048)
Epoch 58, loss: 0.5261, val mf1: 0.8126, (best 0.8126)
Epoch 59, loss: 0.5612, val mf1: 0.8148, (best 0.8148)
Epoch 60, loss: 0.4733, val mf1: 0.8051, (best 0.8148)
Epoch 61, loss: 0.5472, val mf1: 0.7861, (best 0.8148)
Epoch 62, loss: 0.4577, val mf1: 0.8195, (best 0.8195)
Epoch 63, loss: 0.5122, val mf1: 0.8199, (best 0.8199)
Epoch 64, loss: 0.4336, val mf1: 0.8199, (best 0.8199)
Epoch 65, loss: 0.5048, val mf1: 0.8039, (best 0.8199)
Epoch 66, loss: 0.4572, val mf1: 0.8209, (best 0.8209)
Epoch 67, loss: 0.4743, val mf1: 0.8230, (best 0.8230)
Epoch 68, loss: 0.4199, val mf1: 0.8233, (best 0.8233)
Epoch 69, loss: 0.3804, val mf1: 0.8303, (best 0.8303)
Epoch 70, loss: 0.5419, val mf1: 0.8511, (best 0.8511)
Epoch 71, loss: 3.0553, val mf1: 0.2732, (best 0.8511)
Epoch 72, loss: 2.8299, val mf1: 0.5503, (best 0.8511)
Epoch 73, loss: 2.7856, val mf1: 0.5944, (best 0.8511)
Epoch 74, loss: 0.7463, val mf1: 0.8126, (best 0.8511)
Epoch 75, loss: 1.6627, val mf1: 0.4479, (best 0.8511)
Epoch 76, loss: 2.5488, val mf1: 0.3149, (best 0.8511)
Epoch 77, loss: 0.9370, val mf1: 0.5907, (best 0.8511)
Epoch 78, loss: 1.0458, val mf1: 0.8079, (best 0.8511)
Epoch 79, loss: 1.8078, val mf1: 0.7853, (best 0.8511)
Epoch 80, loss: 1.4914, val mf1: 0.8038, (best 0.8511)
Epoch 81, loss: 0.9900, val mf1: 0.8009, (best 0.8511)
Epoch 82, loss: 0.9832, val mf1: 0.6218, (best 0.8511)
Epoch 83, loss: 1.2606, val mf1: 0.5347, (best 0.8511)
Epoch 84, loss: 1.2110, val mf1: 0.5349, (best 0.8511)
Epoch 85, loss: 0.8094, val mf1: 0.6309, (best 0.8511)
Epoch 86, loss: 0.5841, val mf1: 0.8040, (best 0.8511)
Epoch 87, loss: 0.6780, val mf1: 0.8095, (best 0.8511)
Epoch 88, loss: 0.7450, val mf1: 0.8133, (best 0.8511)
Epoch 89, loss: 0.5247, val mf1: 0.8097, (best 0.8511)
Epoch 90, loss: 0.6342, val mf1: 0.7494, (best 0.8511)
Epoch 91, loss: 0.7469, val mf1: 0.7066, (best 0.8511)
Epoch 92, loss: 0.4972, val mf1: 0.8117, (best 0.8511)
Epoch 93, loss: 0.6889, val mf1: 0.8065, (best 0.8511)
Epoch 94, loss: 0.5638, val mf1: 0.8191, (best 0.8511)
Epoch 95, loss: 0.4461, val mf1: 0.8099, (best 0.8511)
Epoch 96, loss: 0.5937, val mf1: 0.7839, (best 0.8511)
Epoch 97, loss: 0.5060, val mf1: 0.7926, (best 0.8511)
Epoch 98, loss: 0.4455, val mf1: 0.8118, (best 0.8511)
Epoch 99, loss: 0.5159, val mf1: 0.8146, (best 0.8511)
time cost:  20.305991649627686 s
Test: REC 62.07 PRE 77.05 MF1 83.70 AUC 88.03
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=128, normalization=both, activation=None)
    (1-3): 3 x GraphConv(in=128, out=128, normalization=both, activation=None)
    (4): GraphConv(in=128, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 121.3117, val mf1: 0.0438, (best 0.0438)
Epoch 1, loss: 397.7468, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 227.0719, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 59.7898, val mf1: 0.4967, (best 0.4967)
Epoch 4, loss: 99.9126, val mf1: 0.0438, (best 0.4967)
Epoch 5, loss: 87.8869, val mf1: 0.0438, (best 0.4967)
Epoch 6, loss: 16.0117, val mf1: 0.0497, (best 0.4967)
Epoch 7, loss: 52.5828, val mf1: 0.4967, (best 0.4967)
Epoch 8, loss: 64.6661, val mf1: 0.4967, (best 0.4967)
Epoch 9, loss: 49.2433, val mf1: 0.4967, (best 0.4967)
Epoch 10, loss: 12.5796, val mf1: 0.5310, (best 0.5310)
Epoch 11, loss: 38.9173, val mf1: 0.0438, (best 0.5310)
Epoch 12, loss: 44.9726, val mf1: 0.0438, (best 0.5310)
Epoch 13, loss: 27.8440, val mf1: 0.0441, (best 0.5310)
Epoch 14, loss: 1.4222, val mf1: 0.4570, (best 0.5310)
Epoch 15, loss: 15.4053, val mf1: 0.5291, (best 0.5310)
Epoch 16, loss: 19.8861, val mf1: 0.4967, (best 0.5310)
Epoch 17, loss: 16.4669, val mf1: 0.5274, (best 0.5310)
Epoch 18, loss: 8.2321, val mf1: 0.5319, (best 0.5319)
Epoch 19, loss: 1.9654, val mf1: 0.3758, (best 0.5319)
Epoch 20, loss: 5.7616, val mf1: 0.1140, (best 0.5319)
Epoch 21, loss: 0.6247, val mf1: 0.7157, (best 0.7157)
Epoch 22, loss: 5.2912, val mf1: 0.5314, (best 0.7157)
Epoch 23, loss: 4.0457, val mf1: 0.5327, (best 0.7157)
Epoch 24, loss: 0.6067, val mf1: 0.7672, (best 0.7672)
Epoch 25, loss: 3.2315, val mf1: 0.1990, (best 0.7672)
Epoch 26, loss: 0.7092, val mf1: 0.7048, (best 0.7672)
Epoch 27, loss: 2.3489, val mf1: 0.5699, (best 0.7672)
Epoch 28, loss: 1.3422, val mf1: 0.7463, (best 0.7672)
Epoch 29, loss: 1.4445, val mf1: 0.4752, (best 0.7672)
Epoch 30, loss: 2.0320, val mf1: 0.3759, (best 0.7672)
Epoch 31, loss: 0.6965, val mf1: 0.7865, (best 0.7865)
Epoch 32, loss: 1.7894, val mf1: 0.7101, (best 0.7865)
Epoch 33, loss: 1.1959, val mf1: 0.7819, (best 0.7865)
Epoch 34, loss: 0.8106, val mf1: 0.6466, (best 0.7865)
Epoch 35, loss: 1.5221, val mf1: 0.4753, (best 0.7865)
Epoch 36, loss: 0.9496, val mf1: 0.5770, (best 0.7865)
Epoch 37, loss: 0.7981, val mf1: 0.7903, (best 0.7903)
Epoch 38, loss: 1.2396, val mf1: 0.7797, (best 0.7903)
Epoch 39, loss: 0.8119, val mf1: 0.7888, (best 0.7903)
Epoch 40, loss: 0.7415, val mf1: 0.6686, (best 0.7903)
Epoch 41, loss: 1.0773, val mf1: 0.5355, (best 0.7903)
Epoch 42, loss: 0.6848, val mf1: 0.7166, (best 0.7903)
Epoch 43, loss: 0.7395, val mf1: 0.7936, (best 0.7936)
Epoch 44, loss: 0.9107, val mf1: 0.7941, (best 0.7941)
Epoch 45, loss: 0.6163, val mf1: 0.7953, (best 0.7953)
Epoch 46, loss: 0.7070, val mf1: 0.6844, (best 0.7953)
Epoch 47, loss: 0.7727, val mf1: 0.6445, (best 0.7953)
Epoch 48, loss: 0.5499, val mf1: 0.7931, (best 0.7953)
Epoch 49, loss: 0.6974, val mf1: 0.8018, (best 0.8018)
Epoch 50, loss: 0.6435, val mf1: 0.7996, (best 0.8018)
Epoch 51, loss: 0.5230, val mf1: 0.7905, (best 0.8018)
Epoch 52, loss: 0.6663, val mf1: 0.7290, (best 0.8018)
Epoch 53, loss: 0.5189, val mf1: 0.7907, (best 0.8018)
Epoch 54, loss: 0.5539, val mf1: 0.8048, (best 0.8048)
Epoch 55, loss: 0.5810, val mf1: 0.8060, (best 0.8060)
Epoch 56, loss: 0.4730, val mf1: 0.8026, (best 0.8060)
Epoch 57, loss: 0.5688, val mf1: 0.7826, (best 0.8060)
Epoch 58, loss: 0.4706, val mf1: 0.8001, (best 0.8060)
Epoch 59, loss: 0.5065, val mf1: 0.8104, (best 0.8104)
Epoch 60, loss: 0.4994, val mf1: 0.8118, (best 0.8118)
Epoch 61, loss: 0.4493, val mf1: 0.8071, (best 0.8118)
Epoch 62, loss: 0.5018, val mf1: 0.7999, (best 0.8118)
Epoch 63, loss: 0.4327, val mf1: 0.8139, (best 0.8139)
Epoch 64, loss: 0.4824, val mf1: 0.8234, (best 0.8234)
Epoch 65, loss: 0.4154, val mf1: 0.8192, (best 0.8234)
Epoch 66, loss: 0.4612, val mf1: 0.8188, (best 0.8234)
Epoch 67, loss: 0.3980, val mf1: 0.8222, (best 0.8234)
Epoch 68, loss: 0.4238, val mf1: 0.8263, (best 0.8263)
Epoch 69, loss: 0.3981, val mf1: 0.8203, (best 0.8263)
Epoch 70, loss: 0.3996, val mf1: 0.8199, (best 0.8263)
Epoch 71, loss: 0.3688, val mf1: 0.8267, (best 0.8267)
Epoch 72, loss: 0.3717, val mf1: 0.8412, (best 0.8412)
Epoch 73, loss: 0.3748, val mf1: 0.8413, (best 0.8413)
Epoch 74, loss: 0.3714, val mf1: 0.8351, (best 0.8413)
Epoch 75, loss: 0.3651, val mf1: 0.8331, (best 0.8413)
Epoch 76, loss: 0.3599, val mf1: 0.8242, (best 0.8413)
Epoch 77, loss: 0.3635, val mf1: 0.8229, (best 0.8413)
Epoch 78, loss: 0.3627, val mf1: 0.8244, (best 0.8413)
Epoch 79, loss: 0.3603, val mf1: 0.8258, (best 0.8413)
Epoch 80, loss: 0.3539, val mf1: 0.8270, (best 0.8413)
Epoch 81, loss: 0.3512, val mf1: 0.8343, (best 0.8413)
Epoch 82, loss: 0.3501, val mf1: 0.8418, (best 0.8418)
Epoch 83, loss: 0.3471, val mf1: 0.8447, (best 0.8447)
Epoch 84, loss: 0.3481, val mf1: 0.8456, (best 0.8456)
Epoch 85, loss: 0.3457, val mf1: 0.8444, (best 0.8456)
Epoch 86, loss: 0.3407, val mf1: 0.8427, (best 0.8456)
Epoch 87, loss: 0.3437, val mf1: 0.8442, (best 0.8456)
Epoch 88, loss: 0.3389, val mf1: 0.8465, (best 0.8465)
Epoch 89, loss: 0.3360, val mf1: 0.8472, (best 0.8472)
Epoch 90, loss: 0.3375, val mf1: 0.8473, (best 0.8473)
Epoch 91, loss: 0.3330, val mf1: 0.8463, (best 0.8473)
Epoch 92, loss: 0.3336, val mf1: 0.8455, (best 0.8473)
Epoch 93, loss: 0.3322, val mf1: 0.8462, (best 0.8473)
Epoch 94, loss: 0.3310, val mf1: 0.8477, (best 0.8477)
Epoch 95, loss: 0.3315, val mf1: 0.8460, (best 0.8477)
Epoch 96, loss: 0.3298, val mf1: 0.8472, (best 0.8477)
Epoch 97, loss: 0.3299, val mf1: 0.8483, (best 0.8483)
Epoch 98, loss: 0.3273, val mf1: 0.8477, (best 0.8483)
Epoch 99, loss: 0.3270, val mf1: 0.8461, (best 0.8483)
time cost:  20.282573461532593 s
Test: REC 70.90 PRE 67.90 MF1 83.93 AUC 92.44
Model during scoring: GCNModel(
  (layers): ModuleList(
    (0): GraphConv(in=10, out=128, normalization=both, activation=None)
    (1-3): 3 x GraphConv(in=128, out=128, normalization=both, activation=None)
    (4): GraphConv(in=128, out=2, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Graph during scoring: Graph(num_nodes=39357, num_edges=42445086,
      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
Evaluate function: test_mask tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')
Average AUC: 0.6568241664040149, Average Recall: 0.830365063196313, Average Precision: 0.484130976754668, Average F1: 0.5598234611838578 in 3 runs, with hid_dim: 128, num_layers: 5
Best parameters found:  {'hid_dim': 128, 'num_layers': 3}
Highest AUC found:  0.700732547357266
