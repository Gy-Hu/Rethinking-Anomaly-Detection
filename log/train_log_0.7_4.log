Using device: cuda
Namespace(dataset='tfinance', train_ratio=0.4, hid_dim=128, num_layers=3, epoch=100, run=3, knn_reconstruct_graph=True, knn_reconstruct_graph_approximate=False, alpha=0.7, top_k=4, save_model=False, model_path='./model', device=device(type='cuda', index=0), choose_model='GCN', hyperparameter_tuning=False)
Graph(num_nodes=39357, num_edges=249334,
      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'feature': Scheme(shape=(10,), dtype=torch.float32)}
      edata_schemes={})
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 42.0747, val mf1: 0.4978, (best 0.4978)
Epoch 1, loss: 598.6876, val mf1: 0.0438, (best 0.4978)
Epoch 2, loss: 129.2027, val mf1: 0.0984, (best 0.4978)
Epoch 3, loss: 28.1538, val mf1: 0.5870, (best 0.5870)
Epoch 4, loss: 46.8689, val mf1: 0.7276, (best 0.7276)
Epoch 5, loss: 58.5392, val mf1: 0.8180, (best 0.8180)
Epoch 6, loss: 67.4518, val mf1: 0.7635, (best 0.8180)
Epoch 7, loss: 73.3268, val mf1: 0.7313, (best 0.8180)
Epoch 8, loss: 76.4512, val mf1: 0.7107, (best 0.8180)
Epoch 9, loss: 77.6203, val mf1: 0.6895, (best 0.8180)
Epoch 10, loss: 77.1593, val mf1: 0.6679, (best 0.8180)
Epoch 11, loss: 75.1914, val mf1: 0.6556, (best 0.8180)
Epoch 12, loss: 71.9137, val mf1: 0.6471, (best 0.8180)
Epoch 13, loss: 67.4871, val mf1: 0.6442, (best 0.8180)
Epoch 14, loss: 61.9711, val mf1: 0.6447, (best 0.8180)
Epoch 15, loss: 55.6627, val mf1: 0.6484, (best 0.8180)
Epoch 16, loss: 48.7729, val mf1: 0.6583, (best 0.8180)
Epoch 17, loss: 41.6203, val mf1: 0.6836, (best 0.8180)
Epoch 18, loss: 34.4229, val mf1: 0.7183, (best 0.8180)
Epoch 19, loss: 27.3950, val mf1: 0.7521, (best 0.8180)
Epoch 20, loss: 20.4966, val mf1: 0.7933, (best 0.8180)
Epoch 21, loss: 13.4948, val mf1: 0.7302, (best 0.8180)
Epoch 22, loss: 10.1356, val mf1: 0.5194, (best 0.8180)
Epoch 23, loss: 16.5838, val mf1: 0.4364, (best 0.8180)
Epoch 24, loss: 18.5569, val mf1: 0.4159, (best 0.8180)
Epoch 25, loss: 13.3800, val mf1: 0.4773, (best 0.8180)
Epoch 26, loss: 10.6247, val mf1: 0.5517, (best 0.8180)
Epoch 27, loss: 6.8688, val mf1: 0.8416, (best 0.8416)
Epoch 28, loss: 6.4597, val mf1: 0.6415, (best 0.8416)
Epoch 29, loss: 7.9473, val mf1: 0.5493, (best 0.8416)
Epoch 30, loss: 8.5337, val mf1: 0.5383, (best 0.8416)
Epoch 31, loss: 7.9419, val mf1: 0.5639, (best 0.8416)
Epoch 32, loss: 6.9256, val mf1: 0.6037, (best 0.8416)
Epoch 33, loss: 5.9572, val mf1: 0.6673, (best 0.8416)
Epoch 34, loss: 5.1315, val mf1: 0.7164, (best 0.8416)
Epoch 35, loss: 4.0806, val mf1: 0.7430, (best 0.8416)
Epoch 36, loss: 2.5889, val mf1: 0.7334, (best 0.8416)
Epoch 37, loss: 7.7886, val mf1: 0.5333, (best 0.8416)
Epoch 38, loss: 2.8814, val mf1: 0.7843, (best 0.8416)
Epoch 39, loss: 4.1385, val mf1: 0.8297, (best 0.8416)
Epoch 40, loss: 4.0791, val mf1: 0.8266, (best 0.8416)
Epoch 41, loss: 2.9247, val mf1: 0.7722, (best 0.8416)
Epoch 42, loss: 3.3725, val mf1: 0.5322, (best 0.8416)
Epoch 43, loss: 2.3190, val mf1: 0.5844, (best 0.8416)
Epoch 44, loss: 2.3609, val mf1: 0.7661, (best 0.8416)
Epoch 45, loss: 2.6943, val mf1: 0.7706, (best 0.8416)
Epoch 46, loss: 2.4858, val mf1: 0.7314, (best 0.8416)
Epoch 47, loss: 2.1768, val mf1: 0.6651, (best 0.8416)
Epoch 48, loss: 2.4365, val mf1: 0.5414, (best 0.8416)
Epoch 49, loss: 1.7917, val mf1: 0.6219, (best 0.8416)
Epoch 50, loss: 1.5769, val mf1: 0.7343, (best 0.8416)
Epoch 51, loss: 1.4768, val mf1: 0.8242, (best 0.8416)
Epoch 52, loss: 1.4009, val mf1: 0.6286, (best 0.8416)
Epoch 53, loss: 1.6114, val mf1: 0.5962, (best 0.8416)
Epoch 54, loss: 1.3642, val mf1: 0.7998, (best 0.8416)
Epoch 55, loss: 1.2780, val mf1: 0.8433, (best 0.8433)
Epoch 56, loss: 1.0368, val mf1: 0.6313, (best 0.8433)
Epoch 57, loss: 0.9487, val mf1: 0.6504, (best 0.8433)
Epoch 58, loss: 1.0642, val mf1: 0.7380, (best 0.8433)
Epoch 59, loss: 1.0094, val mf1: 0.7365, (best 0.8433)
Epoch 60, loss: 0.9158, val mf1: 0.6218, (best 0.8433)
Epoch 61, loss: 0.7331, val mf1: 0.7636, (best 0.8433)
Epoch 62, loss: 0.6909, val mf1: 0.7056, (best 0.8433)
Epoch 63, loss: 0.7134, val mf1: 0.7730, (best 0.8433)
Epoch 64, loss: 0.7072, val mf1: 0.6698, (best 0.8433)
Epoch 65, loss: 0.9005, val mf1: 0.8470, (best 0.8470)
Epoch 66, loss: 0.6632, val mf1: 0.6804, (best 0.8470)
Epoch 67, loss: 1.4951, val mf1: 0.4991, (best 0.8470)
Epoch 68, loss: 2.8748, val mf1: 0.8424, (best 0.8470)
Epoch 69, loss: 4.7209, val mf1: 0.8236, (best 0.8470)
Epoch 70, loss: 4.2330, val mf1: 0.8472, (best 0.8472)
Epoch 71, loss: 2.8196, val mf1: 0.7889, (best 0.8472)
Epoch 72, loss: 2.8098, val mf1: 0.5513, (best 0.8472)
Epoch 73, loss: 3.9805, val mf1: 0.4448, (best 0.8472)
Epoch 74, loss: 2.8904, val mf1: 0.4896, (best 0.8472)
Epoch 75, loss: 1.5212, val mf1: 0.6660, (best 0.8472)
Epoch 76, loss: 1.9129, val mf1: 0.8591, (best 0.8591)
Epoch 77, loss: 1.7892, val mf1: 0.8472, (best 0.8591)
Epoch 78, loss: 4.3977, val mf1: 0.5294, (best 0.8591)
Epoch 79, loss: 3.5871, val mf1: 0.8392, (best 0.8591)
Epoch 80, loss: 5.1723, val mf1: 0.8392, (best 0.8591)
Epoch 81, loss: 5.3748, val mf1: 0.8496, (best 0.8591)
Epoch 82, loss: 4.5991, val mf1: 0.8599, (best 0.8599)
Epoch 83, loss: 3.3546, val mf1: 0.7693, (best 0.8599)
Epoch 84, loss: 3.2729, val mf1: 0.5791, (best 0.8599)
Epoch 85, loss: 4.4593, val mf1: 0.4824, (best 0.8599)
Epoch 86, loss: 4.7305, val mf1: 0.4597, (best 0.8599)
Epoch 87, loss: 3.3063, val mf1: 0.5183, (best 0.8599)
Epoch 88, loss: 2.2092, val mf1: 0.7042, (best 0.8599)
Epoch 89, loss: 2.5967, val mf1: 0.8371, (best 0.8599)
Epoch 90, loss: 2.6818, val mf1: 0.8508, (best 0.8599)
Epoch 91, loss: 2.0228, val mf1: 0.8203, (best 0.8599)
Epoch 92, loss: 3.0847, val mf1: 0.5494, (best 0.8599)
Epoch 93, loss: 1.8107, val mf1: 0.7526, (best 0.8599)
Epoch 94, loss: 2.1729, val mf1: 0.8457, (best 0.8599)
Epoch 95, loss: 1.8258, val mf1: 0.8439, (best 0.8599)
Epoch 96, loss: 1.1474, val mf1: 0.6977, (best 0.8599)
Epoch 97, loss: 1.7615, val mf1: 0.5477, (best 0.8599)
Epoch 98, loss: 1.1342, val mf1: 0.6445, (best 0.8599)
Epoch 99, loss: 1.3527, val mf1: 0.7586, (best 0.8599)
time cost:  26.71331548690796 s
Test: REC 62.07 PRE 85.23 MF1 85.33 AUC 91.80
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 70.3709, val mf1: 0.3138, (best 0.3138)
Epoch 1, loss: 50.6711, val mf1: 0.7392, (best 0.7392)
Epoch 2, loss: 72.2631, val mf1: 0.7780, (best 0.7780)
Epoch 3, loss: 85.8005, val mf1: 0.7333, (best 0.7780)
Epoch 4, loss: 92.5600, val mf1: 0.7054, (best 0.7780)
Epoch 5, loss: 95.1534, val mf1: 0.6749, (best 0.7780)
Epoch 6, loss: 94.4584, val mf1: 0.6513, (best 0.7780)
Epoch 7, loss: 90.9034, val mf1: 0.6382, (best 0.7780)
Epoch 8, loss: 85.1089, val mf1: 0.6314, (best 0.7780)
Epoch 9, loss: 77.3624, val mf1: 0.6281, (best 0.7780)
Epoch 10, loss: 68.1473, val mf1: 0.6318, (best 0.7780)
Epoch 11, loss: 58.0769, val mf1: 0.6404, (best 0.7780)
Epoch 12, loss: 47.4796, val mf1: 0.6570, (best 0.7780)
Epoch 13, loss: 36.5168, val mf1: 0.6591, (best 0.7780)
Epoch 14, loss: 25.6669, val mf1: 0.6412, (best 0.7780)
Epoch 15, loss: 16.4115, val mf1: 0.5789, (best 0.7780)
Epoch 16, loss: 21.5473, val mf1: 0.4380, (best 0.7780)
Epoch 17, loss: 19.5560, val mf1: 0.4349, (best 0.7780)
Epoch 18, loss: 16.0261, val mf1: 0.5067, (best 0.7780)
Epoch 19, loss: 14.0217, val mf1: 0.5856, (best 0.7780)
Epoch 20, loss: 10.9138, val mf1: 0.6870, (best 0.7780)
Epoch 21, loss: 11.3025, val mf1: 0.5458, (best 0.7780)
Epoch 22, loss: 12.6200, val mf1: 0.4935, (best 0.7780)
Epoch 23, loss: 11.7582, val mf1: 0.5008, (best 0.7780)
Epoch 24, loss: 9.4015, val mf1: 0.5664, (best 0.7780)
Epoch 25, loss: 8.0078, val mf1: 0.7136, (best 0.7780)
Epoch 26, loss: 6.8578, val mf1: 0.7710, (best 0.7780)
Epoch 27, loss: 4.9642, val mf1: 0.7131, (best 0.7780)
Epoch 28, loss: 5.8281, val mf1: 0.5513, (best 0.7780)
Epoch 29, loss: 4.1708, val mf1: 0.6238, (best 0.7780)
Epoch 30, loss: 4.4749, val mf1: 0.8134, (best 0.8134)
Epoch 31, loss: 4.1506, val mf1: 0.8080, (best 0.8134)
Epoch 32, loss: 3.7516, val mf1: 0.5733, (best 0.8134)
Epoch 33, loss: 4.0815, val mf1: 0.5423, (best 0.8134)
Epoch 34, loss: 3.6436, val mf1: 0.6896, (best 0.8134)
Epoch 35, loss: 3.6917, val mf1: 0.7847, (best 0.8134)
Epoch 36, loss: 2.7535, val mf1: 0.7694, (best 0.8134)
Epoch 37, loss: 4.6015, val mf1: 0.5035, (best 0.8134)
Epoch 38, loss: 4.5676, val mf1: 0.7600, (best 0.8134)
Epoch 39, loss: 6.5278, val mf1: 0.7846, (best 0.8134)
Epoch 40, loss: 7.2501, val mf1: 0.7749, (best 0.8134)
Epoch 41, loss: 6.9259, val mf1: 0.7375, (best 0.8134)
Epoch 42, loss: 6.0188, val mf1: 0.6685, (best 0.8134)
Epoch 43, loss: 5.0431, val mf1: 0.5909, (best 0.8134)
Epoch 44, loss: 4.5177, val mf1: 0.4861, (best 0.8134)
Epoch 45, loss: 3.7741, val mf1: 0.4132, (best 0.8134)
Epoch 46, loss: 2.0411, val mf1: 0.7778, (best 0.8134)
Epoch 47, loss: 2.8367, val mf1: 0.8333, (best 0.8333)
Epoch 48, loss: 2.9212, val mf1: 0.6153, (best 0.8333)
Epoch 49, loss: 4.3378, val mf1: 0.8124, (best 0.8333)
Epoch 50, loss: 4.5093, val mf1: 0.8094, (best 0.8333)
Epoch 51, loss: 3.0811, val mf1: 0.7396, (best 0.8333)
Epoch 52, loss: 10.6852, val mf1: 0.4717, (best 0.8333)
Epoch 53, loss: 5.9179, val mf1: 0.8477, (best 0.8477)
Epoch 54, loss: 9.5409, val mf1: 0.8517, (best 0.8517)
Epoch 55, loss: 11.4529, val mf1: 0.8564, (best 0.8564)
Epoch 56, loss: 11.9144, val mf1: 0.8538, (best 0.8564)
Epoch 57, loss: 11.4222, val mf1: 0.7796, (best 0.8564)
Epoch 58, loss: 11.0575, val mf1: 0.6532, (best 0.8564)
Epoch 59, loss: 11.2851, val mf1: 0.5640, (best 0.8564)
Epoch 60, loss: 11.6153, val mf1: 0.5147, (best 0.8564)
Epoch 61, loss: 11.3876, val mf1: 0.4864, (best 0.8564)
Epoch 62, loss: 10.2167, val mf1: 0.4795, (best 0.8564)
Epoch 63, loss: 8.1488, val mf1: 0.4955, (best 0.8564)
Epoch 64, loss: 5.6469, val mf1: 0.5404, (best 0.8564)
Epoch 65, loss: 3.6103, val mf1: 0.6710, (best 0.8564)
Epoch 66, loss: 3.1795, val mf1: 0.6631, (best 0.8564)
Epoch 67, loss: 3.2570, val mf1: 0.5551, (best 0.8564)
Epoch 68, loss: 5.2602, val mf1: 0.5063, (best 0.8564)
Epoch 69, loss: 3.9606, val mf1: 0.6867, (best 0.8564)
Epoch 70, loss: 5.1487, val mf1: 0.7698, (best 0.8564)
Epoch 71, loss: 4.8588, val mf1: 0.7921, (best 0.8564)
Epoch 72, loss: 3.5544, val mf1: 0.7695, (best 0.8564)
Epoch 73, loss: 3.2921, val mf1: 0.5258, (best 0.8564)
Epoch 74, loss: 3.0420, val mf1: 0.5246, (best 0.8564)
Epoch 75, loss: 2.2713, val mf1: 0.8144, (best 0.8564)
Epoch 76, loss: 2.5781, val mf1: 0.8340, (best 0.8564)
Epoch 77, loss: 2.1134, val mf1: 0.8130, (best 0.8564)
Epoch 78, loss: 1.7214, val mf1: 0.6279, (best 0.8564)
Epoch 79, loss: 2.6253, val mf1: 0.4989, (best 0.8564)
Epoch 80, loss: 1.9690, val mf1: 0.5844, (best 0.8564)
Epoch 81, loss: 2.0122, val mf1: 0.7222, (best 0.8564)
Epoch 82, loss: 2.1298, val mf1: 0.7488, (best 0.8564)
Epoch 83, loss: 1.7739, val mf1: 0.7530, (best 0.8564)
Epoch 84, loss: 1.0992, val mf1: 0.6957, (best 0.8564)
Epoch 85, loss: 3.4335, val mf1: 0.5187, (best 0.8564)
Epoch 86, loss: 3.1926, val mf1: 0.8301, (best 0.8564)
Epoch 87, loss: 5.4450, val mf1: 0.8446, (best 0.8564)
Epoch 88, loss: 6.6257, val mf1: 0.8520, (best 0.8564)
Epoch 89, loss: 6.7753, val mf1: 0.8526, (best 0.8564)
Epoch 90, loss: 6.0072, val mf1: 0.8463, (best 0.8564)
Epoch 91, loss: 4.4826, val mf1: 0.8269, (best 0.8564)
Epoch 92, loss: 3.1345, val mf1: 0.6204, (best 0.8564)
Epoch 93, loss: 4.4660, val mf1: 0.4201, (best 0.8564)
Epoch 94, loss: 3.6374, val mf1: 0.4126, (best 0.8564)
Epoch 95, loss: 1.2759, val mf1: 0.7436, (best 0.8564)
Epoch 96, loss: 1.4279, val mf1: 0.8284, (best 0.8564)
Epoch 97, loss: 1.3297, val mf1: 0.7147, (best 0.8564)
Epoch 98, loss: 3.6241, val mf1: 0.5689, (best 0.8564)
Epoch 99, loss: 3.5374, val mf1: 0.8430, (best 0.8564)
time cost:  26.112646102905273 s
Test: REC 64.55 PRE 83.42 MF1 85.82 AUC 90.74
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 327.6476, val mf1: 0.0445, (best 0.0445)
Epoch 1, loss: 96.8699, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 141.5788, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 153.5750, val mf1: 0.4883, (best 0.4883)
Epoch 4, loss: 148.3388, val mf1: 0.4883, (best 0.4883)
Epoch 5, loss: 131.9326, val mf1: 0.4883, (best 0.4883)
Epoch 6, loss: 111.2356, val mf1: 0.8398, (best 0.8398)
Epoch 7, loss: 101.2894, val mf1: 0.8089, (best 0.8398)
Epoch 8, loss: 93.8605, val mf1: 0.7373, (best 0.8398)
Epoch 9, loss: 88.2145, val mf1: 0.6899, (best 0.8398)
Epoch 10, loss: 83.8431, val mf1: 0.6467, (best 0.8398)
Epoch 11, loss: 80.2312, val mf1: 0.6174, (best 0.8398)
Epoch 12, loss: 76.2106, val mf1: 0.5942, (best 0.8398)
Epoch 13, loss: 71.2113, val mf1: 0.5841, (best 0.8398)
Epoch 14, loss: 64.9720, val mf1: 0.5788, (best 0.8398)
Epoch 15, loss: 57.8818, val mf1: 0.5802, (best 0.8398)
Epoch 16, loss: 50.4636, val mf1: 0.5865, (best 0.8398)
Epoch 17, loss: 43.3107, val mf1: 0.5970, (best 0.8398)
Epoch 18, loss: 36.3316, val mf1: 0.6139, (best 0.8398)
Epoch 19, loss: 29.4969, val mf1: 0.6289, (best 0.8398)
Epoch 20, loss: 22.8377, val mf1: 0.6523, (best 0.8398)
Epoch 21, loss: 16.7415, val mf1: 0.6818, (best 0.8398)
Epoch 22, loss: 10.9868, val mf1: 0.7229, (best 0.8398)
Epoch 23, loss: 9.1938, val mf1: 0.6230, (best 0.8398)
Epoch 24, loss: 11.5517, val mf1: 0.5851, (best 0.8398)
Epoch 25, loss: 7.8962, val mf1: 0.6068, (best 0.8398)
Epoch 26, loss: 8.0862, val mf1: 0.7517, (best 0.8398)
Epoch 27, loss: 5.9038, val mf1: 0.8164, (best 0.8398)
Epoch 28, loss: 4.8584, val mf1: 0.6265, (best 0.8398)
Epoch 29, loss: 5.1693, val mf1: 0.5385, (best 0.8398)
Epoch 30, loss: 5.9342, val mf1: 0.4733, (best 0.8398)
Epoch 31, loss: 5.7332, val mf1: 0.4588, (best 0.8398)
Epoch 32, loss: 4.1469, val mf1: 0.5247, (best 0.8398)
Epoch 33, loss: 3.1431, val mf1: 0.6275, (best 0.8398)
Epoch 34, loss: 2.9201, val mf1: 0.7498, (best 0.8398)
Epoch 35, loss: 2.5419, val mf1: 0.8023, (best 0.8398)
Epoch 36, loss: 2.1793, val mf1: 0.5922, (best 0.8398)
Epoch 37, loss: 2.6664, val mf1: 0.7760, (best 0.8398)
Epoch 38, loss: 2.9043, val mf1: 0.7952, (best 0.8398)
Epoch 39, loss: 2.3240, val mf1: 0.7395, (best 0.8398)
Epoch 40, loss: 4.9120, val mf1: 0.5398, (best 0.8398)
Epoch 41, loss: 3.5456, val mf1: 0.8440, (best 0.8440)
Epoch 42, loss: 5.1702, val mf1: 0.8479, (best 0.8479)
Epoch 43, loss: 5.8602, val mf1: 0.8361, (best 0.8479)
Epoch 44, loss: 5.7936, val mf1: 0.8084, (best 0.8479)
Epoch 45, loss: 5.2589, val mf1: 0.7526, (best 0.8479)
Epoch 46, loss: 4.6451, val mf1: 0.6753, (best 0.8479)
Epoch 47, loss: 4.2014, val mf1: 0.5906, (best 0.8479)
Epoch 48, loss: 4.2578, val mf1: 0.4900, (best 0.8479)
Epoch 49, loss: 4.4792, val mf1: 0.4164, (best 0.8479)
Epoch 50, loss: 3.2633, val mf1: 0.4546, (best 0.8479)
Epoch 51, loss: 1.8892, val mf1: 0.6546, (best 0.8479)
Epoch 52, loss: 1.9923, val mf1: 0.7695, (best 0.8479)
Epoch 53, loss: 2.0600, val mf1: 0.8169, (best 0.8479)
Epoch 54, loss: 2.4228, val mf1: 0.5944, (best 0.8479)
Epoch 55, loss: 2.7579, val mf1: 0.8014, (best 0.8479)
Epoch 56, loss: 3.0630, val mf1: 0.8094, (best 0.8479)
Epoch 57, loss: 2.5040, val mf1: 0.7801, (best 0.8479)
Epoch 58, loss: 3.3732, val mf1: 0.5628, (best 0.8479)
Epoch 59, loss: 2.1898, val mf1: 0.8240, (best 0.8479)
Epoch 60, loss: 2.3958, val mf1: 0.8397, (best 0.8479)
Epoch 61, loss: 2.0107, val mf1: 0.7844, (best 0.8479)
Epoch 62, loss: 1.3855, val mf1: 0.7070, (best 0.8479)
Epoch 63, loss: 2.2213, val mf1: 0.4864, (best 0.8479)
Epoch 64, loss: 1.5486, val mf1: 0.6473, (best 0.8479)
Epoch 65, loss: 1.9097, val mf1: 0.6895, (best 0.8479)
Epoch 66, loss: 2.0294, val mf1: 0.6993, (best 0.8479)
Epoch 67, loss: 1.8378, val mf1: 0.6906, (best 0.8479)
Epoch 68, loss: 1.5355, val mf1: 0.6536, (best 0.8479)
Epoch 69, loss: 1.5556, val mf1: 0.5658, (best 0.8479)
Epoch 70, loss: 1.0642, val mf1: 0.6496, (best 0.8479)
Epoch 71, loss: 1.0012, val mf1: 0.7391, (best 0.8479)
Epoch 72, loss: 0.9342, val mf1: 0.7083, (best 0.8479)
Epoch 73, loss: 1.6011, val mf1: 0.5303, (best 0.8479)
Epoch 74, loss: 2.8663, val mf1: 0.8367, (best 0.8479)
Epoch 75, loss: 4.3697, val mf1: 0.8395, (best 0.8479)
Epoch 76, loss: 4.9051, val mf1: 0.8455, (best 0.8479)
Epoch 77, loss: 4.6138, val mf1: 0.8533, (best 0.8533)
Epoch 78, loss: 3.6966, val mf1: 0.8458, (best 0.8533)
Epoch 79, loss: 2.4738, val mf1: 0.7538, (best 0.8533)
Epoch 80, loss: 1.5851, val mf1: 0.6362, (best 0.8533)
Epoch 81, loss: 5.2214, val mf1: 0.2925, (best 0.8533)
Epoch 82, loss: 2.3180, val mf1: 0.6715, (best 0.8533)
Epoch 83, loss: 3.8464, val mf1: 0.7542, (best 0.8533)
Epoch 84, loss: 5.0980, val mf1: 0.8059, (best 0.8533)
Epoch 85, loss: 5.8196, val mf1: 0.8373, (best 0.8533)
Epoch 86, loss: 5.9385, val mf1: 0.8411, (best 0.8533)
Epoch 87, loss: 5.5017, val mf1: 0.8256, (best 0.8533)
Epoch 88, loss: 4.6448, val mf1: 0.7799, (best 0.8533)
Epoch 89, loss: 3.5872, val mf1: 0.7197, (best 0.8533)
Epoch 90, loss: 2.6003, val mf1: 0.6362, (best 0.8533)
Epoch 91, loss: 2.6730, val mf1: 0.4627, (best 0.8533)
Epoch 92, loss: 3.7302, val mf1: 0.3374, (best 0.8533)
Epoch 93, loss: 1.3816, val mf1: 0.5538, (best 0.8533)
Epoch 94, loss: 1.4309, val mf1: 0.7978, (best 0.8533)
Epoch 95, loss: 2.1241, val mf1: 0.8371, (best 0.8533)
Epoch 96, loss: 2.2527, val mf1: 0.8252, (best 0.8533)
Epoch 97, loss: 1.7366, val mf1: 0.7901, (best 0.8533)
Epoch 98, loss: 3.5428, val mf1: 0.5329, (best 0.8533)
Epoch 99, loss: 2.2454, val mf1: 0.8270, (best 0.8533)
time cost:  23.6413676738739 s
Test: REC 60.97 PRE 86.84 MF1 85.24 AUC 91.23
MF1-mean: 85.46, MF1-std: 0.25, AUC-mean: 91.26, AUC-std: 0.43
