Using device: cuda
Namespace(dataset='tfinance', train_ratio=0.4, hid_dim=128, num_layers=3, epoch=100, run=3, knn_reconstruct_graph=True, knn_reconstruct_graph_approximate=False, alpha=0.6, top_k=4, save_model=False, model_path='./model', device=device(type='cuda', index=0), choose_model='GCN', hyperparameter_tuning=False)
Graph(num_nodes=39357, num_edges=249334,
      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'feature': Scheme(shape=(10,), dtype=torch.float32)}
      edata_schemes={})
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 96.9851, val mf1: 0.1141, (best 0.1141)
Epoch 1, loss: 92.9315, val mf1: 0.4883, (best 0.4883)
Epoch 2, loss: 125.6737, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 130.9320, val mf1: 0.4883, (best 0.4883)
Epoch 4, loss: 123.5747, val mf1: 0.4883, (best 0.4883)
Epoch 5, loss: 109.0352, val mf1: 0.5103, (best 0.5103)
Epoch 6, loss: 93.4098, val mf1: 0.8511, (best 0.8511)
Epoch 7, loss: 85.6227, val mf1: 0.7664, (best 0.8511)
Epoch 8, loss: 79.6686, val mf1: 0.7047, (best 0.8511)
Epoch 9, loss: 74.7069, val mf1: 0.6469, (best 0.8511)
Epoch 10, loss: 70.0734, val mf1: 0.6139, (best 0.8511)
Epoch 11, loss: 65.2611, val mf1: 0.5811, (best 0.8511)
Epoch 12, loss: 59.7859, val mf1: 0.5602, (best 0.8511)
Epoch 13, loss: 53.7244, val mf1: 0.5424, (best 0.8511)
Epoch 14, loss: 47.1931, val mf1: 0.5339, (best 0.8511)
Epoch 15, loss: 40.1789, val mf1: 0.5248, (best 0.8511)
Epoch 16, loss: 32.8776, val mf1: 0.5171, (best 0.8511)
Epoch 17, loss: 25.5249, val mf1: 0.5142, (best 0.8511)
Epoch 18, loss: 18.4114, val mf1: 0.5120, (best 0.8511)
Epoch 19, loss: 12.3362, val mf1: 0.5028, (best 0.8511)
Epoch 20, loss: 11.1453, val mf1: 0.4577, (best 0.8511)
Epoch 21, loss: 6.5650, val mf1: 0.5705, (best 0.8511)
Epoch 22, loss: 6.7245, val mf1: 0.8200, (best 0.8511)
Epoch 23, loss: 8.5002, val mf1: 0.8516, (best 0.8516)
Epoch 24, loss: 9.3952, val mf1: 0.8380, (best 0.8516)
Epoch 25, loss: 9.3733, val mf1: 0.7913, (best 0.8516)
Epoch 26, loss: 9.4763, val mf1: 0.5871, (best 0.8516)
Epoch 27, loss: 7.5346, val mf1: 0.6659, (best 0.8516)
Epoch 28, loss: 7.1249, val mf1: 0.8154, (best 0.8516)
Epoch 29, loss: 5.9282, val mf1: 0.8312, (best 0.8516)
Epoch 30, loss: 4.3113, val mf1: 0.6668, (best 0.8516)
Epoch 31, loss: 4.3589, val mf1: 0.5830, (best 0.8516)
Epoch 32, loss: 3.7134, val mf1: 0.8301, (best 0.8516)
Epoch 33, loss: 3.8417, val mf1: 0.8190, (best 0.8516)
Epoch 34, loss: 3.4115, val mf1: 0.7894, (best 0.8516)
Epoch 35, loss: 2.9655, val mf1: 0.6639, (best 0.8516)
Epoch 36, loss: 3.4566, val mf1: 0.5268, (best 0.8516)
Epoch 37, loss: 4.2937, val mf1: 0.4591, (best 0.8516)
Epoch 38, loss: 3.9209, val mf1: 0.4754, (best 0.8516)
Epoch 39, loss: 2.9564, val mf1: 0.5839, (best 0.8516)
Epoch 40, loss: 2.7531, val mf1: 0.7285, (best 0.8516)
Epoch 41, loss: 2.8364, val mf1: 0.7593, (best 0.8516)
Epoch 42, loss: 2.5129, val mf1: 0.7743, (best 0.8516)
Epoch 43, loss: 1.7219, val mf1: 0.7785, (best 0.8516)
Epoch 44, loss: 6.0510, val mf1: 0.4890, (best 0.8516)
Epoch 45, loss: 3.5893, val mf1: 0.8146, (best 0.8516)
Epoch 46, loss: 6.0375, val mf1: 0.8317, (best 0.8516)
Epoch 47, loss: 7.6923, val mf1: 0.8393, (best 0.8516)
Epoch 48, loss: 8.5882, val mf1: 0.8434, (best 0.8516)
Epoch 49, loss: 8.7997, val mf1: 0.8445, (best 0.8516)
Epoch 50, loss: 8.3933, val mf1: 0.8410, (best 0.8516)
Epoch 51, loss: 7.4475, val mf1: 0.8339, (best 0.8516)
Epoch 52, loss: 6.0530, val mf1: 0.8214, (best 0.8516)
Epoch 53, loss: 4.3601, val mf1: 0.7897, (best 0.8516)
Epoch 54, loss: 2.7942, val mf1: 0.6741, (best 0.8516)
Epoch 55, loss: 3.6366, val mf1: 0.4409, (best 0.8516)
Epoch 56, loss: 6.0814, val mf1: 0.3602, (best 0.8516)
Epoch 57, loss: 2.9752, val mf1: 0.4761, (best 0.8516)
Epoch 58, loss: 2.4386, val mf1: 0.7135, (best 0.8516)
Epoch 59, loss: 3.3875, val mf1: 0.8001, (best 0.8516)
Epoch 60, loss: 4.0126, val mf1: 0.8296, (best 0.8516)
Epoch 61, loss: 4.1290, val mf1: 0.8417, (best 0.8516)
Epoch 62, loss: 3.7138, val mf1: 0.8411, (best 0.8516)
Epoch 63, loss: 2.8343, val mf1: 0.8326, (best 0.8516)
Epoch 64, loss: 1.6275, val mf1: 0.8006, (best 0.8516)
Epoch 65, loss: 3.2996, val mf1: 0.4859, (best 0.8516)
Epoch 66, loss: 1.1783, val mf1: 0.6632, (best 0.8516)
Epoch 67, loss: 1.5993, val mf1: 0.8070, (best 0.8516)
Epoch 68, loss: 1.8980, val mf1: 0.8103, (best 0.8516)
Epoch 69, loss: 1.7859, val mf1: 0.8086, (best 0.8516)
Epoch 70, loss: 1.3726, val mf1: 0.7760, (best 0.8516)
Epoch 71, loss: 1.1192, val mf1: 0.6211, (best 0.8516)
Epoch 72, loss: 1.6816, val mf1: 0.4740, (best 0.8516)
Epoch 73, loss: 0.9967, val mf1: 0.7646, (best 0.8516)
Epoch 74, loss: 1.3727, val mf1: 0.8390, (best 0.8516)
Epoch 75, loss: 1.2935, val mf1: 0.8474, (best 0.8516)
Epoch 76, loss: 0.7960, val mf1: 0.8278, (best 0.8516)
Epoch 77, loss: 1.7953, val mf1: 0.5114, (best 0.8516)
Epoch 78, loss: 1.3254, val mf1: 0.8257, (best 0.8516)
Epoch 79, loss: 2.1787, val mf1: 0.8362, (best 0.8516)
Epoch 80, loss: 2.5278, val mf1: 0.8240, (best 0.8516)
Epoch 81, loss: 2.4419, val mf1: 0.7999, (best 0.8516)
Epoch 82, loss: 2.0453, val mf1: 0.7437, (best 0.8516)
Epoch 83, loss: 1.7332, val mf1: 0.6241, (best 0.8516)
Epoch 84, loss: 1.8336, val mf1: 0.5232, (best 0.8516)
Epoch 85, loss: 1.1880, val mf1: 0.5686, (best 0.8516)
Epoch 86, loss: 0.5268, val mf1: 0.7480, (best 0.8516)
Epoch 87, loss: 1.1281, val mf1: 0.5908, (best 0.8516)
Epoch 88, loss: 2.0039, val mf1: 0.8579, (best 0.8579)
Epoch 89, loss: 3.0930, val mf1: 0.8512, (best 0.8579)
Epoch 90, loss: 3.5702, val mf1: 0.8508, (best 0.8579)
Epoch 91, loss: 3.4586, val mf1: 0.8522, (best 0.8579)
Epoch 92, loss: 2.8551, val mf1: 0.8564, (best 0.8579)
Epoch 93, loss: 1.8601, val mf1: 0.8470, (best 0.8579)
Epoch 94, loss: 0.9389, val mf1: 0.6633, (best 0.8579)
Epoch 95, loss: 2.8671, val mf1: 0.5049, (best 0.8579)
Epoch 96, loss: 1.7424, val mf1: 0.7857, (best 0.8579)
Epoch 97, loss: 2.8830, val mf1: 0.8060, (best 0.8579)
Epoch 98, loss: 3.5702, val mf1: 0.8079, (best 0.8579)
Epoch 99, loss: 3.8204, val mf1: 0.7928, (best 0.8579)
time cost:  25.928799867630005 s
Test: REC 62.62 PRE 84.07 MF1 85.30 AUC 91.88
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 21.1598, val mf1: 0.5595, (best 0.5595)
Epoch 1, loss: 750.3227, val mf1: 0.0438, (best 0.5595)
Epoch 2, loss: 146.6741, val mf1: 0.0457, (best 0.5595)
Epoch 3, loss: 31.1422, val mf1: 0.7647, (best 0.7647)
Epoch 4, loss: 60.0336, val mf1: 0.7683, (best 0.7683)
Epoch 5, loss: 78.6479, val mf1: 0.6397, (best 0.7683)
Epoch 6, loss: 86.3761, val mf1: 0.8356, (best 0.8356)
Epoch 7, loss: 91.3628, val mf1: 0.8504, (best 0.8504)
Epoch 8, loss: 93.8016, val mf1: 0.8371, (best 0.8504)
Epoch 9, loss: 94.2807, val mf1: 0.8130, (best 0.8504)
Epoch 10, loss: 93.3074, val mf1: 0.7846, (best 0.8504)
Epoch 11, loss: 91.1391, val mf1: 0.7557, (best 0.8504)
Epoch 12, loss: 88.0454, val mf1: 0.7318, (best 0.8504)
Epoch 13, loss: 84.2083, val mf1: 0.7120, (best 0.8504)
Epoch 14, loss: 79.7823, val mf1: 0.6917, (best 0.8504)
Epoch 15, loss: 74.6540, val mf1: 0.6719, (best 0.8504)
Epoch 16, loss: 68.8968, val mf1: 0.6570, (best 0.8504)
Epoch 17, loss: 62.6462, val mf1: 0.6449, (best 0.8504)
Epoch 18, loss: 55.9945, val mf1: 0.6346, (best 0.8504)
Epoch 19, loss: 49.0321, val mf1: 0.6269, (best 0.8504)
Epoch 20, loss: 41.7550, val mf1: 0.6183, (best 0.8504)
Epoch 21, loss: 34.1643, val mf1: 0.6082, (best 0.8504)
Epoch 22, loss: 26.3532, val mf1: 0.6118, (best 0.8504)
Epoch 23, loss: 18.4254, val mf1: 0.6466, (best 0.8504)
Epoch 24, loss: 10.7219, val mf1: 0.6700, (best 0.8504)
Epoch 25, loss: 8.3216, val mf1: 0.4664, (best 0.8504)
Epoch 26, loss: 17.2695, val mf1: 0.3614, (best 0.8504)
Epoch 27, loss: 8.5923, val mf1: 0.4737, (best 0.8504)
Epoch 28, loss: 7.1561, val mf1: 0.7307, (best 0.8504)
Epoch 29, loss: 7.2545, val mf1: 0.8517, (best 0.8517)
Epoch 30, loss: 6.2137, val mf1: 0.8270, (best 0.8517)
Epoch 31, loss: 4.4475, val mf1: 0.7727, (best 0.8517)
Epoch 32, loss: 4.1635, val mf1: 0.5383, (best 0.8517)
Epoch 33, loss: 5.9391, val mf1: 0.4166, (best 0.8517)
Epoch 34, loss: 3.5364, val mf1: 0.6291, (best 0.8517)
Epoch 35, loss: 4.1895, val mf1: 0.7325, (best 0.8517)
Epoch 36, loss: 4.4796, val mf1: 0.7455, (best 0.8517)
Epoch 37, loss: 4.0622, val mf1: 0.7496, (best 0.8517)
Epoch 38, loss: 3.0345, val mf1: 0.7362, (best 0.8517)
Epoch 39, loss: 5.0539, val mf1: 0.5679, (best 0.8517)
Epoch 40, loss: 2.7700, val mf1: 0.7620, (best 0.8517)
Epoch 41, loss: 3.3316, val mf1: 0.7871, (best 0.8517)
Epoch 42, loss: 3.1827, val mf1: 0.7852, (best 0.8517)
Epoch 43, loss: 2.5928, val mf1: 0.7142, (best 0.8517)
Epoch 44, loss: 2.7898, val mf1: 0.5802, (best 0.8517)
Epoch 45, loss: 1.9015, val mf1: 0.6484, (best 0.8517)
Epoch 46, loss: 1.8762, val mf1: 0.7827, (best 0.8517)
Epoch 47, loss: 1.7469, val mf1: 0.7596, (best 0.8517)
Epoch 48, loss: 1.7940, val mf1: 0.6115, (best 0.8517)
Epoch 49, loss: 1.8391, val mf1: 0.5860, (best 0.8517)
Epoch 50, loss: 1.5635, val mf1: 0.7125, (best 0.8517)
Epoch 51, loss: 1.5480, val mf1: 0.7832, (best 0.8517)
Epoch 52, loss: 1.2438, val mf1: 0.7383, (best 0.8517)
Epoch 53, loss: 1.3881, val mf1: 0.6001, (best 0.8517)
Epoch 54, loss: 1.0284, val mf1: 0.7432, (best 0.8517)
Epoch 55, loss: 0.9672, val mf1: 0.7719, (best 0.8517)
Epoch 56, loss: 1.0404, val mf1: 0.5520, (best 0.8517)
Epoch 57, loss: 0.9944, val mf1: 0.6873, (best 0.8517)
Epoch 58, loss: 1.0033, val mf1: 0.7023, (best 0.8517)
Epoch 59, loss: 0.7927, val mf1: 0.6284, (best 0.8517)
Epoch 60, loss: 0.8380, val mf1: 0.6013, (best 0.8517)
Epoch 61, loss: 2.8917, val mf1: 0.8494, (best 0.8517)
Epoch 62, loss: 4.3523, val mf1: 0.8505, (best 0.8517)
Epoch 63, loss: 4.5652, val mf1: 0.8577, (best 0.8577)
Epoch 64, loss: 4.0175, val mf1: 0.7510, (best 0.8577)
Epoch 65, loss: 3.7365, val mf1: 0.5971, (best 0.8577)
Epoch 66, loss: 3.7517, val mf1: 0.5278, (best 0.8577)
Epoch 67, loss: 3.4136, val mf1: 0.4911, (best 0.8577)
Epoch 68, loss: 2.1957, val mf1: 0.5145, (best 0.8577)
Epoch 69, loss: 1.0685, val mf1: 0.5900, (best 0.8577)
Epoch 70, loss: 1.5376, val mf1: 0.7725, (best 0.8577)
Epoch 71, loss: 2.1028, val mf1: 0.6218, (best 0.8577)
Epoch 72, loss: 2.8612, val mf1: 0.5695, (best 0.8577)
Epoch 73, loss: 4.8392, val mf1: 0.8102, (best 0.8577)
Epoch 74, loss: 5.8535, val mf1: 0.8358, (best 0.8577)
Epoch 75, loss: 5.8955, val mf1: 0.8512, (best 0.8577)
Epoch 76, loss: 5.1437, val mf1: 0.8547, (best 0.8577)
Epoch 77, loss: 3.8957, val mf1: 0.7905, (best 0.8577)
Epoch 78, loss: 3.0162, val mf1: 0.6543, (best 0.8577)
Epoch 79, loss: 4.3964, val mf1: 0.4200, (best 0.8577)
Epoch 80, loss: 4.6899, val mf1: 0.3846, (best 0.8577)
Epoch 81, loss: 2.5119, val mf1: 0.5932, (best 0.8577)
Epoch 82, loss: 2.2782, val mf1: 0.7032, (best 0.8577)
Epoch 83, loss: 2.2365, val mf1: 0.7751, (best 0.8577)
Epoch 84, loss: 1.8958, val mf1: 0.8048, (best 0.8577)
Epoch 85, loss: 1.8058, val mf1: 0.6353, (best 0.8577)
Epoch 86, loss: 2.8265, val mf1: 0.5810, (best 0.8577)
Epoch 87, loss: 2.8240, val mf1: 0.8410, (best 0.8577)
Epoch 88, loss: 3.9204, val mf1: 0.8464, (best 0.8577)
Epoch 89, loss: 4.2230, val mf1: 0.8471, (best 0.8577)
Epoch 90, loss: 3.8234, val mf1: 0.8466, (best 0.8577)
Epoch 91, loss: 2.8024, val mf1: 0.8358, (best 0.8577)
Epoch 92, loss: 1.4649, val mf1: 0.7176, (best 0.8577)
Epoch 93, loss: 3.4246, val mf1: 0.5093, (best 0.8577)
Epoch 94, loss: 1.2791, val mf1: 0.7252, (best 0.8577)
Epoch 95, loss: 2.0272, val mf1: 0.7932, (best 0.8577)
Epoch 96, loss: 2.3869, val mf1: 0.7899, (best 0.8577)
Epoch 97, loss: 2.2746, val mf1: 0.7703, (best 0.8577)
Epoch 98, loss: 1.8790, val mf1: 0.7292, (best 0.8577)
Epoch 99, loss: 1.7535, val mf1: 0.5876, (best 0.8577)
time cost:  26.620388507843018 s
Test: REC 65.52 PRE 84.22 MF1 86.29 AUC 91.31
GCNModel
train/dev/test samples:  15742 7792 15823
Train function: val_mask tensor([False, False, False,  ..., False, False, False], device='cuda:0')
cross entropy weight:  20.83356449375867
Epoch 0, loss: 16.1512, val mf1: 0.4764, (best 0.4764)
Epoch 1, loss: 152.7368, val mf1: 0.4241, (best 0.4764)
Epoch 2, loss: 75.0316, val mf1: 0.4883, (best 0.4883)
Epoch 3, loss: 80.6959, val mf1: 0.4883, (best 0.4883)
Epoch 4, loss: 68.9874, val mf1: 0.5258, (best 0.5258)
Epoch 5, loss: 58.5989, val mf1: 0.7614, (best 0.7614)
Epoch 6, loss: 57.0048, val mf1: 0.6540, (best 0.7614)
Epoch 7, loss: 55.8001, val mf1: 0.5952, (best 0.7614)
Epoch 8, loss: 53.4452, val mf1: 0.5606, (best 0.7614)
Epoch 9, loss: 49.4919, val mf1: 0.5360, (best 0.7614)
Epoch 10, loss: 43.9757, val mf1: 0.5199, (best 0.7614)
Epoch 11, loss: 37.0996, val mf1: 0.5056, (best 0.7614)
Epoch 12, loss: 29.3629, val mf1: 0.4892, (best 0.7614)
Epoch 13, loss: 24.2474, val mf1: 0.4126, (best 0.7614)
Epoch 14, loss: 16.2949, val mf1: 0.4697, (best 0.7614)
Epoch 15, loss: 11.3811, val mf1: 0.5844, (best 0.7614)
Epoch 16, loss: 9.6214, val mf1: 0.6686, (best 0.7614)
Epoch 17, loss: 8.5434, val mf1: 0.7547, (best 0.7614)
Epoch 18, loss: 7.1077, val mf1: 0.8205, (best 0.8205)
Epoch 19, loss: 15.1920, val mf1: 0.5869, (best 0.8205)
Epoch 20, loss: 8.5206, val mf1: 0.8239, (best 0.8239)
Epoch 21, loss: 10.0543, val mf1: 0.7543, (best 0.8239)
Epoch 22, loss: 7.8346, val mf1: 0.8441, (best 0.8441)
Epoch 23, loss: 4.1874, val mf1: 0.8402, (best 0.8441)
Epoch 24, loss: 21.1233, val mf1: 0.4875, (best 0.8441)
Epoch 25, loss: 5.1452, val mf1: 0.8127, (best 0.8441)
Epoch 26, loss: 8.9615, val mf1: 0.8141, (best 0.8441)
Epoch 27, loss: 11.2329, val mf1: 0.8059, (best 0.8441)
Epoch 28, loss: 12.1917, val mf1: 0.7933, (best 0.8441)
Epoch 29, loss: 12.0898, val mf1: 0.7647, (best 0.8441)
Epoch 30, loss: 11.1757, val mf1: 0.7320, (best 0.8441)
Epoch 31, loss: 9.8609, val mf1: 0.6710, (best 0.8441)
Epoch 32, loss: 8.6951, val mf1: 0.5723, (best 0.8441)
Epoch 33, loss: 8.3861, val mf1: 0.4852, (best 0.8441)
Epoch 34, loss: 9.0340, val mf1: 0.3829, (best 0.8441)
Epoch 35, loss: 6.4585, val mf1: 0.4205, (best 0.8441)
Epoch 36, loss: 4.0195, val mf1: 0.5623, (best 0.8441)
Epoch 37, loss: 3.2537, val mf1: 0.7095, (best 0.8441)
Epoch 38, loss: 2.8501, val mf1: 0.7441, (best 0.8441)
Epoch 39, loss: 2.4135, val mf1: 0.6414, (best 0.8441)
Epoch 40, loss: 4.7859, val mf1: 0.5334, (best 0.8441)
Epoch 41, loss: 4.1053, val mf1: 0.8509, (best 0.8509)
Epoch 42, loss: 5.8402, val mf1: 0.8537, (best 0.8537)
Epoch 43, loss: 6.4353, val mf1: 0.8505, (best 0.8537)
Epoch 44, loss: 5.9606, val mf1: 0.8479, (best 0.8537)
Epoch 45, loss: 4.5489, val mf1: 0.8437, (best 0.8537)
Epoch 46, loss: 3.2066, val mf1: 0.5967, (best 0.8537)
Epoch 47, loss: 5.6545, val mf1: 0.5173, (best 0.8537)
Epoch 48, loss: 4.0649, val mf1: 0.8494, (best 0.8537)
Epoch 49, loss: 5.9114, val mf1: 0.8520, (best 0.8537)
Epoch 50, loss: 6.7281, val mf1: 0.8419, (best 0.8537)
Epoch 51, loss: 6.6554, val mf1: 0.8321, (best 0.8537)
Epoch 52, loss: 5.8389, val mf1: 0.8080, (best 0.8537)
Epoch 53, loss: 4.4537, val mf1: 0.7768, (best 0.8537)
Epoch 54, loss: 2.9706, val mf1: 0.6677, (best 0.8537)
Epoch 55, loss: 6.3647, val mf1: 0.3720, (best 0.8537)
Epoch 56, loss: 3.1314, val mf1: 0.5787, (best 0.8537)
Epoch 57, loss: 3.7615, val mf1: 0.7116, (best 0.8537)
Epoch 58, loss: 4.3342, val mf1: 0.7429, (best 0.8537)
Epoch 59, loss: 4.3628, val mf1: 0.7559, (best 0.8537)
Epoch 60, loss: 3.8291, val mf1: 0.7496, (best 0.8537)
Epoch 61, loss: 3.0964, val mf1: 0.6434, (best 0.8537)
Epoch 62, loss: 3.1818, val mf1: 0.5381, (best 0.8537)
Epoch 63, loss: 3.8216, val mf1: 0.5072, (best 0.8537)
Epoch 64, loss: 2.8775, val mf1: 0.5701, (best 0.8537)
Epoch 65, loss: 2.8106, val mf1: 0.7292, (best 0.8537)
Epoch 66, loss: 3.3011, val mf1: 0.8311, (best 0.8537)
Epoch 67, loss: 3.1665, val mf1: 0.8352, (best 0.8537)
Epoch 68, loss: 2.4393, val mf1: 0.7373, (best 0.8537)
Epoch 69, loss: 3.1083, val mf1: 0.5462, (best 0.8537)
Epoch 70, loss: 2.1804, val mf1: 0.6084, (best 0.8537)
Epoch 71, loss: 2.4674, val mf1: 0.8322, (best 0.8537)
Epoch 72, loss: 2.5916, val mf1: 0.8315, (best 0.8537)
Epoch 73, loss: 2.0379, val mf1: 0.8132, (best 0.8537)
Epoch 74, loss: 1.4571, val mf1: 0.6098, (best 0.8537)
Epoch 75, loss: 1.4405, val mf1: 0.5843, (best 0.8537)
Epoch 76, loss: 1.7382, val mf1: 0.7542, (best 0.8537)
Epoch 77, loss: 2.0546, val mf1: 0.7549, (best 0.8537)
Epoch 78, loss: 1.8444, val mf1: 0.7247, (best 0.8537)
Epoch 79, loss: 1.3787, val mf1: 0.6528, (best 0.8537)
Epoch 80, loss: 2.6840, val mf1: 0.4317, (best 0.8537)
Epoch 81, loss: 2.0964, val mf1: 0.8001, (best 0.8537)
Epoch 82, loss: 3.3954, val mf1: 0.8456, (best 0.8537)
Epoch 83, loss: 3.9201, val mf1: 0.8549, (best 0.8549)
Epoch 84, loss: 3.6615, val mf1: 0.8546, (best 0.8549)
Epoch 85, loss: 2.7031, val mf1: 0.8478, (best 0.8549)
Epoch 86, loss: 1.2617, val mf1: 0.8024, (best 0.8549)
Epoch 87, loss: 8.1725, val mf1: 0.3049, (best 0.8549)
Epoch 88, loss: 3.3529, val mf1: 0.8508, (best 0.8549)
Epoch 89, loss: 6.4784, val mf1: 0.8590, (best 0.8590)
Epoch 90, loss: 8.6056, val mf1: 0.8574, (best 0.8590)
Epoch 91, loss: 9.7868, val mf1: 0.8584, (best 0.8590)
Epoch 92, loss: 10.1229, val mf1: 0.8603, (best 0.8603)
Epoch 93, loss: 9.7371, val mf1: 0.8528, (best 0.8603)
Epoch 94, loss: 8.7846, val mf1: 0.8262, (best 0.8603)
Epoch 95, loss: 7.4937, val mf1: 0.7510, (best 0.8603)
Epoch 96, loss: 6.2339, val mf1: 0.6374, (best 0.8603)
Epoch 97, loss: 5.1560, val mf1: 0.5593, (best 0.8603)
Epoch 98, loss: 4.2984, val mf1: 0.5055, (best 0.8603)
Epoch 99, loss: 3.9384, val mf1: 0.4262, (best 0.8603)
time cost:  24.70283055305481 s
Test: REC 63.31 PRE 85.79 MF1 85.87 AUC 90.46
MF1-mean: 85.82, MF1-std: 0.41, AUC-mean: 91.22, AUC-std: 0.58
